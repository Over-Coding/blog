{"meta":{"title":"Hexo","subtitle":"","description":"","author":"八一","url":"https://blog.lee81.cn","root":"/"},"pages":[{"title":"404 Not Found：该页无法显示","date":"2022-08-13T12:29:03.569Z","updated":"2022-08-13T12:29:03.569Z","comments":false,"path":"/404.html","permalink":"https://blog.lee81.cn/404.html","excerpt":"","text":""},{"title":"书单","date":"2022-08-13T12:29:03.597Z","updated":"2022-08-13T12:29:03.597Z","comments":false,"path":"books/index.html","permalink":"https://blog.lee81.cn/books/index.html","excerpt":"","text":""},{"title":"关于","date":"2022-08-13T12:29:03.596Z","updated":"2022-08-13T12:29:03.596Z","comments":true,"path":"about/index.html","permalink":"https://blog.lee81.cn/about/index.html","excerpt":"","text":"简介 我是凌风，一个非常懒但又很刻苦的矛盾体。 但是我也是一个有情怀的人，梦想通过自己的技术让这个世界变的更美好一点点(^_^)。 目的 搞这个博客的目的也就是因为我准备跳槽，但是发现自己好多东西都知道的比较零碎，不成体系，复习起来太困难了，所以我就准备搞个博客，把自己知道的技术整理一下，供自己日后复习用。 最后的话 如果我的文章有幸帮到你，或者文章哪里写的不对的，又或者有什么需要我帮助的都可以加我微信私聊，交个朋友，小弟我荣幸之至。"},{"title":"友情链接","date":"2022-08-13T12:29:03.597Z","updated":"2022-08-13T12:29:03.597Z","comments":true,"path":"links/index.html","permalink":"https://blog.lee81.cn/links/index.html","excerpt":"","text":""},{"title":"项目","date":"2022-08-13T12:29:03.597Z","updated":"2022-08-13T12:29:03.597Z","comments":false,"path":"repository/index.html","permalink":"https://blog.lee81.cn/repository/index.html","excerpt":"","text":""},{"title":"标签","date":"2022-08-13T12:29:03.598Z","updated":"2022-08-13T12:29:03.598Z","comments":false,"path":"tags/index.html","permalink":"https://blog.lee81.cn/tags/index.html","excerpt":"","text":""},{"title":"分类","date":"2022-08-13T12:29:03.597Z","updated":"2022-08-13T12:29:03.597Z","comments":false,"path":"categories/index.html","permalink":"https://blog.lee81.cn/categories/index.html","excerpt":"","text":""}],"posts":[{"title":"记一道笔试题","slug":"记一道笔试题","date":"2022-08-13T12:29:03.596Z","updated":"2022-08-13T12:29:03.596Z","comments":true,"path":"2022/08/13/记一道笔试题/","link":"","permalink":"https://blog.lee81.cn/2022/08/13/%E8%AE%B0%E4%B8%80%E9%81%93%E7%AC%94%E8%AF%95%E9%A2%98/","excerpt":"","text":"今天参加了一场笔试，有一道题写出来了，但是有些小问题，在这里记录一下。 1、题目创建一个线程类，实例化三个线程A,B,C，要求线程A打印A，线程B打印B，线程C打印C，然后开启线程的顺序为C -&gt; B -&gt; A，打印结果为： A B C 2、错误思路看到题目的时候，我的第一反应是使用线程通信去做，然后就有了下面的代码。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667public class Test &#123; public static void main(String[] args) &#123; //创建三个线程 MyThread a = new MyThread(&quot;A&quot;); MyThread b = new MyThread(&quot;B&quot;); MyThread c = new MyThread(&quot;C&quot;); //开启线程，按 C-&gt;B-&gt;A的顺序开启 c.start(); b.start(); a.start(); &#125;&#125;class MyThread extends Thread&#123; //创建锁 private static ReentrantLock lock = new ReentrantLock(); private static Condition condition = lock.newCondition(); //创建临时标识，用于表示当前执行那个线程 private static volatile int flag = 0; private String msg; public MyThread(String msg)&#123; this.msg = msg; &#125; public void run() &#123; lock.lock(); try &#123; while (true) &#123; //如果flag为0，并且是线程A if (flag == 0 &amp;&amp; &quot;A&quot;.equals(msg)) &#123; //打印A System.out.println(msg); //将flag设置为1 flag = 1; //唤醒其他线程 condition.signal(); break; &#125; else if (flag == 1 &amp;&amp; &quot;B&quot;.equals(msg)) &#123;//如果flag为1，并且是线程B //打印B System.out.println(msg); //将flag设置为2 flag = 2; //唤醒其他线程 condition.signal(); break; &#125; else if (flag == 2 &amp;&amp; &quot;C&quot;.equals(msg)) &#123;//如果flag为2，并且是线程C //打印C System.out.println(msg); break; &#125; else &#123; //如果是其他情况就阻塞住当前线程 condition.await(); &#125; &#125; &#125; catch (Exception e) &#123; e.printStackTrace(); &#125; finally &#123; //释放锁 lock.unlock(); &#125; &#125;&#125; 3、正确解法面试官说有些问题，所以我就进行了改进，代码如下： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374public class Test &#123; public static void main(String[] args) &#123; //创建三个线程 MyThread a = new MyThread(&quot;A&quot;); MyThread b = new MyThread(&quot;B&quot;); MyThread c = new MyThread(&quot;C&quot;); //开启线程，按 C-&gt;B-&gt;A的顺序开启 c.start(); b.start(); a.start(); &#125;&#125;class MyThread extends Thread&#123; //创建锁 private static ReentrantLock lock = new ReentrantLock(); private static Condition conditionB = lock.newCondition(); private static Condition conditionC = lock.newCondition(); //创建临时标识，用于表示当前执行那个线程 private static volatile int flag = 0; private String msg; public MyThread(String msg)&#123; this.msg = msg; &#125; public void run() &#123; lock.lock(); try &#123; while (true) &#123; //如果flag为0，并且是线程A if (flag == 0 &amp;&amp; &quot;A&quot;.equals(msg)) &#123; //打印A System.out.println(msg); //将flag设置为1 flag = 1; //唤醒B线程 conditionB.signal(); break; &#125; else if (flag == 1 &amp;&amp; &quot;B&quot;.equals(msg)) &#123;//如果flag为1，并且是线程B //打印B System.out.println(msg); //将flag设置为2 flag = 2; //唤醒C线程 conditionC.signal(); break; &#125; else if (flag == 2 &amp;&amp; &quot;C&quot;.equals(msg)) &#123;//如果flag为2，并且是线程C //打印C System.out.println(msg); break; &#125; else &#123;//如果上面的情况不符合，就要阻塞当前线程 //如果当前线程为B，并且flag不为1，就阻塞 if(flag != 1 &amp;&amp; &quot;B&quot;.equals(msg))&#123; conditionB.await(); &#125; //如果当前线程为C，并且flag不为2，就阻塞 if(flag != 2 &amp;&amp; &quot;C&quot;.equals(msg))&#123; conditionC.await(); &#125; &#125; &#125; &#125; catch (Exception e) &#123; e.printStackTrace(); &#125; finally &#123; //释放锁 lock.unlock(); &#125; &#125;&#125; 4、其他解法123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116public class Main &#123; public static void main(String[] args)&#123; Print print = new Print(); //开启线程C new Thread(() -&gt; &#123; print.printC(); &#125;,&quot;C&quot;).start(); //开启线程B new Thread(() -&gt; &#123; print.printB(); &#125;,&quot;B&quot;).start(); //开启线程A new Thread(() -&gt; &#123; print.printA(); &#125;,&quot;A&quot;).start(); &#125;&#125;class Print&#123; private ReentrantLock lock = new ReentrantLock(); private Condition conditionA = lock.newCondition(); private Condition conditionB = lock.newCondition(); private Condition conditionC = lock.newCondition(); private volatile int flag = 0; /** * 打印A */ public void printA()&#123; //获取锁 lock.lock(); try&#123; //如果flag不为0，就将当前线程等待 while(flag != 0)&#123; try &#123; conditionA.await(); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; &#125; //打印a System.out.println(&quot;A&quot;); //将flag设置为1 flag = 1; //唤醒B线程 conditionB.signal(); &#125;catch (Exception e)&#123; e.printStackTrace(); &#125;finally &#123; //释放锁 lock.unlock(); &#125; &#125; /** * 打印B */ public void printB()&#123; //获取锁 lock.lock(); try&#123; //如果flag不为1，就将当前线程等待 while(flag != 1)&#123; try &#123; conditionB.await(); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; &#125; //打印a System.out.println(&quot;B&quot;); //将flag设置为2 flag = 2; //唤醒C线程 conditionC.signal(); &#125;catch (Exception e)&#123; e.printStackTrace(); &#125;finally &#123; //释放锁 lock.unlock(); &#125; &#125; /** * 打印C */ public void printC()&#123; //获取锁 lock.lock(); try&#123; //如果flag不为2，就将当前线程等待 while(flag != 2)&#123; try &#123; conditionC.await(); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; &#125; //打印a System.out.println(&quot;C&quot;); //将flag设置为0 flag = 0; //唤醒C线程 conditionA.signal(); &#125;catch (Exception e)&#123; e.printStackTrace(); &#125;finally &#123; //释放锁 lock.unlock(); &#125; &#125;&#125; 5、总结这场面试我是非常看重的，但是因为当时家里断网，加上自己紧张，没有做出来，不说了，都是泪。归根到底就是一句话还是自己太菜，不找任何理由，继续加油吧。 6、后续第二天我又研究了一下我写错的代码，发现我只是用错了一个方法，就是将代码中的 signal() 修改为 signalAll() 即可，代码如下： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667public class Test &#123; public static void main(String[] args) &#123; //创建三个线程 MyThread a = new MyThread(&quot;A&quot;); MyThread b = new MyThread(&quot;B&quot;); MyThread c = new MyThread(&quot;C&quot;); //开启线程，按 C-&gt;B-&gt;A的顺序开启 c.start(); b.start(); a.start(); &#125;&#125;class MyThread extends Thread&#123; //创建锁 private static ReentrantLock lock = new ReentrantLock(); private static Condition condition = lock.newCondition(); //创建临时标识，用于表示当前执行那个线程 private static volatile int flag = 0; private String msg; public MyThread(String msg)&#123; this.msg = msg; &#125; public void run() &#123; lock.lock(); try &#123; while (true) &#123; //如果flag为0，并且是线程A if (flag == 0 &amp;&amp; &quot;A&quot;.equals(msg)) &#123; //打印A System.out.println(msg); //将flag设置为1 flag = 1; //唤醒其他线程，错误就在这里，只需修改为signalAll()就可以了 condition.signalAll(); break; &#125; else if (flag == 1 &amp;&amp; &quot;B&quot;.equals(msg)) &#123;//如果flag为1，并且是线程B //打印B System.out.println(msg); //将flag设置为2 flag = 2; //唤醒其他线程,这里也是一样 condition.signalAll(); break; &#125; else if (flag == 2 &amp;&amp; &quot;C&quot;.equals(msg)) &#123;//如果flag为2，并且是线程C //打印C System.out.println(msg); break; &#125; else &#123; //如果是其他情况就阻塞住当前线程 condition.await(); &#125; &#125; &#125; catch (Exception e) &#123; e.printStackTrace(); &#125; finally &#123; //释放锁 lock.unlock(); &#125; &#125;&#125;","categories":[{"name":"笔试题","slug":"笔试题","permalink":"https://blog.lee81.cn/categories/%E7%AC%94%E8%AF%95%E9%A2%98/"}],"tags":[{"name":"笔试题","slug":"笔试题","permalink":"https://blog.lee81.cn/tags/%E7%AC%94%E8%AF%95%E9%A2%98/"}]},{"title":"算法--插入排序","slug":"算法--插入排序","date":"2020-08-08T14:32:27.000Z","updated":"2022-08-13T12:29:03.594Z","comments":true,"path":"2020/08/08/算法--插入排序/","link":"","permalink":"https://blog.lee81.cn/2020/08/08/%E7%AE%97%E6%B3%95--%E6%8F%92%E5%85%A5%E6%8E%92%E5%BA%8F/","excerpt":"","text":"1、概述插入排序思想：对一个未排序的数组来说，将第一值当做已经被排好序的数组，然后从第二个值开始循环向前面排好序的数组进行比较插入。比较的顺序是从被排好序的数组的最后向前比较。 2、图解示例 观察可得： 对数组排序需要进行 length - 1 轮遍历，并且将数组第一个值当做已经排好序的数组，从第二个值开始进行插入。 每轮开始比较的位置为要插入的数据的下标 - 1。 进行插入时： 如果要插入的数据小于被比较的数据时，就将被比较的数据向后移一位，然后将被比较的下标 - 1，进行下轮的比较。 如果下标 - 1已经超过了0，那说明要插入的数据为最小值，即插入到第一位。 如果要插入的数据大于被比较的数据时，就将要插入的数据插入到被比较的数据后一位。 3、代码123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960package com.ld.algorithm.sort;import java.util.Arrays;/** * @author ld * @date 2020/8/8 22:38 * * 算法--插入排序 * * 对于一个未排序的数组来说，将第一值当做已经被排好序的数组，然后从第二个值开始循环向前面排好序的数组进行比较插入。 * 比较的顺序是从被排好序的数组的最后向前比较。 * */public class InsertSort &#123; public static void main(String[] args)&#123; //待排序的数组 int[] array = &#123;29,10,-3,90,3&#125;; System.out.println(&quot;排序前：&quot; + Arrays.toString(array)); //进行插入排序 int[] sortArray = sort(array); //排好序的数组 System.out.println(&quot;排序后：&quot; + Arrays.toString(sortArray)); &#125; /** * 进行插入排序，从小到大排序 * @param array 待排序的数组 * @return 返回排序后的数组 */ public static int[] sort(int[] array)&#123; //将第一值当做已经被排好序的数组，然后从第二个值开始循环向前面排好序的数组进行插入 for(int i = 1; i &lt; array.length; i++)&#123; //要插入的数据 int insertVal = array[i]; //定义被插入的数组的结束位置，也是比较的开始位置。即要插入的数据下标减一 int startIndex = i - 1; //循环判断当前被比较的下标有没有越界，并且判断插入的值是否小于要被比较的值， // 如果小于，就要将当前被比较的值向后移一位 while(startIndex &gt;= 0 &amp;&amp; insertVal &lt; array[startIndex])&#123; array[startIndex + 1] = array[startIndex]; //并且将被比较的下标向前移一位，进行下一轮的比较 startIndex--; &#125; //如果不满足上面的条件， //就表示插入的值大于被比较的值，所以要将插入的值插入到被比较的值后面。 //或者前面已经没有数据，将值插入到最前面。 array[startIndex + 1] = insertVal; &#125; return array; &#125;&#125;","categories":[{"name":"算法","slug":"算法","permalink":"https://blog.lee81.cn/categories/%E7%AE%97%E6%B3%95/"}],"tags":[{"name":"算法","slug":"算法","permalink":"https://blog.lee81.cn/tags/%E7%AE%97%E6%B3%95/"},{"name":"排序","slug":"排序","permalink":"https://blog.lee81.cn/tags/%E6%8E%92%E5%BA%8F/"}]},{"title":"算法--选择排序","slug":"算法--选择排序","date":"2020-08-06T13:15:20.000Z","updated":"2022-08-13T12:29:03.595Z","comments":true,"path":"2020/08/06/算法--选择排序/","link":"","permalink":"https://blog.lee81.cn/2020/08/06/%E7%AE%97%E6%B3%95--%E9%80%89%E6%8B%A9%E6%8E%92%E5%BA%8F/","excerpt":"","text":"1、概述选择排序思想：对一组长度为 n 的未排序的数据进行遍历，比较得出最小值和对应的下标，然后将最小值和下标为0的值进行交换，即将最小值放到最前面；然后再从下标为1的位置进行第二轮遍历，比较得出剩余数据中的最小值，并与下标为1的值进行交换；按照这种方式依次遍历，直到完成所有数据的排序。 2、图解示例 观察可得： 定义两个临时变量min和index，分别表示最小值和最小值的下标。并且每轮排序开始时，都将min和index的值重置为当前剩余未排序的起始值，然后依次向后遍历比较。 对数组排序需要进行 length - 1 轮遍历。 每轮遍历中的数据比较都在依次减少。 3、代码12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061package com.ld.algorithm.sort;import java.util.Arrays;/** * @author ld * @date 2020/8/6 21:30 * * 算法--选择排序 * 对一组长度为 n 的未排序的数据进行遍历，比较得出最小值和对应的下标，然后将最小值和下标为0的值进行交换，即将最小值放到最前面； * 然后再从下标为1的位置进行第二轮遍历，比较得出剩余数据中的最小值，并与下标为1的值进行交换； * 按照这种方式依次遍历，直到完成所有数据的排序。 * */public class SelectSort &#123; public static void main(String[] args) &#123; //测试数据 int[] array = &#123;23,1,90,-3,18&#125;; System.out.println(&quot;排序前：&quot; + Arrays.toString(array)); //进行选择排序 int[] sortArray = sort(array); System.out.println(&quot;排序后：&quot; + Arrays.toString(sortArray)); &#125; /** * 进行选择排序，以升序的方式排序 * @param array 待排序的数组 * @return 返回排序后的数组 */ public static int[] sort(int[] array)&#123; //标识要被交换的下标,初始默认为0 int minIndex = 0; //标识为最小值,初始默认为第一个值 int min = 0; for(int i = 0;i &lt; array.length - 1;i++)&#123; minIndex = i; min = array[i]; for(int j = i + 1; j &lt; array.length;j++)&#123; //判断当前值是否小于最小值 if(array[j] &lt; min)&#123; //将当前值赋值给min min = array[j]; //记录当前下标 minIndex = j; &#125; &#125; //交换值 if(minIndex != i)&#123; array[minIndex] = array[i]; array[i] = min; &#125; &#125; return array; &#125;&#125;","categories":[{"name":"算法","slug":"算法","permalink":"https://blog.lee81.cn/categories/%E7%AE%97%E6%B3%95/"}],"tags":[{"name":"算法","slug":"算法","permalink":"https://blog.lee81.cn/tags/%E7%AE%97%E6%B3%95/"},{"name":"排序","slug":"排序","permalink":"https://blog.lee81.cn/tags/%E6%8E%92%E5%BA%8F/"}]},{"title":"算法--冒泡排序","slug":"算法--冒泡排序","date":"2020-08-05T06:09:27.000Z","updated":"2022-08-13T12:29:03.593Z","comments":true,"path":"2020/08/05/算法--冒泡排序/","link":"","permalink":"https://blog.lee81.cn/2020/08/05/%E7%AE%97%E6%B3%95--%E5%86%92%E6%B3%A1%E6%8E%92%E5%BA%8F/","excerpt":"","text":"1、概述冒泡排序思想：对一组乱序的数据，从前向后依次比较相邻的俩个元素的值，如果前一个值大于后一个值就交换位置，最后就会将最大的值放到末尾；然后再从前向后开始进行第二轮的比较，将第二大的值排在倒数第二位。就这样循环下去，就会得到一组有序的数据。 2、图解示例 观察可得： 对数组排序需要进行 length - 1 轮遍历。 每轮遍历中的数据比较都在依次减少。 优化，当发现某一轮遍历中没有进行数据交换，即表示已经排好序，可以直接结束冒泡排序。 3、代码12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667package com.ld.algorithm.sort;import java.util.Arrays;/** * @author ld * @date 2020/8/5 16:26 * * 排序算法--冒泡排序 * * 冒泡排序思想： * 对一组乱序的数据，从前向后依次比较相邻的俩个元素的值，如果前一个值大于后一个值就交换位置，最后就会将最大的值放到末尾； * 然后再从前向后开始进行第二轮的比较，将第二大的值排在倒数第二位。 * 就这样循环下去，就会得到一组有序的数据。 */public class BubbleSort &#123; public static void main(String[] args)&#123; //测试数据 int[] array = &#123;4,1,7,-3&#125;; System.out.println(&quot;排序前的数据：&quot; + Arrays.toString(array)); //进行冒泡排序 int[] sortArray = sort(array); System.out.println(&quot;排序后的数据：&quot; + Arrays.toString(sortArray));&#125; /** * 进行冒泡排序 * @param array 要被排序的数据 * @return 返回排序后有序的数据 */ public static int[] sort(int[] array)&#123; //临时变量，用于交换数据时使用 int temp = 0; //用于优化冒泡排序，即如果一轮遍历中，没有进行交换，说明已经排好序 boolean flag = false; //本层循环表示要对array进行多少轮遍历 for(int i = 0;i &lt; array.length - 1;i++) &#123; //本层循环用于两两比较 for (int j = 0; j &lt; array.length - 1 - i; j++) &#123; //判断前一个值是否大于后一个值,如果大于就交换 if (array[j] &gt; array[j + 1]) &#123; //如果进行了交换，就设置为true flag = true; temp = array[j]; array[j] = array[j + 1]; array[j + 1] = temp; &#125; &#125; //判断一轮遍历后，是否进行了交换 if(!flag)&#123; //未交换，直接跳出循环 break; &#125;else&#123; //重置 flag = false; &#125; &#125; return array; &#125;&#125;","categories":[{"name":"算法","slug":"算法","permalink":"https://blog.lee81.cn/categories/%E7%AE%97%E6%B3%95/"}],"tags":[{"name":"算法","slug":"算法","permalink":"https://blog.lee81.cn/tags/%E7%AE%97%E6%B3%95/"},{"name":"排序","slug":"排序","permalink":"https://blog.lee81.cn/tags/%E6%8E%92%E5%BA%8F/"}]},{"title":"Kafka集群搭建","slug":"Kafka集群搭建","date":"2020-05-09T01:10:44.000Z","updated":"2022-08-13T12:29:03.573Z","comments":true,"path":"2020/05/09/Kafka集群搭建/","link":"","permalink":"https://blog.lee81.cn/2020/05/09/Kafka%E9%9B%86%E7%BE%A4%E6%90%AD%E5%BB%BA/","excerpt":"","text":"1、集群规划 IP地址 系统 环境 192.168.150.101 CentOS7 jdk8，Zookeeper 3.4.14 192.168.150.102 CentOS7 jdk8，Zookeeper 3.4.14 192.168.150.103 CentOS7 jdk8，Zookeeper 3.4.14 2、下载安装2.1、下载下载地址：http://kafka.apache.org/downloads 根据自己的需求，选择相对应的版本，我这是用的是kafka_2.11-1.1.1。 解释：kafka_2.11-1.1.1中有两个版本号，2.11表示Scala的版本号，1.1.1表示Kafka的版本号。 2.2、安装将下载好的压缩包，解压到自己指定的路径下，例如： 1tar -zxvf kafka_2.11-1.1.1.tgz -C /opt/module/ 3、配置文件参数说明进入到 config/ 目录下，里面有一个 server.properties 文件，这个就是 kafka 的配置文件。这里只介绍部分参数，其他参数请看 http://kafka.apache.org/documentation/#brokerconfigs 参数名 默认值 描述 broker.id -1 表示该节点在Kafka集群中broker的唯一标识。 listeners 无 表示broker 监听客户端连接的地址列表。配置格式为：protocol://hostname:port。其中protocol 表示协议类型，hostname表示主机名，port表示端口号。 log.dirs /tmp/kafka-logs 表示用来配置Kafka日志文件存放的根目录。并且可以配置多个根目录（以逗号分隔）。 num.partitions 1 表示主题的分区数。 log.retention.hours 168 表示日志文件的留存时间，单位为小时。 log.segment.bytes 1073741824 表示日志分段文件的最大值，超过这个值会强制创建一个新的日志分段。 zookeeper.connect 无 表示连接的Zookeeper集群地址，表示多个地址时用逗号分隔。并且可以配置chroot路径，即指定节点为根路径。例如：192.168.150.101:2181,192.168.150.102:2181, 192.168.150.103:2181/kafka zookeeper.connection.timeout.ms 6000 表示连接 Zookeeper 集群的超时时间。 delete.topic.enable true 表示是否开启删除主题。 4、修改配置4.1、修改配置文件修改以下参数： 1234broker.id=0listeners=PLAINTEXT://192.168.0.10:9092log.dirs=/data/kafka/datazookeeper.connect=192.168.150.101:2181,192.168.150.102:2181,192.168.150.103:2181/kafka 注意：这里只进行了简单的配置，请根据自己的业务需求进行修改。 4.2、创建数据目录根据配置文件中的 log.dirs 参数创建对应的目录。 5、配置其他机器根据上面的步骤在其他两台机器上进行配置。 注意：一定要根据不同服务器修改 broker.id 和 listeners 参数。 6、启动与关闭服务在根目录中有一个 /bin 文件夹，Kafka中所有的脚本工具都在这个目录下。 6.1、启动服务在 kafka 根目录下执行如下命令： 1bin/kafka-server-start.sh -daemon config/server.properties -daemon： 表示指定服务后台运行。 注意：在启动 kafka 集群之前，要先启动 Zookeeper 集群。 6.2、关闭服务在 kafka 根目录下执行如下命令： 1bin/kafka-server-stop.sh","categories":[{"name":"Kafka","slug":"Kafka","permalink":"https://blog.lee81.cn/categories/Kafka/"}],"tags":[{"name":"集群搭建","slug":"集群搭建","permalink":"https://blog.lee81.cn/tags/%E9%9B%86%E7%BE%A4%E6%90%AD%E5%BB%BA/"},{"name":"Kafka","slug":"Kafka","permalink":"https://blog.lee81.cn/tags/Kafka/"}]},{"title":"Zookeeper运维","slug":"Zookeeper运维","date":"2020-04-28T07:03:04.000Z","updated":"2022-08-13T12:29:03.592Z","comments":true,"path":"2020/04/28/Zookeeper运维/","link":"","permalink":"https://blog.lee81.cn/2020/04/28/Zookeeper%E8%BF%90%E7%BB%B4/","excerpt":"","text":"本篇文章摘自《从Paxos到Zookeeper分布式一致性原理与实践》 1、四字命令Zookeeper 中有很多4个英文字母长度的运维命令，简称为“四字命令”。 1.1、使用方式四字命令的使用方式非常简单，通常有两种方式。介绍如下： Telnet 方式 实例: 12345#连接telnet &lt;ip&gt; &lt;port&gt;#输入命令&lt;命令&gt; nc 方式 1echo &lt;命令&gt; | nc &lt;ip&gt; &lt;port&gt; 如果没有安装，请先进行安装 12345#root用户安装#下载安装包wget http://vault.centos.org/6.6/os/x86_64/Packages/nc-1.84-22.el6.x86_64.rpm#rpm安装rpm -iUv nc-1.84-22.el6.x86_64.rpm 1.2、命令介绍1.2.1、confconf 命令用于输出 Zookeeper 服务器运行时使用的基本配置信息。 1echo conf | nc localhost 2181 属性 说明 clientPort 对外暴漏的客户端连接端口号。 dataDir 数据快照文件目录，默认情况下100000次事务操作生成一次快照。 dataLogDir 事务日志文件目录，生产环境中放在独立的磁盘上。 tickTime 服务器之间或客户端与服务器之间维持心跳的时间间隔（以毫秒为单位）。 maxClientCnxns 最大连接数。 minSessionTimeout 最小session超时 minSessionTimeout=tickTime*2 maxSessionTimeout 最大session超时 maxSessionTimeout=tickTime*20 serverId 服务器编号。 initLimit 集群中的follower服务器(F)与leader服务器(L)之间初始连接时能容忍的最多心跳数。 syncLimit 集群中的follower服务器(F)与leader服务器(L)之间 请求和应答之间能容忍的最多心跳数。 electionAlg 0:基于UDP的LeaderElection 1:基于UDP的FastLeaderElection 2:基于UDP和认证的FastLeaderElection 3:基于TCP的FastLeaderElection 在3.4.10版本中，默认值为3另外三种算法已经被弃用，并且有计划在之后的版本中将它们彻底删除而不再支持。 electionPort 选举端口。 quorumPort 数据通信端口。 peerType 是否为观察者 1为观察者。 1.2.2、conscons命令用于输出当前这台服务器上所有客户端连接的详细信息。 1echo cons | nc localhost 2181 属性 说明 ip ip地址 port 端口号 queued 等待被处理的请求数，请求缓存在队列中 received 收到的包数 sent 发送的包数 sid 会话id lop 最后的操作 GETD-读取数据 DELE-删除数据 CREA-创建数据 est 连接时间戳 to 超时时间 lcxid 当前会话的操作id lzxid 最大事务id lresp 最后响应时间戳 llat 最后/最新 延时 minlat 最小延时 maxlat 最大延时 avglat 平均延时 1.2.3、crstcrst 命令是一个功能性命令，用于重置所有的客户端连接统计信息。 1echo crst | nc localhost 2181 1.2.4、dumpdump 命令用于输出当前集群的所有会话信息，包括这些会话的会话ID，以及每个会话创建的临时节点等信息。 1echo dump | nc localhost 2181 属性 说明 session id znode path（1对多，处于队列中排队的session和临时节点） 1.2.5、envienvi 命令用于输出 Zookeeper 所在服务器运行时的环境信息。 1echo envi | nc localhost 2181 属性 说明 zookeeper.version 版本 host.name host信息 java.version java版本 java.vendor 供应商 java.home 运行环境所在目录 java.class.path classpath java.library.path 第三方库指定非java类包的位置（如：dll，so） java.io.tmpdir 默认的临时文件路径 java.compiler JIT 编译器的名称 os.name Linux os.arch amd64 os.version 3.10.0-514.el7.x86_64 user.name zookeeper user.home 用户名目录 user.dir 服务所在目录 1.2.6、ruokruok 命令用于输出当前 Zookeeper 服务器是否正在运行。 1echo ruok | nc localhost 2181 如果当前 Zookeeper 服务器正在运行，那么返回 “imok” ，否则没有任何响应输出。 1.2.7、statstat 命令用于获取 Zookeeper 服务器的运行时状态信息。 1echo stat | nc localhost 2181 属性 说明 Zookeeper version 版本 Clients 客户端连接列表 Latency min/avg/max 延时 Received 收包 Sent 发包 Connections 连接数 Outstanding 堆积数 Zxid 最大事物id Mode 服务器角色 Node 节点数 1.2.8、srvrsrvr 命令和 stat 命令的功能一致，唯一的区别是 srvr 不会将客户端的连接情况输出，仅仅输出服务器的自身信息。 1.2.9、srstsrst 命令是一个功能行命令，用于重置所有服务器的统计信息。 1echo srst | nc localhost 2181 1.2.10、wchswchs 命令用于输出当前服务器上管理的 Watcher 的概要信息。 1echo wchs | nc localhost 2181 属性 说明 connectsions 连接数 watch-paths watch节点数 watchers watcher数量 1.2.11、wchcwchc 命令用于输出当前服务器上管理的 Watcher 的详细信息，以会话为单位进行归组，同时列出被该会话注册了 Watcher 的节点路径。 1echo wchc | nc localhost 2181 问题: 1wchc is not executed because it is not in the whitelist. 解决方法： 12345678910# 修改启动指令 zkServer.sh ​# 注意找到这个信息else echo &quot;JMX disabled by user request&quot; &gt;&amp;2 ZOOMAIN=&quot;org.apache.zookeeper.server.quorum.QuorumPeerMain&quot; fi​# 下面添加如下信息ZOOMAIN=&quot;-Dzookeeper.4lw.commands.whitelist=* $&#123;ZOOMAIN&#125;&quot; 1.2.12、wchpwchp 命令和 wchc 命令非常类似，也是用于输出当前服务器上管理的 Watcher 的详细信息，不同点在于 wchp 命令的输出信息以节点路径为单位进行归组。 1echo wchp | nc localhost 2181 1.2.13、mntrmntr 命令用于输出比 stat 命令更为详尽的服务器统计信息。 属性 说明 zk_version 版本 zk_avg_latency 平均延时 zk_max_latency 最大延时 zk_min_latency 最小延时 zk_packets_received 收包数 zk_packets_sent 发包数 zk_num_alive_connections 连接数 zk_outstanding_requests 堆积请求数 zk_server_state leader/follower 状态 zk_znode_count znode数量 zk_watch_count watch数量 zk_ephemerals_count 临时节点（znode） zk_approximate_data_size 数据大小 zk_open_file_descriptor_count 打开的文件描述符数量 zk_max_file_descriptor_count 最大文件描述符数量 zk_fsync_threshold_exceed_count 0 2、Zookeeper 图形化的客户端工具（ZooInspector）ZooInspector下载地址： 1https://issues.apache.org/jira/secure/attachment/12436620/ZooInspector.zip 解压后进入目录ZooInspector\\build，运行zookeeper-dev-ZooInspector.jar 12#执行命令如下java -jar zookeeper-dev-ZooInspector.jar 点击左上角连接按钮，输入zk服务地址：ip或者主机名:2181 点击OK，即可查看ZK节点信息 3、taoKeeper 监控工具基于zookeeper的监控管理工具taokeeper，由淘宝团队开源的zk管理中间件，安装前要求服务前先配置nc 和 sshd 1.下载数据库脚本 1wget https://github.com/downloads/alibaba/taokeeper/taokeeper.sql 2.下载主程序 1wget https://github.com/downloads/alibaba/taokeeper/taokeeper-monitor.tar.gz 3.下载配置文件 1wget https://github.com/downloads/alibaba/taokeeper/taokeeper-monitor-config.properties 4.配置 taokeeper-monitor-config.properties 123456789101112131415161718192021222324#DailysystemInfo.envName=DAILY#DBCPdbcp.driverClassName=com.mysql.jdbc.Driver#mysql连接的ip地址端口号dbcp.dbJDBCUrl=jdbc:mysql://localhost:3306/taokeeperdbcp.characterEncoding=GBK#用户名dbcp.username=root#密码dbcp.password=rootdbcp.maxActive=30dbcp.maxIdle=10dbcp.maxWait=10000#SystemConstant#用户存储内部数据的文件夹#创建/home/zookeeper/taokeeperdata/ZooKeeperClientThroughputStatSystemConstent.dataStoreBasePath=/home/zookeeper/taokeeperdata#ssh用户SystemConstant.userNameOfSSH=zookeeper#ssh密码SystemConstant.passwordOfSSH=zookeeper#OptionalSystemConstant.portOfSSH=22 5.安装配置 tomcat，修改catalina.sh 12#指向配置文件所在的位置JAVA_OPTS=-DconfigFilePath=&quot;/home/zookeeper/taokeeper-monitor-tomcat/webapps/ROOT/conf/taokeeper-monitor-config.properties&quot; 6.部署工程启动","categories":[{"name":"Zookeeper","slug":"Zookeeper","permalink":"https://blog.lee81.cn/categories/Zookeeper/"}],"tags":[{"name":"Zookeeper","slug":"Zookeeper","permalink":"https://blog.lee81.cn/tags/Zookeeper/"},{"name":"运维","slug":"运维","permalink":"https://blog.lee81.cn/tags/%E8%BF%90%E7%BB%B4/"}]},{"title":"Zookeeper一致性协议","slug":"Zookeeper一致性协议","date":"2020-04-26T03:35:26.000Z","updated":"2022-08-13T12:29:03.590Z","comments":true,"path":"2020/04/26/Zookeeper一致性协议/","link":"","permalink":"https://blog.lee81.cn/2020/04/26/Zookeeper%E4%B8%80%E8%87%B4%E6%80%A7%E5%8D%8F%E8%AE%AE/","excerpt":"","text":"本篇文章摘自《从Paxos到Zookeeper分布式一致性原理与实践》 1、前言随着PC机性能的不断提升和网络技术的快速普及，很多企业开始放弃原来的大型主机，而改用小型机和普通PC服务器来搭建分布式的计算机系统。其中最为典型的就是阿里巴巴集团的 “去 IOE” 运动。 在以前集中式的应用，我们很容易的能够实现一套满足ACID特性的事务处理系统，来保证数据的严格一致性。但在分布式的应用中，数据分散在各台不同的机器上，要想保证数据的严格一致性就很难了。因此出现了CAP和BASE这样的分布式系统经典理论。 1.1、ACID事务（Transaction）是由一系列对系统中数据进行访问与更新的操作所组成的一个程序执行逻辑单元（Unit）,狭义上的事务特指数据库事务。 事务包含四大特性，分别是原子性（Atomicity）、一致性（Consistency）、隔离性（Isolation）和持久性（Durability）。 1.1.1、原子性原子性是指事务必须是一个原子的操作序列单元。每一个事务的所有操作要么全部成功，要么全部失败。 1.1.2、一致性一致性是指事务的执行不能破环数据库数据的完整性和一致性。一个事务在执行之前和执行之后，数据库都必须处于一致性状态。 1.1.3、隔离性隔离性是指并发的事务是相互隔离的，一个事务的执行不能被其他事务干扰。 1.1.4、持久性持久性是指一个事务一旦提交，它对数据库中对应数据的状态变更就应该是永久性的。 1.2、CAP定理CAP定理是指一个分布式系统不可能同时满足一致性（C：Consistency）、可用性（A：Availability）和分区容错性（P：Partition tolerance）这三个基本需求，最多只能同时满足其中的两项。因为分布式系统中分区容错性是一定存在的，所以主要还是在一致性和可用性中进行权衡选择。 1.2.1、一致性在分布式环境中，一致性是指数据在多个副本之间是否能够保持一致的特性。在一致性的需求下，当一个系统在数据一致的状态下执行更新操作后，应该保证系统的数据仍然处于一致的状态。 对于一个将数据副本分布在不同分布式节点上的系统来说，如果对第一个节点的数据进行了更新操作并且更新成功后，却没有使得第二个节点上的数据得到相应的更新，于是在对第二个节点的数据进行读取操作时，获取的依然是老数据（或称为脏数据），这就是典型的分布式数据不一致情况。在分布式系统中，如果能够做到针对一个数据项的更新操作执行成功后，所有的用户都可以读取到其最新的值，那么这样的系统就被认为具有强一致性（或严格的一致性）。 1.2.2、可用性可用性是指系统提供的服务必须一直处于可用的状态，对于用户的每一个操作请求总是能够在有限的时间内返回结果。 1.2.3、分区容错性分区容错性约束了一个分布式系统需要具有如下特性：分布式系统在遇到任何网络分区故障的时候，仍然需要能够保证对外提供满足一致性和可用性的服务，除非是整个网络环境都发生了故障。 网络分区是指在分布式系统中，不同的节点分布在不同的子网络（机房或异地网络等）中，由于一些特殊的原因导致这些子网络之间出现网络不连通的状况，但各个子网络的内部网络是正常的，从而导致整个系统的网络环境被切分成了若干个孤立的区域。需要注意的是，组成一个分布式系统的每个节点的加入与退出都可以看作是一个特殊的网络分区。 1.3、BASE理论BASE理论是指 Basically Available（基本可用）、Soft state（软状态）和 Eventually consistent（最终一致性）三个短语的简写。是对 CAP 中一致性和可用性权衡的结果。是基于 CAP 定理逐步演化而来的，其核心思想是即使无法做到强一致性，但每个应用都可以根据自身的业务特点，采用适当的方式来使系统达到最终一致性。 1.3.1、基本可用基本可用是指分布式系统在出现不可预知故障的时候，允许损失部分可用性——但请注意，这绝不等价于系统不可用。 1.3.2、弱状态弱状态也称为软状态，和硬状态相对，是指允许系统中的数据存在中间状态，并认为该中间状态的存在不会影响系统的整体可用性，即允许系统在不同节点的数据副本之间进行数据同步的过程存在延时。 1.3.3、最终一致性最终一致性强调的是系统中所有的数据副本，在经过一段时间的同步后，最终能够达到一个一致的状态。因此，最终一致性的本质是需要系统保证最终数据能够达到一致，而不需要实时保证系统数据的强一致性。 2、一致性协议和算法为了解决分布式一致性问题，在长期的探索研究过程中，涌现出了一大批经典的一致性协议和算法，其中最著名的就是二阶段提交协议、三阶段提交协议和Paxos算法。 2.1、2PC协议2PC，是 Two-Phase Commit 的缩写，即二阶段提交，是计算机网络尤其是在数据库领域内，为了使基于分布式系统架构下的所有节点在进行事务处理过程中能够保持原子性和一致性而设计的一种算法。 2.1.1、协议说明二阶段提交协议是将事务的提交过程分成了两个阶段来进行处理。在讲述流程之前先介绍两个概念： 协调者：用来统一调度所有分布式节点的执行逻辑。 参与者：被调度的分布式节点。 其执行流程如下： 阶段一：提交事务请求（投票阶段） 分发事务 协调者向所有的参与者发送事务内容，询问是否可以执行事务提交操作，并开始等待各参与者的响应。 执行事务 各参与者节点执行事务操作，并将Undo 和 Redo 信息记入事务日志中。 反馈响应 如果参与者成功执行了事务操作，那么就反馈给协调者 Yes 响应，表示事务可以执行； 如果参与者没有成功执行事务，那么就反馈给协调者 No 响应，表示事务不可以执行。 阶段二：执行事务请求（执行阶段） 协调者根据各参与者的反馈情况来决定最终是否可以进行事务提交操作，正常情况下，包含以下两种可能。 提交事务 ​ 假如协调者从所有的参与者获得的反馈都是 Yes 响应，那么就会执行事务提交。 发送提交请求 协调者向所有参与者节点发出 Commit 请求。 事务提交 参与者接收到 Commit 请求后，会正式执行事务提交操作，并在完成提交之后释放在整个事务执行期间占用的事务资源。 反馈事务提交结果 参与者在完成事务提交之后，向协调者发送Ack消息。 完成事务 协调者接收到所有参与者反馈的 Ack 消息后，完成事务。 中断事务 ​ 假如任何一个参与者向协调者反馈了 No 响应，或者在等待超时之后，协调者尚无法接收到所有参与者的反馈响应，那么就会中断事务。 发送回滚请求 协调者向所有参与者节点发出 Rollback 请求。 事务回滚 参与者接收到 Rollback 请求后，会利用其在阶段一中记录的 Undo 信息来执行事务回滚操作，并在完成回滚之后释放在整个事务执行期间占用的资源。 反馈事务回滚结果 参与者在完成事务回滚之后，向协调者发送 Ack 消息。 中断事务 协调者接收到所有参与者反馈的 Ack 消息后，完成事务中断。 2.1.2、优缺点优点： 原理简单 实现方便 缺点： 同步阻塞 二阶段提交协议存在的最明显也是最大的一个问题就是同步阻塞，这会极大地限制分布式系统的性能。在二阶段提交的执行过程中，所有参与该事务操作的逻辑都处于阻塞状态，也就是说，各个参与者在等待其他参与者响应的过程中，将无法进行其他任何操作。 单点问题 在二阶段提交中，一旦协调者出现问题，那么整个二阶段提交流程将无法运转，更为严重的是，如果协调者是在阶段二中出现问题的话，那么其他参与者将会一直处于锁定事务资源的状态中，而无法继续完成事务操作。 数据不一致 在二阶段提交协议的阶段二，即执行事务提交的时候，当协调者向所有的参与者发送Commit 请求之后，发生了局部网络异常或者是协调者在尚未发送完 Commit 请求之前自身发生了崩溃，导致最终只有部分参与者收到了 Commit 请求。于是，这部分收到了 Commit 请求的参与者就会进行事务的提交，而其他没有收到 Commit 请求的参与者则无法进行事务提交，于是整个分布式系统便出现了数据不一致性现象。 太过保守 二阶段提交协议没有设计较为完善的容错机制，任意一个节点的失败都会导致整个事务的失败。 2.2、3PC协议2.2.1、协议说明3PC，是 Three-Phase Commit 的缩写，即三阶段提交，是 2PC 的改进版，其将二阶段提交协议的“提交事务请求”过程一分为二，形成了由 CanCommit、PreCommit 和 DoCommit 三个阶段组成的事务处理协议。其执行流程如下： 阶段一：CanCommit 事务询问 协调者向所有的参与者发送一个包含事务内容的 CanCommit 请求，询问是否可以执行事务提交操作，并开始等待各参与者的响应。 反馈响应 参与者在接收到来自协调者的 CanCommit 请求后，正常情况下，如果其自身认为可以顺利执行事务，那么会反馈 Yes 响应，并进入预备状态，否则反馈 No 响应。 阶段二：PreCommit 协调者会根据各参与者的反馈情况来决定是否可以进行事务的 PreCommit 操作，正常情况下，包含两种可能。 执行事务预提交 ​ 假如协调者从所有的参与者获得的反馈都是 Yes 响应，那么就会执行事务预提交。 发送预提交请求 协调者向所有参与者节点发出 PreCommit 的请求，并进入 Prepared 阶段。 事务预提交 参与者接收到 PreCommit 请求后，会执行事务操作，并将 Undo 和 Redo 信息记录到事务日志中。 反馈响应 如果参与者成功执行了事务操作，那么就会反馈给协调者 Ack 响应，同时等待最终的指令：提交 （commit）或中止（abort）。 中断事务 ​ 假如任何一个参与者向协调者反馈了No 响应，或者在等待超时之后，协调者尚无法接收到所有参与者的反馈响应，那么就会中断事务。 发送中断请求 协调者向所有参与者节点发出 abort 请求。 中断事务 无论是收到来自协调者的 abort 请求，或者是在等待协调者请求过程中出现超时，参与者都会中断事务。 阶段三：DoCommit 该阶段将进行真正的事务提交，会存在以下两种可能的情况。 执行提交 发送提交请求 进入这一阶段，假设协调者处于正常工作状态，并且它接收到了来自所有参与者的 Ack 响应，那么它将从 “预提交” 状态转换到 “提交” 状态，并向所有的参与者发送 doCommit 请求。 事务提交 参与者接收到 doCommit 请求后，会正式执行事务提交操作，并在完成提交之后释放在整个事务执行期间占用的事务资源。 反馈事务提交结果 参与者在完成事务提交之后，向协调者发送 Ack 消息。 完成事务 协调者接收到所有参与者反馈的 Ack 消息后，完成事务。 中断事务 ​ 进入这一阶段，假设协调者处于正常工作状态，并且有任意一个参与者向协调者反馈了No 响应，或者在等待超时之后，协调者尚无法接收到所有参与者的反馈响应，那么就会中断事务。 发送中断请求 协调者向所有的参与者节点发送 abort 请求。 事务回滚 参与者接收到 abort 请求后，会利用其在阶段二中记录的 Undo 信息来执行事务回滚操作，并在完成回滚之后释放在整个事务执行期间占用的资源。 反馈事务回滚结果 参与者在完成事务回滚之后，向协调者发送 Ack 消息。 中断事务 协调者接收到所有参与者反馈的 Ack 消息后，中断事务。 注意：阶段三可能会存在以下两种故障 协调者出现问题。 协调者和参与者之间的网络出现故障。 无论出现哪种情况，最终都会导致参与者无法及时接收到来自协调者的 doCommit 或是 abort 请求，针对这样的异常情况，参与者都会在等待超时之后，继续进行事务提交。 2.2.2、优缺点优点： 相较于二阶段提交，三阶段提交降低了参与者的阻塞范围。 能够在出现单点故障后继续达成一致。 缺点： 数据不一致 在参与者接收到 preCommit 消息后，如果网络出现分区，此时协调者所在的节点和参与者无法进行正常的网络通信，在这种情况下，该参与者依然会进行事务的提交，这必然出现数据的不一致性。 2.3、Paxos算法Paxos 算法是一种基于消息传递且具有高度容错特性的一致性算法。是目前公认的解决分布式一致性问题最有效的算法之一。（这里不介绍Paxos算法，后面会写一篇文章专题讲讲Paxos算法） 3、ZAB（Zookeeper Atomic Broadcast）协议ZAB协议是为分布式协调服务Zookeeper专门设计的一种支持崩溃恢复的原子广播协议。基于该协议，Zookeeper实现了一种主备模式的系统架构来保持集群中各副本之间数据的一致性。 3.1、核心处理过程所有事务请求必须由一个全局唯一的服务器来协调处理，这样的服务器被称为 Leader 服务器，而余下的其他服务器则成为 Follower 服务器。 Leader 服务器负责将一个客户端事务请求转换成一个事务 Proposal（提议），并将该 Proposal 分发给集群中所有的 Follower 服务器。之后 Leader 服务器需要等待所有 Follower 服务器的反馈，一旦超过半数的 Follower 服务器进行了正确的反馈后，那么 Leader 就会再次向所有的 Follower 服务器分发 Commit 消息，要求其将前一个 Proposal 进行提交。 3.2、协议介绍ZAB协议包括两种基本的模式，分别是崩溃恢复和消息广播。当整个服务框架在启动过程中，或是当 Leader 服务器出现网络中断，崩溃退出与重启等异常情况时，ZAB 协议就会进入恢复模式并选举产生新的 Leader 服务器。当选举产生了新的 Leader 服务器，同时集群中已经有过半的机器与该 Leader 服务器完成了状态同步（数据同步）之后，ZAB 协议就会退出恢复模式，进入消息广播模式。Leader 服务器在接收到客户端的事务请求后，会生成对应的事务提案并发起一轮广播协议；而如果集群中的其他机器接收到客户端的写事务请求，那么这些非 Leader 服务器会首先将这个事务请求转发给 Leader 服务器。如果新加入了一台服务器，此服务器就会进入数据恢复模式，找到Leader 所在的服务器，并与其进行数据同步，然后一起参与到消息广播流程中去。 3.2.1、崩溃恢复模式当整个服务器框架启动过程中，或是当 Leader 服务器出现崩溃，或者说由于网络原因导致 Leader 服务器失去了与过半 Follower 的联系，那么就会进入崩溃恢复模式。（说白了崩溃恢复模式就是选举新的 Leader，完成数据同步） 在崩溃恢复过程中可能会出现两个数据不一致性的问题： ZAB 协议需要确保那些已经在 Leader服务器上提交的事务最终被所有服务器都提交。 假设一个事务在 Leader 服务器上被提交了，并且已经得到过半的 Follower 服务器的 Ack 反馈，但是在它将 Commit 消息发送给所有 Follower 机器之前，Leader 服务器挂了。针对这种情况， ZAB 协议就需要确保事务最终能够在所有的服务器上都被提交成功，否则将出现不一致。 ZAB 协议需要确保丢弃那些只在 Leader 服务器上被提出的事务。 假设在 Leader 服务器上 Server1 提出了一个事务之后就崩溃退出了，从而导致集群中的其他服务器都没有收到这个事务。于是，当 Server1 恢复过来再次加入到集群中的时候，ZAB 协议需要确保丢弃这个事务。 对于上面提出的问题，决定了 ZAB 协议必须设计这样一个 Leader 选举算法：能够确保提交已经被 Leader 提交的事务 Proposal，同时丢弃已经被跳过的事务 Proposal。针对这个要求，如果让 Leader 选举算法能够保证新选举出来的 Leader 服务器拥有集群中所有机器最高编号（即 ZXID 最大）的事务 Proposal，那么就可以保证这个新选举出来的 Leader 一定具有所有已经提交的提案。更为重要的是如果让具有最高编号事务 Proposal 的机器来成为 Leader ，就可以省去 Leader 服务器检查 Proposal 的提交和丢弃工作的这一步操作了。（Leader选举过程请看 《Zookeeper深入原理》） 在完成 Leader 选举之后，正式开始工作之前，还需要确认事务日志中的所有 Proposal 是否都已经被集群中过半的机器提交了，即是否完成了数据同步。 下面介绍一下数据同步过程： Leader服务器会为每一个 Follower服务器都准备一个队列，并将那些没有被各 Follower 服务器同步的事务以 Proposal 消息的形式逐个发送给 Follower 服务器，并在每一个 Proposal 消息后面紧接着再发送一个 Commit 消息，以表示该事务已经被提交。等到 Follower 服务器将所有其尚未同步的事务 Proposal 都从 Leader 服务器上同步过来并成功应用到本地数据库中后，Leader 服务器就会将该 Follower 服务器加入到真正的可用 Follower 列表中。 3.2.2、消息广播模式ZAB 协议的消息广播过程使用的是一个原子广播协议，类似于一个二阶段提交的过程。但是 ZAB 协议与二阶段提交略有不同。在 ZAB 协议的二阶段提交过程中，移除了中断逻辑，所有的 Follower 服务器要么正常反馈 Leader 提出的事务 Proposal，要么就抛弃 Leader 服务器。同时 ZAB 协议支持半数原则，即超过半数的 Follower 服务器反馈 Ack 之后就开始提交事务 Proposal 了，而不需要等待集群中所有的 Follower 服务器都反馈响应。 因为这种简化的二阶段提交模型下，是无法处理 Leader 服务器崩溃退出而带来的数据不一致问题的，因此在ZAB 协议中添加了崩溃恢复模式来解决这种问题。 在消息广播过程中，Leader 服务器会为每一个事务请求生成对应的 Proposal 来进行广播，并且在广播事务 Proposal 之前，Leader 服务器会首先为这个事务 Proposal 分配一个全局单调递增的唯一ID（即 ZXID），Leader服务器会为每一个 Follower 服务器都各自分配一个单独的队列，然后将需要广播的事务 Proposal 依次放入这些队列中去，并且根据 FIFO 策略进行消息发送。每一个 Follower 服务器在接收到这个事务 Proposal 之后，都会首先将其以事务日志的形式写入到本地磁盘中去，并且在成功写入后反馈给 Leader 服务器一个 Ack 响应。当 Leader 服务器接收到超过半数 Follower 的 Ack 响应后，就会广播一个 Commit 消息给所有的 Follower 服务器以通知其进行事务提交，同时 Leader 自身也会完成对事务的提交，而每一个 Follower 服务器在接收到 Commit 消息后，也会完成对事务的提交。 3.3、协议说明整个 ZAB 协议主要包括消息广播和崩溃恢复两个过程，进一步可以细分为三个阶段，分别是发现（Discovery）、同步（Synchronization）和广播（Broadcast）阶段。 阶段一：发现 主要就是 Leader 选举过程，用于在多个分布式进程中选举出主进程。 阶段二：同步 在完成发现流程之后，就进入了同步阶段。即 Leader 服务器和 Follower 服务器之间同步数据。 阶段三：广播 完成同步阶段之后，ZAB 协议就可以正式开始接收客户端新的事物请求，并进行消息广播流程。","categories":[{"name":"Zookeeper","slug":"Zookeeper","permalink":"https://blog.lee81.cn/categories/Zookeeper/"}],"tags":[{"name":"Zookeeper","slug":"Zookeeper","permalink":"https://blog.lee81.cn/tags/Zookeeper/"},{"name":"一致性协议","slug":"一致性协议","permalink":"https://blog.lee81.cn/tags/%E4%B8%80%E8%87%B4%E6%80%A7%E5%8D%8F%E8%AE%AE/"}]},{"title":"Zookeeper使用场景","slug":"Zookeeper使用场景","date":"2020-04-25T02:57:22.000Z","updated":"2022-08-13T12:29:03.590Z","comments":true,"path":"2020/04/25/Zookeeper使用场景/","link":"","permalink":"https://blog.lee81.cn/2020/04/25/Zookeeper%E4%BD%BF%E7%94%A8%E5%9C%BA%E6%99%AF/","excerpt":"","text":"学 Zookeeper 就是为了用它，接下来我就介绍以下常用的使用场景。 1、数据发布/订阅1.1、介绍数据发布/订阅，顾名思义就是发布者将数据发布到 Zookeeper 上，然后供订阅者进行数据订阅和监控，进而实现动态改变和获取数据的目的。 1.2、示例需求：当我们部署集群时，需要重复修改每个节点的配置信息，节点少的时候还好，如果多了，并且需要修改频繁的时候就会很浪费时间。此时以数据库连接信息为例，连接信息包括：IP地址，端口号，用户名，密码，数据库名称。 解决： 为解决上述需求，我们可以引入 Zookeeper 作为配置中心，将所有的配置信息都发布到 Zookeeper 上，然后供集群所有节点进行数据订阅和监控，当需要修改配置时，只需修改 Zookeeper 上的数据，就可以触发所有节点进行修改。 设计思路如下： 创建一个永久节点（mysql）表示为数据库连接信息。 在 mysql 节点下创建多个子节点，表示IP地址，端口号，用户名，密码，数据库名称。 所有的客户端都获取 mysql 节点下的子节点信息，并注册监控事件。 当数据库连接信息有变化时，所有客户端都能被触发，重新执行步骤3。 2、Master选举2.1、介绍Master 选举就是从集群中选出一个所谓的 “老大”，这里称之为 Master，Master 往往用来协调集群中其他系统单元，具有对分布式系统状态变更的决定权。 2.2、示例需求：需要从集群选出一个节点作为主节点 (Master)，来处理工作，其他节点作为从节点，当主节点挂掉时，其他节点接着竞选主节点。 解决： 为解决上述需求，我们可以引入 Zookeeper 服务，通过所有节点竞争创建同一个节点（Master），创建成功的为主节点，其他节点只能监控 Master 节点，当 Master 节点被删除时，接着去竞争创建。 设计思路如下： 创建一个永久节点（App1）表示为App1集群。 集群中的所有节点都竞争创建名为 Master 的临时节点（这里设计为临时节点的原因是当主节点宕机时，临时节点也就跟着被删除了）。 创建成功 Master 节点的集群节点就是主节点，处理功能，当然还可以将主节点的一些本地信息存储到 Master 节点中，供监控系统展示主节点信息。 其他集群节点就对 Master 节点注册监控。 当Master 节点删除时，其他节点都收到通知，重新执行步骤2。 3、分布式锁3.1、介绍分布式锁是控制分布式系统之间同步访问共享资源的一种方式。比如你的项目为单体应用是，就可以使用Synchronize 或者 Lock 锁来实现同步访问共享资源。但是如果是分布式应用，多个应用之间如果想同步访问共享资源时 Synchronize 和 Lock 就不管用了，所以就提出了分布式锁的概念。现在实现分布式锁的方式有很多种，比如：Redis，数据库，Zookeeper。这里只说 Zookeeper 实现分布式锁的思路。 3.2、示例需求：当一个分布式系统中，需要同步访问共享某一个资源时，怎么才能防止并发问题呢？ 解决：如果理解了上面的 Master 选举的思想，应该就明白 Zookeeper 怎么实现分布式锁了（创建指定节点，创建成功的线程就是获取到锁）。但是如果使用上面的方式实现的话有一个问题，如果现在有成千上百个线程同时获取分布式锁时，就会出现羊群效应。 羊群效应：当并发量比较高时，当线程释放锁时，其他所有的线程都需要抢占锁（即创建锁节点），就会出现大量的创建请求，所以就出现了羊群效应。如何解决羊群效应呢？请看下图： 设计思路如下： 当线程需要获取锁时，就创建一个节点路径为 lock 的临时有序节点（使用临时节点是为了防止死锁的问题）。 获取 /MyLock 的子节点列表。 判断自己创建的节点是否为第一个。 如果是第一个，说明获取到了锁，执行业务代码。 如果不是第一个，就对自己的前一个节点注册监控，当前一个节点删除时，就重新执行步骤2。 当执行完业务代码时，删除自己创建的节点。 这样每次释放锁，就不会让其他所有线程都去抢占锁，只需要让下一个节点去抢占锁就可以了。避免了羊群效应。 注意：上面讲述的是排他锁，只有一个线程能获取到锁。如果想实现读写锁，该怎么进行变形呢？自己可以尝试思考一下。 4、分布式唯一性ID4.1、介绍在过去的单库单表型系统中，通常可以使用数据库字段自带的auto_increment属性来自动为每条记录生成一个唯一的ID。但是分库分表后，就无法在依靠数据库的auto_increment属性来唯一标识一条记录了。此时我们就可以用zookeeper在分布式环境下生成全局唯一ID。 4.2、示例 设计思路如下： 当需要生成唯一性ID 时，就在 /MyID 节点下创建一个节点路径为 id 的持久有序节点。 获取创建后的节点路径。 将节点路径的前缀 id 截取，留下的就是唯一性 ID。 然后删除比自己小的节点。 也可以使用 /MyID 中的版本号来实现 唯一性 ID。","categories":[{"name":"Zookeeper","slug":"Zookeeper","permalink":"https://blog.lee81.cn/categories/Zookeeper/"}],"tags":[{"name":"Zookeeper","slug":"Zookeeper","permalink":"https://blog.lee81.cn/tags/Zookeeper/"},{"name":"使用场景","slug":"使用场景","permalink":"https://blog.lee81.cn/tags/%E4%BD%BF%E7%94%A8%E5%9C%BA%E6%99%AF/"}]},{"title":"Zookeeper深入原理","slug":"Zookeeper深入原理","date":"2020-04-18T06:50:30.000Z","updated":"2022-08-13T12:29:03.592Z","comments":true,"path":"2020/04/18/Zookeeper深入原理/","link":"","permalink":"https://blog.lee81.cn/2020/04/18/Zookeeper%E6%B7%B1%E5%85%A5%E5%8E%9F%E7%90%86/","excerpt":"","text":"本篇文章摘自《从Paxos到Zookeeper分布式一致性原理与实践》 1、系统模型1.1、数据模型Zookeeper 的视图结构是一个树形结构，树上的每个节点称之为数据节点（即 ZNode），每个ZNode 上都可以保存数据，同时还可以挂载子节点。并且Zookeeper的根节点为 “/“。 1.2、节点类型在 Zookeeper 中，每个数据节点都是有生命周期的，其生命周期的长短取决于数据节点的节点类型。在 Zookeeper 中有如下几类节点： 节点类型 说明 持久节点（PERSISTENT） 指该数据节点被创建后，就会一直存在于 Zookeeper 服务器上，直到有删除操作来主动清除这个节点。 持久顺序节点（PERSISTENT_SEQUENTIAL） 基本特性和持久节点是一致的，额外的特性表现在顺序性上，在 Zookeeper 中，每个父节点都会为它的第一级子节点维护一份顺序，用于记录下每个子节点创建的先后顺序。基于这个顺序特性，在创建子节点的时候，可以设置这个标记，那么在创建节点过程中，Zookeeper 会自动为给定节点名加上一个数字后缀，作为一个新的、完整的节点名。另外需要注意的是，这个数字后缀的上限是整型的最大值。 临时节点（EPHEMERAL） 临时节点的生命周期和客户端的会话绑定在一起，如果客户端会话失效，那么这个节点就会被自动清理掉。另外，Zookeeper 规定了不能基于临时节点来创建子节点，即临时节点只能作为叶子节点。 临时顺序节点（EPHEMERAL_SEQUENTIAL） 基本特性和临时节点一致，只是添加了顺序的特性。 1.3、状态信息每个数据节点中除了存储了数据内容之外，还存储了数据节点本身的一些状态信息（State）。 状态属性 说明 cZxid 即 Create ZXID，表示该数据节点被创建时的事务ID。 ctime 即 Create Time，表示该数据节点被创建的时间。 mZxid 即 Modified ZXID，表示该节点最后一次被更新时的事务ID。 mtime 即 Modified Time，表示该数据节点最后一次被更新的时间。 pZxid 表示该节点的子节点列表最后一次被修改时的事务ID。注意，只有子节点列表变更了才会变更 pZxid，子节点内容变更不会影响pZxid。 cversion 表示子节点的版本号。 dataVersion 表示数据节点的版本号。 aclVersion 表示节点的 ACL 版本号。 ephemeralOwner 创建该临时节点的会话的sessionID。如果该节点是持久节点，那么这个属性值为0。 dataLength 表示数据内容的长度。 numChildren 表示当前节点的子节点个数。 1.4、ZXID在Zookeeper 中，事务是指能够改变 Zookeeper 服务器状态的操作，我们也称之为事务操作或更新操作，一般包括数据节点创建与删除、数据节点内容更新和客户端会话创建与失效等操作。对于每一个事务请求，Zookeeper 都会为其分配一个全局唯一的事务ID，用 ZXID 来表示，通常是一个 64 位的数字。每一个 ZXID 对应一次更新操作，从这些 ZXID 中可以间接地识别出 Zookeeper 处理这些更新操作请求的全局顺序。 ZXID 是一个 64 位的数字，其中低 32 位可以看作是一个简单的单调递增的计数器，针对客户端的每一个事务请求，Leader 服务器在产生一个新的事务 Proposal 的时候，都会对该计数器进行加 1 操作；而高 32 位则代表了 Leader 周期 epoch 的编号，每当选举产生一个新的 Leader 服务器，就会从这个 Leader 服务器上取出其本地日志中最大事务 Proposal 的 ZXID，并从该 ZXID 中解析出对应的 epoch 值，然后再对其进行加 1 操作，之后就会以此编号作为新的 epoch，并将低 32 位置 0 来开始生成新的 ZXID。 1.5、版本 Zookeeper 中为数据节点引入了版本的概念，每个数据节点都具有三种类型的版本信息（在上面的状态信息中已经介绍了三种版本信息代表的意思），对数据节点的任何更新操作都会引起版本号的变化。其中我们以 dataVersion 为例来说明。在一个数据节点被创建完毕之后，节点的dataVersion 值是 0，表示的含义是 ”当前节点自从创建之后，被更新过 0 次“。如果现在对该节点的数据内容进行更新操作，那么随后，dataVersion 的值就会变成 1。即表示的是对数据节点的数据内容的变更次数。 版本的作用是用来实现乐观锁机制中的 “写入校验” 的。例如，当要修改数据节点的数据内容时，带上版本号，如果数据节点的版本号与传入的版本号相等，就进行修改，否则修改失败。 1.6、Watcher1.6.1、概述Zookeeper 提供了分布式数据的发布/订阅功能。一个典型的发布/订阅模型系统定义了一种一对多的订阅关系，能够让多个订阅者同时监听某一个主题对象，当这个主题对象自身状态变化时，会通知所有订阅者，使它们能够做出相应的处理。在 Zookeeper 中，引入了 Watcher 机制来实现这种分布式的通知功能。Zookeeper 允许客户端向服务端注册一个 Watcher 监听，当服务端的一些指定事件触发了这个 Watcher，那么就会向指定客户端发送一个事件通知来实现分布式的通知功能。 从上图可以看出 Zookeeper 的 Watcher 机制主要包括客户端线程、客户端WatchMananger 和 Zookeeper 服务器三部分。在具体工作流程上，简单地讲，客户端在向 Zookeeper 服务器注册 Watcher 的同时，会将 Watcher 对象存储在客户端的 WatchMananger 中。当 Zookeeper 服务器端触发 Watcher 事件后，会向客户端发送通知，客户端线程从 WatchManager 中取出对应的 Watcher 对象来执行回调逻辑。 1.6.2、Watcher特性 一次性：表示无论是服务端还是客户端，一旦一个 Watcher 被触发，Zookeeper 都会将其从相应的存储中移除。因此，开发人员在 Watcher 的使用上要记住的一点是需要反复注册。 客户端串行执行：客户端 Watcher 回调的过程是一个串行同步的过程，这为我们保证了顺序，同时，需要开发人员注意的一点是，千万不要因为一个 Watcher 的处理逻辑影响了整个客户端的 Watcher 回调。 轻量：WatchedEvent 是 Zookeeper 整个 Watcher 通知机制的最小通知单元，这个数据结构中只包含三部分内容：通知状态、事件类型和节点路径。也就是说，Watcher通知非常简单，只会告诉客户端发生了事件，而不会说明事件的具体内容。 1.6.3、watcher接口设计Watcher是一个接口，任何实现了Watcher接口的类就是一个新的Watcher。Watcher内部包含了两个枚举类：KeeperState、EventType Watcher通知状态(KeeperState) KeeperState是客户端与服务端连接状态发生变化时对应的通知类型。路径为org.apache.zookeeper.Watcher.Event.KeeperState，是一个枚举类，其枚举属性如下： 枚举属性 说明 SyncConnected 客户端与服务器正常连接时 Disconnected 客户端与服务器断开连接时 Expired 会话session失效时 AuthFailed 身份认证失败时 Watcher事件类型(EventType) EventType是数据节点(znode)发生变化时对应的通知类型。EventType变化时KeeperState永远处于SyncConnected通知状态下；当KeeperState发生变化时，EventType永远为None。其路径为org.apache.zookeeper.Watcher.Event.EventType，是一个枚举类，枚举属性如下： 枚举属性 说明 None 无 NodeCreated Watcher监听的数据节点被创建时 NodeDeleted Watcher监听的数据节点被删除时 NodeDataChanged Watcher监听的数据节点内容发生变更时(无论内容数据是否变化) NodeChildrenChanged Watcher监听的数据节点的子节点列表发生变更时 注：客户端接收到的相关事件通知中只包含状态及类型等信息，不包括节点变化前后的具体内容，变化前的数据需业务自身存储，变化后的数据需调用get等方法重新获取； 1.6.4、捕获相应的事件上面讲到zookeeper客户端连接的状态和zookeeper对znode节点监听的事件类型，下面我们来讲解如何建立zookeeper的watcher监听。在zookeeper中采用zk.getChildren(path, watch)、zk.exists(path, watch)、zk.getData(path, watcher, stat)这样的方式为某个znode注册监听。 下表以node-x节点为例，说明调用的注册方法和可监听事件间的关系： 注册方式 Created ChildrenChanged Changed Deleted zk.exists(“/node-x”,watcher) 可监控 可监控 可监控 zk.getData(“/node-x”,watcher) 可监控 可监控 zk.getChildren(“/node-x”,watcher) 可监控 可监控 1.7、ACLZookeeper 中提供了一套完善的 ACL（Access Control List）权限控制机制来保障数据的安全。 1.7.1、概述ACL 由三部分组成，分别是：权限模式（Scheme）、授权对象（ID）和权限（Permission），通常使用“scheme: ​id:permission”来标识一个有效的ACL 信息。下面分别介绍： 权限模式（Scheme） 方案 说明 world 只有一个用户：anyone，代表登录 Zookeeper 所有人（默认） ip 对客户端使用IP地址认证。 auth 使用已添加认证的用户认证。 digest 使用“用户名:密码”方式认证。 授权对象（ID） 授权对象ID是指，权限赋予的实体，例如：IP 地址或用户。 权限（Permission） 权限 ACL简写 描述 create c 可以创建子节点。 delete d 可以删除子节点（仅下一级节点）。 read r 可以读取节点数据或子节点列表。 write w 可以对节点进行更新操作。 admin a 可以设置节点访问控制列表权限。 1.7.2、特性 zooKeeper的权限控制是基于每个znode节点的，需要对每个节点设置权限。 每个znode支持设置多种权限控制方案和多个权限。 子节点不会继承父节点的权限，客户端无权访问某节点，但可能可以访问它的子节点。 1.7.3、案例 world授权模式 命令 1setAcl &lt;path&gt; world:anyone:&lt;acl&gt; 案例 1234567891011121314151617[zk: localhost:2181(CONNECTED) 0] create /node1 &quot;node1&quot;Created /node1[zk: localhost:2181(CONNECTED) 1] getAcl /node1&#x27;world,&#x27;anyone: cdrwa[zk: localhost:2181(CONNECTED) 2] setAcl /node1 world:anyone:crwacZxid = 0x100000004ctime = Fri May 29 14:31:54 CST 2020mZxid = 0x100000004mtime = Fri May 29 14:31:54 CST 2020pZxid = 0x100000004cversion = 0dataVersion = 0aclVersion = 1ephemeralOwner = 0x0dataLength = 5numChildren = 0 IP授权模式 命令 1setAcl &lt;path&gt; ip:&lt;ip&gt;:&lt;acl&gt; 案例 注意：远程登录zookeeper命令:./zkCli.sh -server ip 1234567891011121314151617181920212223[zk: localhost:2181(CONNECTED) 18] create /node2 &quot;node2&quot;Created /node2[zk: localhost:2181(CONNECTED) 23] setAcl /node2 ip:192.168.150.101:cdrwacZxid = 0xectime = Fri Dec 13 22:30:29 CST 2019mZxid = 0x10mtime = Fri Dec 13 22:33:36 CST 2019pZxid = 0xecversion = 0dataVersion = 2aclVersion = 1ephemeralOwner = 0x0dataLength = 20numChildren = 0[zk: localhost:2181(CONNECTED) 25] getAcl /node2&#x27;ip,&#x27;192.168.150.101: cdrwa#使用IP非 192.168.150.101 的机器[zk: localhost:2181(CONNECTED) 0] get /node2Authentication is not valid : /node2 #没有权限 Auth授权模式 命令 12addauth digest &lt;user&gt;:&lt;password&gt; #添加认证用户setAcl &lt;path&gt; auth:&lt;user&gt;:&lt;acl&gt; 案例 12345678910111213141516171819202122232425262728293031323334353637[zk: localhost:2181(CONNECTED) 6] create /node3 &quot;node3&quot;Created /node3#添加认证用户[zk: localhost:2181(CONNECTED) 7] addauth digest ld:123456[zk: localhost:2181(CONNECTED) 8] setAcl /node3 auth:ld:cdrwacZxid = 0x10000000cctime = Fri May 29 14:47:13 CST 2020mZxid = 0x10000000cmtime = Fri May 29 14:47:13 CST 2020pZxid = 0x10000000ccversion = 0dataVersion = 0aclVersion = 1ephemeralOwner = 0x0dataLength = 5numChildren = 0[zk: localhost:2181(CONNECTED) 9] getAcl /node3&#x27;digest,&#x27;ld:kesl2p6Yx58a+/mP+TKSFZkzkZ0=: cdrwa#添加认证用户后可以访问[zk: localhost:2181(CONNECTED) 10] get /node3node3cZxid = 0x10000000cctime = Fri May 29 14:47:13 CST 2020mZxid = 0x10000000cmtime = Fri May 29 14:47:13 CST 2020pZxid = 0x10000000ccversion = 0dataVersion = 0aclVersion = 1ephemeralOwner = 0x0dataLength = 5numChildren = 0 Digest授权模式 命令 1setAcl &lt;path&gt; digest:&lt;user&gt;:&lt;password&gt;:&lt;acl&gt; 这里的密码是经过SHA1及BASE64处理的密文，在SHELL中可以通过以下命令计算： 1echo -n &lt;user&gt;:&lt;password&gt; | openssl dgst -binary -sha1 | openssl base64 先来计算一个密文 1echo -n monkey:123456 | openssl dgst -binary -sha1 | openssl base64 案例 12345678910111213141516171819202122232425262728293031323334353637383940[zk: localhost:2181(CONNECTED) 12] create /node4 &quot;node4&quot;Created /node4[zk: localhost:2181(CONNECTED) 13] setAcl /node4 digest:monkey:Rk6u/zJJdOYrTZ6+J0p4/4gTILg=:cdrwacZxid = 0x10000000ectime = Fri May 29 14:52:50 CST 2020mZxid = 0x10000000emtime = Fri May 29 14:52:50 CST 2020pZxid = 0x10000000ecversion = 0dataVersion = 0aclVersion = 1ephemeralOwner = 0x0dataLength = 5numChildren = 0#没有权限无法读取[zk: localhost:2181(CONNECTED) 14] getAcl /node4Authentication is not valid : /node4#添加认证用户[zk: localhost:2181(CONNECTED) 15] addauth digest monkey:123456[zk: localhost:2181(CONNECTED) 16] getAcl /node4 &#x27;digest,&#x27;monkey:Rk6u/zJJdOYrTZ6+J0p4/4gTILg=: cdrwa[zk: localhost:2181(CONNECTED) 17] get /node4node4cZxid = 0x10000000ectime = Fri May 29 14:52:50 CST 2020mZxid = 0x10000000emtime = Fri May 29 14:52:50 CST 2020pZxid = 0x10000000ecversion = 0dataVersion = 0aclVersion = 1ephemeralOwner = 0x0dataLength = 5numChildren = 0 多种模式授权 同一个节点可以同时使用多种模式授权 123456789101112131415[zk: localhost:2181(CONNECTED) 18] create /node5 &quot;node5&quot;Created /node5[zk: localhost:2181(CONNECTED) 19] addauth digest ld:123456[zk: localhost:2181(CONNECTED) 20] setAcl /node5 ip:192.168.150.101:cdrwa,auth:ld:cdrwacZxid = 0x100000010ctime = Fri May 29 14:56:38 CST 2020mZxid = 0x100000010mtime = Fri May 29 14:56:38 CST 2020pZxid = 0x100000010cversion = 0dataVersion = 0aclVersion = 1ephemeralOwner = 0x0dataLength = 5numChildren = 0 1.7.4、ACL 超级管理员zookeeper的权限管理模式有一种叫做super，该模式提供一个超管可以方便的访问任何权限的节点 假设这个超管是：super:admin，需要先为超管生成密码的密文 1echo -n super:admin | openssl dgst -binary -sha1 | openssl base64 那么打开zookeeper目录下的/bin/zkServer.sh服务器脚本文件，找到如下一行： 1nohup $JAVA &quot;-Dzookeeper.log.dir=$&#123;ZOO_LOG_DIR&#125;&quot; &quot;-Dzookeeper.root.logger=$&#123;ZOO_LOG4J_PROP&#125;&quot; 这就是脚本中启动zookeeper的命令，默认只有以上两个配置项，我们需要加一个超管的配置项 1&quot;-Dzookeeper.DigestAuthenticationProvider.superDigest=super:xQJmxLMiHGwaqBvst5y6rkB6HQs=&quot; 那么修改以后这条完整命令变成了 12nohup $JAVA &quot;-Dzookeeper.log.dir=$&#123;ZOO_LOG_DIR&#125;&quot; &quot;-Dzookeeper.root.logger=$&#123;ZOO_LOG4J_PROP&#125;&quot; &quot;-Dzookeeper.DigestAuthenticationProvider.superDigest=super:xQJmxLMiHGwaqBvst5y6rkB6HQs=&quot;\\ -cp &quot;$CLASSPATH&quot; $JVMFLAGS $ZOOMAIN &quot;$ZOOCFG&quot; &gt; &quot;$_ZOO_DAEMON_OUT&quot; 2&gt;&amp;1 &lt; /dev/null &amp; 之后启动zookeeper,输入如下命令添加权限 1addauth digest super:admin #添加认证用户 2、Leader 选举2.1、服务器状态 looking：寻找leader状态。当服务器处于该状态时，它会认为当前集群中没有Leader，因此需要进入 Leader 选举流程。 leading：领导者状态。表明当前服务器角色是leader。 following：跟随者状态。表明当前服务器角色是follower。 observing：观察者状态。表明当前服务器角色是observer。 2.2、服务器启动时期的 Leader 选举在服务器集群初始化阶段，我们以 3 台机器组成的服务器集群为例，当有一台服务器server1 启动的时候，它是无法进行 Leader 选举的，当第二台机器 server2 也启动时，此时这两台服务器已经能够进行互相通信，每台机器都试图找到一个 Leader，于是便进入了 Leader 选举流程。 每个server发出一个投票。由于是初始情况，server1和server2都会将自己作为leader服务器来进行投票，每次投票会包含所推举的服务器的myid和zxid，使用(myid, zxid)来表示，此时server1的投票为(1, 0)，server2的投票为(2, 0)，然后各自将这个投票发给集群中其他机器。 集群中的每台服务器接收来自集群中各个服务器的投票。 处理投票。针对每一个投票，服务器都需要将别人的投票和自己的投票进行pk，pk规则如下 优先检查zxid。zxid比较大的服务器优先作为leader。 如果zxid相同，那么就比较myid。myid较大的服务器作为leader服务器。 ​ 对于Server1而言，它的投票是(1, 0)，接收Server2的投票为(2, 0)，首先会比较两者的zxid，均为0，再比较myid，此时server2的myid最大，于是更新自己的投票为(2, 0)，然后重新投票，对于server2而言，其无须更新自己的投票，只是再次向集群中所有机器发出上一次投票信息即可。 统计投票。每次投票后，服务器都会统计投票信息，判断是否已经有过半机器接受到相同的投票信息，对于server1、server2而言，都统计出集群中已经有两台机器接受了(2, 0)的投票信息，此时便认为已经选出了leader。 改变服务器状态。一旦确定了leader，每个服务器就会更新自己的状态，如果是follower，那么就变更为following，如果是leader，就变更为leading。 2.3、服务器运行时期的 Leader 选举在zookeeper运行期间，leader与非leader服务器各司其职，即便当有非leader服务器宕机或新加入，此时也不会影响leader，但是一旦leader服务器挂了，那么整个集群将暂停对外服务，进入新一轮leader选举，其过程和启动时期的Leader选举过程基本一致。 假设正在运行的有server1、server2、server3三台服务器，当前leader是server2，若某一时刻leader挂了，此时便开始Leader选举。选举过程如下: 变更状态。leader挂后，余下的非 Observer 服务器都会将自己的服务器状态变更为looking，然后开始进入leader选举过程。 每个server会发出一个投票。在运行期间，每个服务器上的zxid可能不同，此时假定server1的zxid为123，server3的zxid为122，在第一轮投票中，server1和server3都会投自己，产生投票(1, 123)，(3, 122)，然后各自将投票发送给集群中所有机器。 接收来自各个服务器的投票。 处理投票。对于投票的处理，和上面提到的服务器启动期间的处理规则是一致的。在这个例子里面，由于 Server1 的 zxid 为 123，Server3 的 zxid 为 122，那么显然，Server1 会成为 Leader。 统计投票。 改变服务器状态。 2.4、Observer 角色及其设置observer角色特点： 不参与集群的leader选举 不参与集群中写数据时的ack反馈 为了使用observer角色，在任何想变成observer角色的配置文件中加入如下配置： 1peerType=observer 并在所有server的配置文件中，配置成observer模式的server的那行配置追加:observer，例如： 1server.3=192.168.60.130:2289:3389:observer","categories":[{"name":"Zookeeper","slug":"Zookeeper","permalink":"https://blog.lee81.cn/categories/Zookeeper/"}],"tags":[{"name":"深入原理","slug":"深入原理","permalink":"https://blog.lee81.cn/tags/%E6%B7%B1%E5%85%A5%E5%8E%9F%E7%90%86/"},{"name":"Zookeeper","slug":"Zookeeper","permalink":"https://blog.lee81.cn/tags/Zookeeper/"}]},{"title":"Zookeeper客户端使用","slug":"Zookeeper客户端使用","date":"2020-04-12T01:15:08.000Z","updated":"2022-08-13T12:29:03.591Z","comments":true,"path":"2020/04/12/Zookeeper客户端使用/","link":"","permalink":"https://blog.lee81.cn/2020/04/12/Zookeeper%E5%AE%A2%E6%88%B7%E7%AB%AF%E4%BD%BF%E7%94%A8/","excerpt":"","text":"本篇文章借鉴了《从Paxos到Zookeeper分布式一致性原理与实践》 本篇将会介绍Zookeeper自带的客户端脚本，Java客户端API和开源客户端。 1、客户端脚本在Zookeeper的安装目录下的 /bin 文件夹中有一个 zkCli.sh 脚本，这个是官方提供的客户端脚本。 1.1、连接可以直接运行zkCli.sh脚本，默认就是连接本地的Zookeeper服务器。 1sh zkCli.sh 如果想连接指定的Zookeeper服务器，需要在后面添加一些参数。 1sh zkCli.sh -server ip:port -server：表示指定Zookeeper服务器，后面跟服务器的IP地址和端口号。 例子： 指定连接 192.168.0.10 上的 Zookeeper 服务器。 1sh zkCli.sh -server 192.168.0.10:2181 1.2、创建使用 create 命令可以创建一个 ZNode 节点。默认创建永久节点。用法如下： 1create [-s] [-e] path data acl -s：表示创建一个顺序节点。 -e：表示创建一个临时节点。 path：表示要创建的节点路径名。 data：表示要创建的节点数据。 acl：表示要创建的节点的访问控制列表。可以不写，默认为 world:anyone:cdrwa。 注意： 不可以递归创建。例如：创建 /create/node 节点时，其父节点 /create 必须已经存在。 临时节点下不可以创建子节点。 例子： 创建一个永久顺序节点，节点路径为 /node，节点数据为 node，访问控制列表为 ip:192.168.0.10:cdrwa**。 1create -s /node &quot;node&quot; ip:192.168.0.10:cdrwa 1.3、读取1.3.1、ls使用 ls 命令可以列出 Zookeeper 指定节点下的所有下级节点。用法如下： 1ls path [watch] path：表示要查询的节点路径。 watch：表示是否开启监控，监控 path 下的子节点变化（NodeChildrenChanged，NodeDeleted）。 例子： 列出根节点下的所有子节点。**/** 表示根节点。 1ls / 1.3.3、ls2使用 ls2 命令可以列出 Zookeeper 指定节点下的所有下级节点，并且显示当前节点的属性信息。用法如下： 1ls2 path [watch] path：表示要查询的节点路径。 watch：表示是否开启监控，监控 path 下的子节点变化。 例子： 列出根节点下的所有子节点，并且查看根节点的属性信息。**/** 表示根节点。 1ls2 / 1.3.2、get使用 get 命令可以获取 Zookeeper 指定节点的数据内容和属性信息。用法如下： 1get path [watch] path：表示要查询的节点路径。 watch：表示是否开启监控，监控节点变化（NodeDataChanged，NodeDeleted）。 例子： 获取 /node 节点的数据和属性信息。 1get /node 1.4、更新使用 set 命令可以更新指定节点的数据内容。用法如下： 1set path data [version] path：表示要更新的节点路径名。 data：表示要更新的节点数据。 version：表示指定基于哪个节点数据版本进行更新。 例子： 更新 /node 节点数据为 test。 1set /node &quot;test&quot; 1.5、删除1.5.1、delete使用 delete 命令可以删除 Zookeeper 上的指定节点。用法如下： 1delete path [version] path：表示要删除的节点路径名。 version：表示指定基于哪个节点数据版本进行删除。 注意：不支持递归删除。例如：删除 /create 节点时，其节点下不能存在子节点。 例子： 删除 /node 节点。 1delete /node 1.5.2、rmr使用 rmr 命令可以递归删除 Zookeeper 上的指定节点和其所有的子节点。用法如下： 1rmr path path：表示要删除的节点路径名。 例子： 删除 /node 节点和其下的所有子节点。 1rmr /node 1.6、ACL1.6.1、setAcl使用 setAcl 命令可以设置 Zookeeper 上的指定节点的访问控制列表，即访问权限。具体可以设置哪些访问权限，请阅读 Zookeeper深入原理。用法如下： 1setAcl path acl path：表示要设置权限的节点路径名。 acl：表示要设置的权限列表，可以设置多种权限。 例子： 为 /node 节点设置权限 ip:192.168.0.10:cdrwa 。 1setAcl /node ip:192.168.0.10:cdrwa 1.6.2、getAcl使用 getAcl 命令可以获取 Zookeeper 上的指定节点的访问控制列表。用法如下： 1getAcl path path：表示要获取权限的节点路径名。 例子： 获取 /node 节点的访问控制列表。 1getAcl /node 1.7、其他1.7.1、stat使用 stat 命令可以获取 Zookeeper 上的指定节点的属性信息。用法如下： 1stat path [watch] path：表示要获取属性信息的节点路径名。 watch：表示是否开启监控，监控节点变化（NodeDataChanged，NodeDeleted）。 例子： 查看 /node 节点属性信息。 1stat /node 1.7.2、connect使用 connect 命令可以连接 Zookeeper 上的指定服务器。用法如下： 1connect host:port host：表示要连接的 Zookeeper 服务器IP。 port：表示要连接的 Zookeeper 服务器端口号。 例子： 连接 192.168.0.12:2181 Zookeeper 服务器。 1connect 192.168.0.12:2181 1.7.3、close使用 close 命令可以关闭当前会话。用法如下： 1close 1.7.4、quit使用 quit 命令可以退出当前客户端。用法如下： 1quit 2、Java客户端APIZookeeper 官方提供了很多编程语言的客户端API，这里我只介绍Java客户端API。 API地址：https://zookeeper.apache.org/doc/r3.4.14/api/index.html 2.1、创建会话客户端可以通过创建一个 Zookeeper（org.apache.zookeeper.Zookeeper） 实例来连接 Zookeeper服务器。 API列表： Zookeeper(String connectString, int sessionTimeout, Watcher watcher) Zookeeper(String connectString, int sessionTimeout, Watcher watcher, boolean canBeReadOnly) Zookeeper(String connectString, int sessionTimeout, Watcher watcher, long sessionId, byte[] sessionPasswd) Zookeeper(String connectString, int sessionTimeout, Watcher watcher, long sessionId, byte[] sessionPasswd, boolean canBeReadOnly) 参数介绍： 参数名 说明 connectString Zookeeper服务器连接地址，多个服务器可以使用 , 连接。例如：192.168.0.10:2181,192.168.0.11:2181,192.168.0.12:2181 sessionTimeout 指会话的超时时间，单位是毫秒。 watcher Zookeeper允许客户端在构造方法中传入一个接口 Watcher 的实现类对象来作为默认的 Watcher 事件通知处理器。该参数也可以设置为 null，表明不设置默认的 Watcher 处理器。 canBeReadOnly 这是一个 boolean 类型的参数，用于标识当前会话是否支持只读模式。 sessionId 和 sessionPasswd 分别代表会话ID 和 会话密钥。这两个参数能够唯一确定一个会话，同时客户端可以使用这两个参数实现客户端会话复用，从而达到恢复会话的效果。 例子： 注意：Zookeeper客户端和服务器会话的建立是一个异步过程。 123456789101112131415161718192021222324public class ZookeeperConnect &#123; //阻塞主线程，等待会话创建成功 private CountDownLatch countDownLatch = new CountDownLatch(1); public static void main(String[] args) throws Exception&#123; //创建Zookeeper对象，连接服务器 ZooKeeper zooKeeper = new ZooKeeper(&quot;192.168.0.10:2181&quot;, 5000, new Watcher() &#123; @Override public void process(WatchedEvent watchedEvent) &#123; //连接成功 if(Event.KeeperState.SyncConnected.equals(watchedEvent.getState()))&#123; countDownLatch.countDown(); &#125;else if(Event.KeeperState.Disconnected.equals(watchedEvent.getState()))&#123; System.out.println(&quot;连接失败......&quot;); &#125;else if(Event.KeeperState.AuthFailed.equals(watchedEvent.getState()))&#123; System.out.println(&quot;用户认证失败......&quot;); &#125; &#125; &#125;); //等待连接成功 countDownLatch.await(); System.out.println(&quot;连接成功......&quot;); &#125;&#125; 2.2、创建节点客户端可以通过Zookeeper的API来创建一个数据节点。 API列表： String create(String path, byte[] data, List acl, CreateMode createMode) void create(String path, byte[] data, List acl, CreateMode createMode, AsyncCallback.StringCallback cb, Object ctx) 参数介绍： 参数名 说明 path 要创建的节点路径。 data 要创建的节点的数据内容。 acl 要创建的节点访问控制列表。 createMode 要创建的节点的节点类型。节点类型：持久，持久顺序，临时，临时顺序。 cb 回调函数，用于异步创建时使用。 ctx 上下文信息，用于异步创建时传递数据使用。 2.3、读取数据读取数据包括节点数据的获取和子节点列表的获取。 2.3.1、getData客户端可以通过 Zookeeper 的 API 来获取一个节点的数据内容。 API列表： byte[] getData(String path, boolean watch, Stat stat) byte[] getData(String path, Watcher watcher, Stat stat) void getData(String path, boolean watch, AsyncCallback.DataCallback cb, Object ctx) void getData(java.lang.String path, Watcher watcher, AsyncCallback.DataCallback cb, Object ctx) 参数介绍： 参数名 说明 path 指定数据节点的节点路径 watch 表明是否需要注册一个 Watcher。如果是就使用默认的 Watcher。 stat 指定数据节点的状态信息。 watcher 注册Watcher。 cb 回调函数，用于异步获取数据时使用。 ctx 上下文信息，用于异步获取数据时传递数据使用。 2.3.2、getChildren客户端可以通过 Zookeeper 的 API 来获取一个节点的所有子节点。 API列表： List getChildren(String path, boolean watch) void getChildren(String path, boolean watch, AsyncCallback.Children2Callback cb, Object ctx) void getChildren(String path, boolean watch, AsyncCallback.ChildrenCallback cb, Object ctx) List getChildren(String path, boolean watch, Stat stat) List getChildren(String path, Watcher watcher) void getChildren(String path, Watcher watcher, AsyncCallback.Children2Callback cb, Object ctx) void getChildren(String path, Watcher watcher, AsyncCallback.ChildrenCallback cb, Object ctx) List getChildren(String path, Watcher watcher, Stat stat) 参数介绍： 参数名 说明 path 指定数据节点的节点路径。 watch 表明是否需要注册一个 Watcher。如果是就使用默认的 Watcher。 watcher 注册Watcher。 cb 回调函数，用于异步获取数据时使用。 ctx 上下文信息，用于异步获取数据时传递数据使用。 stat 指定数据节点的节点状态信息。 2.4、更新数据客户端可以通过 Zookeeper 的 API 来更新一个节点的数据内容。 API列表： Stat setData(String path, byte[] data, int version) void setData(String path, byte[] data, int version, AsyncCallback.StatCallback cb, Object ctx) 参数介绍： 参数名 说明 path 指定数据节点的节点路径。 data[] 一个字节数组，即需要使用该数据内容来覆盖节点现在的数据内容。 version 指定节点的数据版本。 cb 回调函数，用于异步更新数据时使用。 ctx 上下文信息，用于异步更新数据时传递数据使用。 2.5、删除节点客户端可以通过Zookeeper的API来删除一个数据节点。 API列表： void delete(String path, int version) void delete(String path, int version, AsyncCallback.VoidCallback cb, Object ctx) 参数介绍： 参数名 说明 path 要删除的节点路径 version 指定节点的数据版本 cb 回调函数，用于异步删除时使用。 ctx 上下文信息，用于异步删除时传递数据使用。 2.6、检测节点是否存在客户端可以通过 Zookeeper 的 API 来检测节点是否存在。 API列表： State exists(String path, boolean watch) State exists(String path, Watcher watcher) void exists(String path, boolean watch, AsyncCallback.StatCallback cb, Object ctx) void exists(String path, Watcher watcher, AsyncCallback.StatCallback cb, Object ctx) 参数介绍： 参数名 说明 path 指定数据节点的节点路径。 watch 指定是否复用 Zookeeper 中默认的 Watcher。 watcher 注册的Watcher，用于监听以下三类事件：节点被创建、节点被删除、节点被更新 cb 回调函数，用于异步检测节点是否存在时使用。 ctx 上下文信息，用于异步检测节点是否存在时传递数据使用。 3、开源客户端3.1、ZkClientZkClient 是 Github 上一个开源的 Zookeeper 客户端，是由 Datameer 的工程师 Stefan Groschupf 和 Peter Voss 一起开发的。ZkClient 在 Zookeeper 原生 API 接口之上进行了包装，是一个更易用的Zookeeper 客户端。同时，ZkClient 在内部实现了诸如 Session 超时重连、Watcher 反复注册等功能，使得 Zookeeper 客户端的这些繁琐的细节工作对开发人员透明。 这里我就不演示使用方法了，自己去探索研究吧。 3.2、CuratorCurator 是 Netflix 公司开源的一套 Zookeeper 客户端框架，其作者是 Jordan Zimmerman。和 ZkClient 一样，Curator 解决了很多 Zookeeper 客户端非常底层的细节开发工作，包括连接重连、反复注册 Watcher 和 NodeExistsException 异常等，目前已经成为了 Apache 的顶级项目，是全世界范围内使用最广泛的 Zookeeper 客户端之一。并且，Curator 在 Zookeeper 原生API的基础上进行了包装，提供了一套易用性和可读性更强的 Fluent 风格的客户端 API 框架。 除此之外，Curator 中还提供了 Zookeeper 各种应用场景（Recipe，如共享锁服务、Master选举机制和分布式计数器等）的抽象封装。 官网地址：http://curator.apache.org/ 同样，这里我就不演示使用方法了，自己去探索研究吧。 源码地址：https://gitee.com/lingfeng1024/stu-zookeeper","categories":[{"name":"Zookeeper","slug":"Zookeeper","permalink":"https://blog.lee81.cn/categories/Zookeeper/"}],"tags":[{"name":"Zookeeper","slug":"Zookeeper","permalink":"https://blog.lee81.cn/tags/Zookeeper/"},{"name":"客户端","slug":"客户端","permalink":"https://blog.lee81.cn/tags/%E5%AE%A2%E6%88%B7%E7%AB%AF/"}]},{"title":"Zookeeper集群搭建","slug":"Zookeeper集群搭建","date":"2020-04-10T17:12:44.000Z","updated":"2022-08-13T12:29:03.593Z","comments":true,"path":"2020/04/11/Zookeeper集群搭建/","link":"","permalink":"https://blog.lee81.cn/2020/04/11/Zookeeper%E9%9B%86%E7%BE%A4%E6%90%AD%E5%BB%BA/","excerpt":"","text":"本篇文章借鉴了《从Paxos到Zookeeper分布式一致性原理与实践》 Zookeeper有两种运行模式：单机模式和集群模式。因为单机模式只是在开发测试时使用，所以这里就不介绍单机模式的搭建。 1、集群规划注意：因为Zookeeper遵循半数原则，所以集群节点个数最好是奇数。 IP地址 系统 环境 192.168.0.10 CentOS7 jdk8 192.168.0.11 CentOS7 jdk8 192.168.0.12 CentOS7 jdk8 2、下载安装2.1、下载下载地址：http://archive.apache.org/dist/zookeeper/ 根据自己的需求，选择相对应的版本，我这是用的是zookeeper-3.4.14。 2.2、安装将下载好的压缩包，解压到自己指定的路径下，例如： 1tar -zxvf zookeeper-3.4.14.tar.gz -C /opt/module/ 3、配置文件参数说明进入到 conf/ 目录下，里面有一个 zoo_sample.cfg 文件，这个就是zookeeper的配置文件。我们先对里面的参数介绍下： 参数名 默认值 描述 tickTime 2000 单位是毫秒（ms）。表示zookeeper中的最小时间单元的长度，其他参数都是以tickTime为单位来配置。 initLimit 10 单位是tickTime。表示允许Follower初始化连接到Leader并完成数据同步的超时时间，如果ZooKeeper管理的数据量很大，请根据需要增加此值。 syncLimit 5 单位是tickTime。表示Leader与Follower之间进行心跳检测的最大延时时间。如果超过时间，那么Leader认为该Follower已经脱离了集群。 dataDir 无 必须配置。用于配置Zookeeper服务器存储快照文件的目录。 dataLogDir dataDir 用于配置Zookeeper服务器存储事务日志文件的目录。推荐配置为单独的一个磁盘上，因为事务日志写入的性能直接决定了Zookeeper在处理事务请求时的吞吐。 clientPort 2181 必须配置。用于配置当前服务器对外的服务端口，客户端会通过该端口和Zookeeper服务器创建连接。 snapCount 100000 用于配置相邻两次数据快照之间的事务操作次数，即Zookeeper会在snapCount次事务操作之后进行一次数据快照。 preAllocSize 65536 单位是KB。用于配置Zookeeper事务日志文件预分配的磁盘空间大小。 minSessionTimeout 2 单位是tickTime。用于配置服务端和客户端会话超时时间的最小值。 maxSessionTimeout 20 单位是tickTime。用于配置服务端和客户端会话超时时间的最大值。 maxClientCnxns 60 用于从Socket层面限制单个客户端与单台服务器之间的并发连接数，即以IP地址粒度来进行连接数的限制。如果将该参数设置为0，则表示对连接数不作任何限制。 server.id=host:port:port 无 用于配置组成Zookeeper集群的机器列表,其中id即为ServerID，与每台服务器myid文件中的数字相对应。同时,在该参数中，会配置两个端口：第一个端口用于指定Follower服务器与Leader进行运行时通信和数据同步时所使用的端口，第二个端口则专门用于进行Leader选举过程中的投票通信。 autopurge.snapRetainCont 3 用于配置Zookeeper在自动清理的时候需要保留的快照数据文件数量和对应的事务日志文件。需要注意的是，并不是磁盘上的所有事务日志和快照数据文件都可以被清理掉——那样的话将无法恢复数据。因此 autopurge.snapRetainCont 的最小值是3，如果配置的 autopurge.snapRetainCont 值比3小的话，那么会被自动调整到3，即至少需要保留3个快照数据文件和对应的事务日志文件。 autopurge.purgeInterval 0 单位是小时。用于配置Zookeeper进行历史文件自动清理的频率。如果配置该值为0或负数，那么就表明不需要开启定时清理功能。 4、修改配置4.1、修改配置文件先将 zoo_sample.cfg 文件重命名为zoo.cfg，然后修改里面的参数，我修改的参数如下： 12345678tickTime=2000initLimit=10syncLimit=5dataDir=/data/zookeeper/dataclientPort=2181server.1=192.168.0.10:2888:3888server.2=192.168.0.11:2888:3888server.3=192.168.0.12:2888:3888 注意：这里只进行了简单的配置，请根据自己的业务需求进行修改。 4.2、创建数据目录根据配置文件中的dataDir参数创建对应的目录，然后在此目录下创建名为myid的文件，添加配置的当前节点id。 5、配置其他机器根据上面的步骤在其他两台机器上进行配置。 注意：一定要修改myid文件中的数据为对应节点的id。 6、启动与关闭服务在根目录中有一个 /bin 文件夹，zookeeper中所有的命令都在这个目录下。 6.1、启动服务1./zkServer.sh start 6.2、查看服务状态1./zkServer.sh status 6.2、关闭服务1./zkServer.sh stop","categories":[{"name":"Zookeeper","slug":"Zookeeper","permalink":"https://blog.lee81.cn/categories/Zookeeper/"}],"tags":[{"name":"集群搭建","slug":"集群搭建","permalink":"https://blog.lee81.cn/tags/%E9%9B%86%E7%BE%A4%E6%90%AD%E5%BB%BA/"},{"name":"Zookeeper","slug":"Zookeeper","permalink":"https://blog.lee81.cn/tags/Zookeeper/"}]},{"title":"Nginx深入原理","slug":"Nginx深入原理","date":"2020-03-22T07:28:19.000Z","updated":"2022-08-13T12:29:03.583Z","comments":true,"path":"2020/03/22/Nginx深入原理/","link":"","permalink":"https://blog.lee81.cn/2020/03/22/Nginx%E6%B7%B1%E5%85%A5%E5%8E%9F%E7%90%86/","excerpt":"","text":"1、概述 2、master-workers 的机制的好处首先，对于每个 worker 进程来说，独立的进程，不需要加锁，所以省掉了锁带来的开销，同时在编程以及问题查找时，也会方便很多。其次，采用独立的进程，可以让互相之间不会影响，一个进程退出后，其它进程还在工作，服务不会中断，master 进程则很快启动新的worker 进程。当然，worker 进程的异常退出，肯定是程序有 bug 了，异常退出，会导致当前 worker 上的所有请求失败，不过不会影响到所有请求，所以降低了风险。 3、worker数量设置Nginx 同 redis 类似都采用了 io 多路复用机制，每个 worker 都是一个独立的进程，但每个进程里只有一个主线程，通过异步非阻塞的方式来处理请求， 即使是千上万个请求也不在话下。每个 worker 的线程可以把一个 cpu 的性能发挥到极致。所以 worker 数和服务器的 cpu数相等是最为适宜的。设少了会浪费 cpu，设多了会造成 cpu 频繁切换上下文带来的损耗。 worker_processes 4#work 绑定 cpu(4 work 绑定 4cpu)。worker_cpu_affinity 0001 0010 0100 1000#work 绑定 cpu (4 work 绑定 8cpu 中的 4 个) 。worker_cpu_affinity 0000001 00000010 00000100 00001000 4、worker_connection 数量设置这个值是表示每个 worker 进程所能建立连接的最大值，所以，一个 nginx 能建立的最大连接数，应该是 worker_connections * worker_processes。当然，这里说的是最大连接数，对于HTTP 请 求 本 地 资 源 来 说 ， 能 够 支 持 的 最 大 并 发 数 量 是 worker_connections * worker_processes，如果是支持 http1.1 的浏览器每次访问要占两个连接，所以普通静态访问最大并发数是：worker_connections * worker_processes /2，而如果是 HTTP 作 为反向代理来说，最大并发数量是：worker_connections * worker_processes/4。因为作为反向代理服务器，每个并发会建立与客户端的连接和与后端服务的连接，会占用两个连接。","categories":[{"name":"Nginx","slug":"Nginx","permalink":"https://blog.lee81.cn/categories/Nginx/"}],"tags":[{"name":"Nginx","slug":"Nginx","permalink":"https://blog.lee81.cn/tags/Nginx/"},{"name":"深入原理","slug":"深入原理","permalink":"https://blog.lee81.cn/tags/%E6%B7%B1%E5%85%A5%E5%8E%9F%E7%90%86/"}]},{"title":"Nginx负载均衡","slug":"Nginx负载均衡","date":"2020-03-21T08:41:57.000Z","updated":"2022-08-13T12:29:03.584Z","comments":true,"path":"2020/03/21/Nginx负载均衡/","link":"","permalink":"https://blog.lee81.cn/2020/03/21/Nginx%E8%B4%9F%E8%BD%BD%E5%9D%87%E8%A1%A1/","excerpt":"","text":"1、案例1.1、需求使用 nginx （192.168.150.101）负载均衡，在本机（192.168.150.100）访问 www.ld.com/test/index.html 跳转到 192.168.150.102:8080/test/index.html或192.168.150.103:8080/test/index.html 。 1.2、配置 step1：修改本机 hosts 文件，位置：C:\\Windows\\System32\\drivers\\etc\\，并在文件最后添加如下配置。1192.168.150.101 www.ld.com step2：修改nginx.conf，在文件中的 http 块中添加如下配置。12345678910111213upstream ldserver &#123; server 192.168.150.102:8080; server 192.168.150.103:8080;&#125;server&#123; listen 80; server_name www.ld.com location / &#123; proxy_pass http://ldserver; &#125;&#125; step3：在102和103服务器上 tomcat 的webapp目录下分别添加文件夹test,并在文件夹下添加index.html，并启动。 102服务器上的index.html 12345678910&lt;!DOCTYPE html&gt;&lt;html&gt;&lt;head&gt; &lt;meta http-equiv=&quot;Content-Type&quot; content=&quot;text/html; charset=utf-8&quot; /&gt; &lt;title&gt;&lt;/title&gt;&lt;/head&gt;&lt;body&gt; &lt;h1&gt;你好，我是102&lt;/h1&gt;&lt;/body&gt;&lt;/html&gt; 103服务器上的index.html 12345678910&lt;!DOCTYPE html&gt;&lt;html&gt;&lt;head&gt; &lt;meta http-equiv=&quot;Content-Type&quot; content=&quot;text/html; charset=utf-8&quot; /&gt; &lt;title&gt;&lt;/title&gt;&lt;/head&gt;&lt;body&gt; &lt;h1&gt;你好，我是103&lt;/h1&gt;&lt;/body&gt;&lt;/html&gt; step4：在浏览器上多次访问 http://www.ld.com/test/index.html，循环显示如下页面： 2、Nginx 支持的负载均衡策略 轮询（默认） 每个请求按时间顺序逐一分配到不同的后端服务器，如果后端服务器down掉，能自动剔除。 weight weight 代表权重，默认为1，权重越高被分配的客户端越多例子： 1234upstream server_pool &#123; server 192.168.150.102:8080 weight=10; server 192.168.150.103:8080 weight=5;&#125; ip_hash 每个请求按访问 ip 的 hash 结果分配，这样每个访客固定访问一个后端服务器，可以解决session 的问题。例子： 12345upstream server_pool &#123; ip_hash; server 192.168.150.102:8080; server 192.168.150.103:8080;&#125; fair 按后端服务器的响应时间来分配请求，响应时间短的优先分配。注意：需要安装插件，因为是第三方的。例子： 12345upstream server_pool &#123; fair; server 192.168.150.102:8080; server 192.168.150.103:8080;&#125;","categories":[{"name":"Nginx","slug":"Nginx","permalink":"https://blog.lee81.cn/categories/Nginx/"}],"tags":[{"name":"Nginx","slug":"Nginx","permalink":"https://blog.lee81.cn/tags/Nginx/"}]},{"title":"Nginx反向代理","slug":"Nginx反向代理","date":"2020-03-21T06:36:01.000Z","updated":"2022-08-13T12:29:03.581Z","comments":true,"path":"2020/03/21/Nginx反向代理/","link":"","permalink":"https://blog.lee81.cn/2020/03/21/Nginx%E5%8F%8D%E5%90%91%E4%BB%A3%E7%90%86/","excerpt":"","text":"1、案例一1.1、需求使用 nginx （192.168.150.101）反向代理，在本机（192.168.150.100）访问 www.ld.com 直接跳转到 192.168.150.102:8080 。 1.2、配置 step1：修改本机 hosts 文件，位置：C:\\Windows\\System32\\drivers\\etc\\，并在文件最后添加如下配置。1192.168.150.101 www.ld.com step2：修改nginx.conf，在文件中的 http 块中添加如下配置。12345678server&#123; listen 80; server_name www.ld.com location / &#123; proxy_pass http://192.168.150.102:8080; &#125;&#125; step3：启动tomcat，使用默认的端口号。 step4：在浏览器上访问 www.ld.com，出现如下效果就算成功。 2、案例二2.1、需求使用 nginx（192.168.150.101）反向代理，在本机（192.168.150.100）访问 不同的地址，跳转到不同的tomcat中。地址1：www.ld.com/102/index.html ,目标：192.168.150.102:8080地址2：www.ld.com/103/index.html ,目标：192.168.150.103:8080 2.2、配置 step1：修改本机 hosts 文件，位置：C:\\Windows\\System32\\drivers\\etc\\，并在文件最后添加如下配置。 1192.168.150.101 www.ld.com step2：修改nginx.conf，在文件中的 http 块中添加如下配置。 123456789101112server&#123; listen 80; server_name www.ld.com location ~ /102/ &#123; proxy_pass http://192.168.150.102:8080; &#125; location ~ /103/ &#123; proxy_pass http://192.168.150.103:8080; &#125;&#125; step3：在102和103服务器上 tomcat 的webapp目录下分别添加文件夹102,103,并在文件夹下添加index.html，并启动。 102服务器上的index.html 12345678910&lt;!DOCTYPE html&gt;&lt;html&gt;&lt;head&gt; &lt;meta http-equiv=&quot;Content-Type&quot; content=&quot;text/html; charset=utf-8&quot; /&gt; &lt;title&gt;&lt;/title&gt;&lt;/head&gt;&lt;body&gt; &lt;h1&gt;你好，我是102&lt;/h1&gt;&lt;/body&gt;&lt;/html&gt; 103服务器上的index.html 12345678910&lt;!DOCTYPE html&gt;&lt;html&gt;&lt;head&gt; &lt;meta http-equiv=&quot;Content-Type&quot; content=&quot;text/html; charset=utf-8&quot; /&gt; &lt;title&gt;&lt;/title&gt;&lt;/head&gt;&lt;body&gt; &lt;h1&gt;你好，我是103&lt;/h1&gt;&lt;/body&gt;&lt;/html&gt; step4：在浏览器上分别访问不同的url 地址1：www.ld.com/102/index.html ​ 地址2：www.ld.com/103/index.html","categories":[{"name":"Nginx","slug":"Nginx","permalink":"https://blog.lee81.cn/categories/Nginx/"}],"tags":[{"name":"Nginx","slug":"Nginx","permalink":"https://blog.lee81.cn/tags/Nginx/"}]},{"title":"Nginx动静分离","slug":"Nginx动静分离","date":"2020-03-15T01:46:08.000Z","updated":"2022-08-13T12:29:03.574Z","comments":true,"path":"2020/03/15/Nginx动静分离/","link":"","permalink":"https://blog.lee81.cn/2020/03/15/Nginx%E5%8A%A8%E9%9D%99%E5%88%86%E7%A6%BB/","excerpt":"","text":"1、概述Nginx 动静分离简单来说就是把动态跟静态请求分开，不能理解成只是单纯的把动态页面和静态页面物理分离。严格意义上说应该是动态请求跟静态请求分开，可以理解成使用 Nginx处理静态页面，Tomcat 处理动态页面。动静分离从目前实现角度来讲大致分为两种： 纯粹把静态文件独立成单独的域名，放在独立的服务器上，也是目前主流推崇的方案； 把动态跟静态文件混合在一起发布，通过 nginx 来分开。通过 location 指定不同的后缀名实现不同的请求转发。通过 expires 参数设置，可以使浏览器缓存过期时间，减少与服务器之前的请求和流量。具体 Expires 定义：是给一个资源设定一个过期时间，也就是说无需去服务端验证，直接通过浏览器自身确认是否过期即可，所以不会产生额外的流量。此种方法非常适合不经常变动的资源。（如果经常更新的文件，不建议使用 Expires 来缓存），我这里设置 3d，表示在这 3 天之内访问这个 URL，发送一个请求，比对服务器该文件最后更新时间没有变化，则不会从服务器抓取，返回状态码304，如果有修改，则直接从服务器重新下载，返回状态码 200。 2、案例2.1、需求使用 nginx（192.168.150.101）动态分离，在本机（192.168.150.100）访问不同的地址，获取192.168.150.101服务器上不同的静态资源。地址1：www.ld.com/html/index.html地址2：www.ld.com/image/test.png 2.2、配置 step1：修改本机 hosts 文件，位置：C:\\Windows\\System32\\drivers\\etc\\，并在文件最后添加如下配置。 1192.168.150.101 www.ld.com step2：修改nginx.conf，在文件中的 http 块中添加如下配置。 123456789101112131415server&#123; listen 80; server_name www.ld.com #动态资源 location /html/ &#123; root /data/; index index.html index.htm; &#125; location /image/ &#123; root /data/; #打开目录浏览功能 autoindex on; &#125;&#125; step3：在192.168.150.101服务器根目录下创建data文件夹。 在data文件夹下创建html文件夹，在html文件夹下添加index.html。index.html内容如下： 12345678910&lt;!DOCTYPE html&gt;&lt;html&gt;&lt;head&gt; &lt;meta http-equiv=&quot;Content-Type&quot; content=&quot;text/html; charset=utf-8&quot; /&gt; &lt;title&gt;&lt;/title&gt;&lt;/head&gt;&lt;body&gt; &lt;h1&gt;你好，我是一个html&lt;/h1&gt;&lt;/body&gt;&lt;/html&gt; ​ 在data文件夹下创建image文件夹，在image文件夹下添加test.png。 step4：在浏览器上访问不同路径显示不同信息，测试如下： 地址1：www.ld.com/html/index.html ​ 地址2：www.ld.com/image/test.png ​ 地址3（浏览目录）：www.ld.com/image/","categories":[{"name":"Nginx","slug":"Nginx","permalink":"https://blog.lee81.cn/categories/Nginx/"}],"tags":[{"name":"Nginx","slug":"Nginx","permalink":"https://blog.lee81.cn/tags/Nginx/"}]},{"title":"Nginx安装","slug":"Nginx安装","date":"2020-03-14T07:11:13.000Z","updated":"2022-08-13T12:29:03.583Z","comments":true,"path":"2020/03/14/Nginx安装/","link":"","permalink":"https://blog.lee81.cn/2020/03/14/Nginx%E5%AE%89%E8%A3%85/","excerpt":"","text":"1、简介Nginx (engine x) 是一个高性能的HTTP和反向代理web服务器，同时也提供了IMAP/POP3/SMTP服务。其特点是占有内存少，并发能力强，事实上nginx的并发能力在同类型的网页服务器中表现较好，中国大陆使用nginx网站用户有：百度、京东、新浪、网易、腾讯、淘宝等。(来自百度百科) 2、常用的使用场景 正向代理 概念：正向代理，意思是一个位于客户端和原始服务器(origin server)之间的服务器，为了从原始服务器取得内容，客户端向代理发送一个请求并指定目标(原始服务器)，然后代理向原始服务器转交请求并将获得的内容返回给客户端。客户端才能使用正向代理。 反向代理 概念：反向代理服务器位于用户与目标服务器之间，但是对于用户而言，反向代理服务器就相当于目标服务器，即用户直接访问反向代理服务器就可以获得目标服务器的资源。同时，用户不需要知道目标服务器的地址，也无须在用户端作任何设定。 负载均衡 概念：负载均衡，英文名称为Load Balance，其含义就是指将负载（工作任务）进行平衡、分摊到多个操作单元上进行运行，例如FTP服务器、Web服务器、企业核心应用服务器和其它主要任务服务器等，从而协同完成工作任务。 动静分离 动静分离是指在web服务器架构中，将静态页面与动态页面或者静态内容接口和动态内容接口分开不同系统访问的架构设计方法，进而提升整个服务访问性能和可维护性。 3、下载、安装 下载 地址：http://nginx.org/en/download.html 安装 安装相关依赖 1yum -y install gcc zlib zlib-devel pcre-devel openssl openssl-devel 解压 1tar -zxvf nginx-1.16.1.tar.gz 进入到解压目录，运行configure脚本 1./configure 编译安装 1make &amp;&amp; make install nginx已经安装完成，安装目录为/usr/local/nginx，目录结构如下： 4、常用命令 查看帮助信息 1nginx -h 查看nginx版本 1nginx -v 查看nginx详细版本信息，还显示配置参数信息 1nginx -V 启动nginx 1nginx 指定配置文件启动nginx 1nginx -c filename 优雅停止nginx，有连接时会等连接请求完成再杀死worker进程 1nginx -s quit 快速停止nginx，可能并不保存相关信息 1nginx -s stop 重新载入nginx，当配置信息修改后，需要重新加载配置时使用 1nginx -s reload 重新打开日志文件，一般用于切割日志 1nginx -s reopen 检验配置文件是否有错 1nginx -t filename 5、配置文件介绍 位置 安装目录下的 conf 文件夹下的 nginx.conf 文件，在 conf 文件夹下还存放着nginx服务器的其他基础配置。 内容 去除注释后的文件内容如下： 1234567891011121314151617181920212223242526272829worker_processes 1;events &#123; worker_connections 1024;&#125;http &#123; include mime.types; default_type application/octet-stream; sendfile on; keepalive_timeout 65; server &#123; listen 80; server_name localhost; location / &#123; root html; index index.html index.htm; &#125; error_page 500 502 503 504 /50x.html; location = /50x.html &#123; root html; &#125; &#125;&#125; 根据上述文件内容，可以将 nginx.conf 配置文件分为三部分。 全局块 从配置文件开始到 events 块之间的内容，主要会设置一些影响 nginx 服务器整体运行的配置指令，主要包括配置运行 nginx 服务器的用户（组）、允许生成的 worker process 数、进程 PID 存放路径、日志存放路径和类型以及配置文件的引入等。 events块 events 块涉及的指令主要影响 nginx 服务器与用户的网络连接，常用的设置包括是否开启对多 worker process 下的网络连接进行序列化，是否允许同时接收多个网络连接，选取哪种事件驱动模型来处理连接请求，每个 worker process 可以同时支持的最大连接数等。 http块 这块算是 nginx 服务器配置中最繁琐的部分，代理、缓存和日志定义等绝大多数功能和第三方模块的配置都在这里。注意：http 块包括 http 全局块、server 块。每个 http 块可以包括多个 server 块，每个 server 块就相当于一个虚拟主机。 http 全局块http 全局块配置的指令包括文件引入、MIME-TYPE 定义、日志自定义、连接超时时间、单链接请求数上限等。 server 块server 块和虚拟主机有密切关系，虚拟主机从用户角度看，和一台独立的硬件主机是完全一样的，该技术的产生是为了节省互联网服务器硬件成本。注意：每个 server 块也分为全局 server 块，以及可以同时包含多个 location 块。 server 全局块最常见的配置是本虚拟主机的监听配置和本虚拟主机的名称或IP配置。 location 块location 块主要作用是基于 nginx 服务器接收到请求字符串，对虚拟主机名称之外的字符串进行匹配，对特定的请求进行处理。地址定向、数据缓存和应答控制等功能，还有许多第三方模块的配置也在这里进行。 6、nginx + keepalived 高可用6.1、主从模式TODO 6.2、双主模式TODO","categories":[{"name":"Nginx","slug":"Nginx","permalink":"https://blog.lee81.cn/categories/Nginx/"}],"tags":[{"name":"安装","slug":"安装","permalink":"https://blog.lee81.cn/tags/%E5%AE%89%E8%A3%85/"},{"name":"Nginx","slug":"Nginx","permalink":"https://blog.lee81.cn/tags/Nginx/"}]},{"title":"Maven离线开发","slug":"Maven离线开发","date":"2020-03-11T02:45:16.000Z","updated":"2022-08-13T12:29:03.574Z","comments":true,"path":"2020/03/11/Maven离线开发/","link":"","permalink":"https://blog.lee81.cn/2020/03/11/Maven%E7%A6%BB%E7%BA%BF%E5%BC%80%E5%8F%91/","excerpt":"","text":"1、背景开始在有网环境下开发项目，后面因为各种原因，需要在无网环境下进行开发，因此需要在无网环境下运行Maven项目。 2、解决方案2.1、配置setting.xml 设置本地仓库路径。 1&lt;localRepository&gt;本地仓库路径&lt;/localRepository&gt; 设置镜像地址指向本地仓库路径。 12345678&lt;mirrors&gt; &lt;mirror&gt; &lt;id&gt;central&lt;/id&gt; &lt;name&gt;central&lt;/name&gt; &lt;url&gt;file://本地仓库路径&lt;/url&gt; &lt;mirrorOf&gt;*&lt;/mirrorOf&gt; &lt;/mirror&gt; &lt;/mirrors&gt; 2.2、准备本地仓库在有网环境下下载好项目依赖的所有jar包，然后导入到无网环境下的本地仓库路径下。 2.3、修改idea配置 修改maven配置，勾选 Work offline。 修改配置文件路径为上文修改的setting.xml文件路径。 重启idea,就可以使用了。","categories":[{"name":"Maven","slug":"Maven","permalink":"https://blog.lee81.cn/categories/Maven/"}],"tags":[{"name":"Maven","slug":"Maven","permalink":"https://blog.lee81.cn/tags/Maven/"}]},{"title":"Ubuntu共享目录","slug":"Ubuntu共享目录","date":"2020-03-03T11:14:03.000Z","updated":"2022-08-13T12:29:03.590Z","comments":true,"path":"2020/03/03/Ubuntu共享目录/","link":"","permalink":"https://blog.lee81.cn/2020/03/03/Ubuntu%E5%85%B1%E4%BA%AB%E7%9B%AE%E5%BD%95/","excerpt":"","text":"1、samba 安装1sudo apt-get install samba 2、创建共享目录1mkdir [目录] 3、修改samba配置文件 备份默认配置文件 1sudo cp /etc/samba/smb.conf /etc/samba/smb.conf.bak 编辑配置文件 1sudo vim /etc/samba/smb.conf 在文件最后添加 1234567[share] path = [共享目录] available = yes browsealbe = yes public = yes writable = yes comment = [共享目录描述] 注意 推荐为共享目录创建指定的用户，修改共享目录的权限为指定用户。","categories":[{"name":"Linux","slug":"Linux","permalink":"https://blog.lee81.cn/categories/Linux/"}],"tags":[{"name":"Linux","slug":"Linux","permalink":"https://blog.lee81.cn/tags/Linux/"},{"name":"Ubuntu","slug":"Ubuntu","permalink":"https://blog.lee81.cn/tags/Ubuntu/"}]},{"title":"Linux硬盘挂载","slug":"Linux硬盘挂载","date":"2020-03-01T01:21:19.000Z","updated":"2022-08-13T12:29:03.573Z","comments":true,"path":"2020/03/01/Linux硬盘挂载/","link":"","permalink":"https://blog.lee81.cn/2020/03/01/Linux%E7%A1%AC%E7%9B%98%E6%8C%82%E8%BD%BD/","excerpt":"","text":"1、查看硬盘1lsblk 2、分区12345678910#使用parted来对GPT磁盘操作，进入交互式模式sudo parted /dev/[设备名] #将磁盘格式化为GPT(parted) mklabel gpt#将所有容量分为一个主分区(parted) mkpart primary ext4 0% 100%#打印当前分区(parted) p#退出(parted) q 3、格式化1sudo mkfs.ext4 /dev/[分区名] 4、挂载1234#在根目录创建一个文件夹sudo mkdir /data#将磁盘分区挂载到文件夹下sudo mount /dev/[分区名] /data 5、查看UUID1sudo blkid 6、修改/etc/fstab 在fstab文件的最后添加一行 1UUID=cf116c95-b7f0-4ce4-b0da-7f2856784cc3 /data ext4 defaults 0 2","categories":[{"name":"Linux","slug":"Linux","permalink":"https://blog.lee81.cn/categories/Linux/"}],"tags":[{"name":"Linux","slug":"Linux","permalink":"https://blog.lee81.cn/tags/Linux/"}]},{"title":"Cassandra设置用户名和密码","slug":"Cassandra设置用户名和密码","date":"2020-02-28T00:05:59.000Z","updated":"2022-08-13T12:29:03.570Z","comments":true,"path":"2020/02/28/Cassandra设置用户名和密码/","link":"","permalink":"https://blog.lee81.cn/2020/02/28/Cassandra%E8%AE%BE%E7%BD%AE%E7%94%A8%E6%88%B7%E5%90%8D%E5%92%8C%E5%AF%86%E7%A0%81/","excerpt":"","text":"1、修改cassandra.yamlauthenticator：AllowAllAuthenticator （允许所有认证登录）修改为authenticator: PasswordAuthenticator （允许密码认证登录） 重启服务。 2、使用默认用户登录使用默认用户：cassandra，密码：cassandra 登录进入到bin/目录下，运行命令： 1./cqlsh [ip] -u cassandra -p cassandra 3、创建新用户运行命令： 1create user 用户名 with password &#x27;密码&#x27; superuser; 注意：密码左右两侧需要 单引号 括起来 4、使用新用户登录运行命令： 1./cqlsh [ip] -u 用户名 -p 密码 5、删除默认用户运行命令： 1drop user cassandra; 6、测试使用默认用户登录，提示无法登录，则设置成功。运行命令： 1./cqlsh [ip] -u cassandra -p cassandra","categories":[{"name":"Cassandra","slug":"Cassandra","permalink":"https://blog.lee81.cn/categories/Cassandra/"}],"tags":[{"name":"Cassandra","slug":"Cassandra","permalink":"https://blog.lee81.cn/tags/Cassandra/"}]},{"title":"Cassandra删除节点","slug":"Cassandra删除节点","date":"2020-02-19T17:12:44.000Z","updated":"2022-08-13T12:29:03.570Z","comments":true,"path":"2020/02/20/Cassandra删除节点/","link":"","permalink":"https://blog.lee81.cn/2020/02/20/Cassandra%E5%88%A0%E9%99%A4%E8%8A%82%E7%82%B9/","excerpt":"","text":"1、删除在线节点在要删除的节点服务器上，执行命令： 1nodetool decommission 然后等待同步数据。 2、删除离线节点2.1、查看集群所有节点状态在一个在线节点服务器上执行命令： 12#查看集群所有节点nodetool status 2.2、删除节点删除指定节点，执行命令： 1nodetool removenode [ndoeId] 等待时间可能有点长，如果长时间没反应，就kill 掉上面的命名，然后执行： 1nodetool removenode force 2.3、重新查看节点状态再查看节点状态，应该就删除成功了。 12#查看集群所有节点nodetool status","categories":[{"name":"Cassandra","slug":"Cassandra","permalink":"https://blog.lee81.cn/categories/Cassandra/"}],"tags":[{"name":"Cassandra","slug":"Cassandra","permalink":"https://blog.lee81.cn/tags/Cassandra/"}]},{"title":"动态代理","slug":"动态代理","date":"2020-02-15T01:06:25.000Z","updated":"2022-08-13T12:29:03.593Z","comments":true,"path":"2020/02/15/动态代理/","link":"","permalink":"https://blog.lee81.cn/2020/02/15/%E5%8A%A8%E6%80%81%E4%BB%A3%E7%90%86/","excerpt":"","text":"1、基本概念 代理 指以他人的名义，在授权范围内进行对被代理人直接发生法律效力的法律行为。 静态代理 指由人创建或者工具生成的代理类，这个类在编译期就已经存在的。 动态代理 指代理类在编译期不存在，是在程序运行中自动生成的。 2、动态代理分类 JDK动态代理 基于java的反射机制并实现目标类的接口，动态生成代理类调用目标类的方法。 CGLIB 动态代理 基于继承目标类生成代理子类，不需要实现接口，只需要目标类是非final类即可。（底层是借助asm字节码技术） AspectJ 动态代理 基于修改目标类的字节，织入代理的字节，在程序编译的时候插入动态代理的字节码，不会生成全新的Class。 3、例子3.1、JDK动态代理 创建接口。 1234567891011121314151617181920212223242526272829303132333435public interface CalculateService &#123; /** * 加法计算 * @param one * @param two * @return */ public int add(int one,int two); /** * 减法计算 * @param one * @param two * @return */ public int sub(int one,int two); /** * 乘法计算 * @param one * @param two * @return */ public int mul(int one,int two); /** * 除法计算 * @param one * @param two * @return */ public int div(int one,int two); &#125; 创建接口实现类。 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647public class CalculateServiceImpl implements CalculateService&#123; /** * 加法计算 * @param one * @param two * @return */ public int add(int one,int two)&#123; int result = one + two; return result; &#125; /** * 减法计算 * @param one * @param two * @return */ public int sub(int one,int two)&#123; int result = one - two; return result; &#125; /** * 乘法计算 * @param one * @param two * @return */ public int mul(int one,int two)&#123; int result = one * two; return result; &#125; /** * 除法计算 * @param one * @param two * @return */ public int div(int one,int two)&#123; int result = one / two; return result; &#125;&#125; 创建获取代理类的通用代理 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455public class MyProxy &#123; //1、获取目标对象 private Object target; public MyProxy(Object target) &#123; this.target = target; &#125; //2、生成代理对象 public Object getProxy() &#123; //2.1、生成代理对象 Object proxy; /** * loader：ClassLoader对象。类加载器对象，用于加载动态生成的代理类。 * interfaces：接口数组，提供目标对象的所有接口，目的是让代理对象保证与目标对象都有接口中相同的方法。 * h：InvocationHandler类型的对象。 */ ClassLoader loader = target.getClass().getClassLoader(); Class [] interfaces = target.getClass().getInterfaces(); proxy = Proxy.newProxyInstance(loader, interfaces, new InvocationHandler() &#123; /** * 代理对象调用代理方法，在其中调用目标对象的方法 * * proxy：代理对象，在invoke方法中一般不会使用 * * method：目标对象要被调用的方法对象 * * args：目标对象要被调用的方法的参数 * */ @Override public Object invoke(Object proxy, Method method, Object[] args) throws Throwable &#123; //获取方法名称 String name = method.getName(); //在方法调用前进行日志记录 System.out.println(&quot;方法&quot; + name + &quot;传入参数为：&quot; + Arrays.asList(args) + &quot;，执行开始&quot;); //执行方法 Object result = method.invoke(target, args); //在方法调用后进行日志记录 System.out.println(&quot;方法&quot; + name + &quot;执行结果：&quot; + result); return result; &#125; &#125;); return proxy; &#125;&#125; 主方法 1234567891011121314151617public class Main &#123; public static void main(String[] args) throws Exception &#123; // 代理类class文件存入本地磁盘方便我们反编译查看源码 System.setProperty(&quot;sun.misc.ProxyGenerator.saveGeneratedFiles&quot;, &quot;true&quot;); //创建目标对象 CalculateServiceImpl target = new CalculateServiceImpl(); //通用的代理 CalculateService proxy = (CalculateService)new MyProxy(target).getProxy(); //执行方法 int result = proxy.add(1, 2); System.out.println(result); &#125;&#125; 3.2、CGLIB 动态代理 创建服务类 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647public class CalculateService&#123; /** * 加法计算 * @param one * @param two * @return */ public int add(int one,int two)&#123; int result = one + two; return result; &#125; /** * 减法计算 * @param one * @param two * @return */ public final int sub(int one,int two)&#123; int result = one - two; return result; &#125; /** * 乘法计算 * @param one * @param two * @return */ public int mul(int one,int two)&#123; int result = one * two; return result; &#125; /** * 除法计算 * @param one * @param two * @return */ public int div(int one,int two)&#123; int result = one / two; return result; &#125;&#125; 创建方法拦截器，用于在方法调用前后进行业务处理。 123456789101112131415161718192021222324252627282930public class MyMethodInterceptor implements MethodInterceptor &#123; /** * 方法拦截 * * obj：cglib生成的代理对象 * * method：目标对象要被调用的方法对象 * * args：目标对象要被调用的方法参数 * * MethodProxy：代理方法 */ @Override public Object intercept(Object obj, Method method, Object[] args, MethodProxy proxy) throws Throwable &#123; //获取方法名称 String name = method.getName(); //在方法调用前进行日志记录 System.out.println(&quot;方法&quot; + name + &quot;传入参数为：&quot; + Arrays.asList(args) + &quot;，执行开始&quot;); //执行方法 Object result = proxy.invokeSuper(obj, args); //在方法调用后进行日志记录 System.out.println(&quot;方法&quot; + name + &quot;执行结果：&quot; + result); return result; &#125;&#125; 主方法。 123456789101112131415161718192021222324public class Main &#123; public static void main(String[] args) &#123; // 代理类class文件存入本地磁盘方便我们反编译查看源码 System.setProperty(DebuggingClassWriter.DEBUG_LOCATION_PROPERTY, &quot;E:\\\\proxy\\\\cglib&quot;); //通过CGLIB动态代理获取代理对象的过程 Enhancer enhancer = new Enhancer(); //设置enhancer对象的父类 enhancer.setSuperclass(CalculateService.class); //设置enhancer的回调对象 enhancer.setCallback(new MyMethodInterceptor()); //创建代理对象 CalculateService proxy = (CalculateService) enhancer.create(); //通过代理对象调用目标方法 int result = proxy.add(1, 2); System.out.println(result); //注意：类或者方法为final的修饰的没办法进行代理 result = proxy.sub(2, 1); System.out.println(result); &#125;&#125;","categories":[{"name":"动态代理","slug":"动态代理","permalink":"https://blog.lee81.cn/categories/%E5%8A%A8%E6%80%81%E4%BB%A3%E7%90%86/"}],"tags":[{"name":"动态代理","slug":"动态代理","permalink":"https://blog.lee81.cn/tags/%E5%8A%A8%E6%80%81%E4%BB%A3%E7%90%86/"}]},{"title":"Linux下安装Elasticsearch","slug":"Elasticsearch-install-on-Linux","date":"2020-02-09T08:08:31.000Z","updated":"2022-08-13T12:29:03.571Z","comments":true,"path":"2020/02/09/Elasticsearch-install-on-Linux/","link":"","permalink":"https://blog.lee81.cn/2020/02/09/Elasticsearch-install-on-Linux/","excerpt":"","text":"1、搭建集群1.1、准备环境 Linux服务器 jdk8以上 1.2、下载并安装下载地址：https://www.elastic.co/cn/downloads/elasticsearch 执行解压安装命令 1tar -zxvf elasticsearch-6.3.2.tar.gz -C /opt/module/ 1.3、配置进入到 /opt/module/elasticsearch-6.3.2/config 目录下，修改配置文件elasticsearch.yml 1234567891011121314151617181920212223#集群名称，一个集群的所有节点的集群名称必须相同cluster.name: es-test#节点名称，每个节点之间都不能相同node.name: node-101#数据存放路径path.data: /data/elasticsearch/data#日志存放路径path.logs: /data/elasticsearch/logs#当前节点ip地址network.host: 192.168.150.101#network.host: 0.0.0.0#http访问端口http.port: 9200#集群访问端口transport.tcp.port: 9300#是否为主节点node.master: true#是否为数据节点node.data: true#集群其他节点地址discovery.zen.ping.unicast.hosts: [&quot;192.168.150.102&quot;,&quot;192.168.150.103&quot;]#最少主节点数discovery.zen.minimum_master_nodes: 2 其他节点也是同样配置，不过配置文件有少许改动，请按自己的集群进行配置。 1.4、启动进入到 /opt/module/elasticsearch-6.3.2/bin 执行如下命令： 1./elasticsearch 后台启动： 1./elasticsearch -d 1.5、解决启动错误 [1]和[2]问题解决方案： 修改 /etc/security/limits.conf ,在文件结束之前添加如下配置： 12345678#打开文件的最大数目* hard nofile 655360#进程的最大数目* soft nofile 131072#当前系统生效的设置值* hard nproc 4096#系统所能设定的最大值* soft nproc 2048 [3]解决方案： 修改 /etc/sysctl.conf ,在文件的最后添加如下配置： 1234#在缺省配置下，单个jvm能开启的最大线程数为其一半vm.max_map_count=655360#设置系统所有进程一共可以打开的文件数量fs.file-max=655360 然后执行如下命令： 1sysctl -p 注意：如果启动es还是报错，请重启一下服务器。 1.6、测试使用浏览器访问： 1http://192.168.150.101:9200/_cat/nodes/?v 出现如下页面，说明部署成功。 2、可视化工具2.1、Kibana2.1.1、下载地址：https://www.elastic.co/cn/downloads/past-releases#kibana 注意：要选与elasticsearch对应的版本 2.1.2、解压安装1tar -zxvf kibana-6.3.2-linux-x86_64.tar.gz -C /opt/module/ 2.1.3、配置进入到 /opt/module/kibana-6.3.2-linux-x86_64/config 目录下，修改配置文件 kibana.yml 123456#端口号server.port: 5601#服务器ip地址server.host: &quot;192.168.150.101&quot;#连接的elasticsearch url地址elasticsearch.url: &quot;http://192.168.150.101:9200&quot; 2.1.4、启动进入到 /opt/module/kibana-6.3.2-linux-x86_64/bin 目录下，执行如下命令： 1./kibana 后台启动： 1nohup ./kibana &amp; 2.1.5、连接使用浏览器访问： 1http://192.168.150.101:5601 2.2、cerebro2.2.1、下载地址：https://github.com/lmenezes/cerebro/releases 2.2.2、解压安装1tar -zxvf cerebro-0.8.5.tgz -C /opt/module/ 2.2.3、配置进入到 /opt/module/cerebro-0.8.5/conf 目录下，修改配置文件 application.conf 1234567891011121314151617181920212223242526272829#服务运行的pid存放位置，如要避免产生pid可使用/dev/nullpidfile.path=/dev/null#cerebro 存储数据的位置，默认为cerebro安装目录data.path = &quot;./cerebro.db&quot;#配置需要连接的es集群hosts = [ &#123; # 集群连接地址 host = &quot;http://192.168.150.101:9200&quot; #自定义集群名称 name = &quot;Weather cluster&quot; &#125; #&#123; # host = &quot;http://localhost:9200&quot; # name = &quot;Localhost cluster&quot; # headers-whitelist = [ &quot;x-proxy-user&quot;, &quot;x-proxy-roles&quot;, &quot;X-Forwarded-For&quot; ] #&#125; # Example of host with authentication #&#123; # host = &quot;http://some-authenticated-host:9200&quot; # name = &quot;Secured Cluster&quot; # auth = &#123; # username = &quot;username&quot; # password = &quot;secret-password&quot; # &#125; #&#125;] 2.2.4、启动进入到 /opt/module/cerebro-0.8.5/bin 目录下，执行如下命令： 1./cerebro 后台启动： 1nohup ./cerebro &amp; 后台启动，不需要保留日志信息 1nohup ./cerebro &gt;/dev/null 2&gt;&amp;1 &amp; 启动指定端口号 1nohup ./cerebro -Dhttp.port=8888 &gt;/dev/null 2&gt;&amp;1 &amp; 2.2.5、连接使用浏览器访问： 1http://192.168.150.101:8888","categories":[{"name":"Elasticsearch","slug":"Elasticsearch","permalink":"https://blog.lee81.cn/categories/Elasticsearch/"}],"tags":[{"name":"Elasticsearch","slug":"Elasticsearch","permalink":"https://blog.lee81.cn/tags/Elasticsearch/"},{"name":"集群搭建","slug":"集群搭建","permalink":"https://blog.lee81.cn/tags/%E9%9B%86%E7%BE%A4%E6%90%AD%E5%BB%BA/"}]},{"title":"Windows下安装Elasticsearch","slug":"ElasticSearch-install-on-Windows","date":"2020-02-09T06:50:22.000Z","updated":"2022-08-13T12:29:03.570Z","comments":true,"path":"2020/02/09/ElasticSearch-install-on-Windows/","link":"","permalink":"https://blog.lee81.cn/2020/02/09/ElasticSearch-install-on-Windows/","excerpt":"","text":"1、前言因es版本原因，es5.x 以上不能按原来插件的方式安装elasticsearch-head，故需要新的方式安装使用。我这是在win10下安装测试的。 2、环境准备jdk1.8 以上。 3、安装ElasticSearch3.1、下载官网地址：https://www.elastic.co/cn/downloads/elasticsearch按自己的需求下载相应的版本，我这里选择的是 5.6.16版本的zip包。提示：es5.x 以上版本最低需要jdk1.8。 3.2、安装解压安装包到自己指定的位置。 3.3、修改配置文件进入到 elasticsearch-5.6.16\\config 目录下，修改elasticsearch.yml文件。去除以下注释： 1234567891011121314151617集群名称（可自定义）cluster.name: my-application节点名称（可自定义）node.name: node-1数据存储路径（修改为你自己的路径）path.data: /path/to/data日志存储路径（修改为你自己的路径）path.logs: /path/to/logs监控ipnetwork.host: 0.0.0.0http访问端口号http.port: 9200 3.4、运行进入到 elasticsearch-5.6.16\\bin 目录下，双击运行 elasticsearch.bat。 3.5、测试在浏览器上输入 http://localhost:9200 ，页面上出现节点信息，就说明安装成功。 4、安装node4.1、下载官网地址：http://nodejs.cn/download/按自己的需求下载相应的版本，我这里选择的是 版本：10.16.0 windows安装包（.msi) 64位。 4.2、安装双击安装即可。 4.3、测试在命令行中运行。 1node -v 5、安装elasticsearch-head5.1、下载地址：https://github.com/mobz/elasticsearch-head 5.2、安装解压安装包到自己指定的位置。 5.3、配置进入到 elasticsearch-head-master 目录下，修改 Gruntfile.js 文件，添加 hostname: ‘*’, 进入到 elasticsearch-head-master_site 目录下，修改 app.js 文件。将 localhost 改为安装elasticsearch的服务器ip地址，如果是本机，则不需要更改。 进入到 elasticsearch-5.6.16\\config 目录下，修改elasticsearch.yml文件。在文件的末尾添加以下配置： 123456789设置当前节点为主节点node.master: truenode.data: true开启跨域http.cors.enabled: true 允许所有域名访问http.cors.allow-origin: &quot;*&quot; 5.4、安装grunt-cli在命令行中执行以下命令（比较慢）： 1npm install -g grunt-cli 5.5、初始化依赖进入到 elasticsearch-5.6.16 目录下，在命令行中执行： 1npm install 5.6、运行到目前为止所有的安装都已完成，以后每次启动都需要进入到 elasticsearch-5.6.16 目录下，在命令行中执行： 1npm run start 5.7、测试在浏览器上输入 http://localhost:9100 ,出现下图，说明安装成功。","categories":[{"name":"Elasticsearch","slug":"Elasticsearch","permalink":"https://blog.lee81.cn/categories/Elasticsearch/"}],"tags":[{"name":"Elasticsearch","slug":"Elasticsearch","permalink":"https://blog.lee81.cn/tags/Elasticsearch/"}]},{"title":"Docker安装","slug":"Docker安装","date":"2020-02-02T06:09:27.000Z","updated":"2022-08-13T12:29:03.570Z","comments":true,"path":"2020/02/02/Docker安装/","link":"","permalink":"https://blog.lee81.cn/2020/02/02/Docker%E5%AE%89%E8%A3%85/","excerpt":"","text":"1、Ubuntu 安装step 1: 安装依赖工具123sudo apt-get updatesudo apt-get -y install apt-transport-https ca-certificates curl software-properties-common step 2: 安装GPG证书1curl -fsSL http://mirrors.aliyun.com/docker-ce/linux/ubuntu/gpg | sudo apt-key add - step 3: 添加软件源信息1sudo add-apt-repository &quot;deb [arch=amd64] http://mirrors.aliyun.com/docker-ce/linux/ubuntu $(lsb_release -cs) stable&quot; step 4: 更新并安装Docker-CE12sudo apt-get -y updatesudo apt-get -y install docker-ce step 5: 配置镜像加速器（针对Docker客户端版本大于 1.10.0 的用户）12345678sudo mkdir -p /etc/docker sudo tee /etc/docker/daemon.json &lt;&lt;-&#x27;EOF&#x27; &#123; &quot;registry-mirrors&quot;:[&quot;镜像加速地址&quot;] &#125; EOF sudo systemctl daemon-reload sudo systemctl restart docker 2、CentOS7 安装step 1: 安装依赖工具1sudo yum install -y yum-utils device-mapper-persistent-data lvm2 step 2: 添加软件源信息1sudo yum-config-manager --add-repo http://mirrors.aliyun.com/docker-ce/linux/centos/docker-ce.repo step 3: 更新并安装Docker-CE12sudo yum makecache fastsudo yum -y install docker-ce step 4: 开启Docker服务1sudo service docker start step 5: 配置镜像加速器（针对Docker客户端版本大于 1.10.0 的用户）12345678sudo mkdir -p /etc/docker sudo tee /etc/docker/daemon.json &lt;&lt;-&#x27;EOF&#x27; &#123; &quot;registry-mirrors&quot;:[&quot;镜像加速地址&quot;] &#125; EOF sudo systemctl daemon-reload sudo systemctl restart docker 3、检验1docker version","categories":[{"name":"Docker","slug":"Docker","permalink":"https://blog.lee81.cn/categories/Docker/"}],"tags":[{"name":"Docker","slug":"Docker","permalink":"https://blog.lee81.cn/tags/Docker/"},{"name":"安装","slug":"安装","permalink":"https://blog.lee81.cn/tags/%E5%AE%89%E8%A3%85/"}]},{"title":"JVM工具","slug":"JVM工具","date":"2020-01-20T02:02:18.000Z","updated":"2022-08-13T12:29:03.572Z","comments":true,"path":"2020/01/20/JVM工具/","link":"","permalink":"https://blog.lee81.cn/2020/01/20/JVM%E5%B7%A5%E5%85%B7/","excerpt":"","text":"1、概述JDK为开发人员提供一些工具，可以查看异常堆栈、虚拟机运行日志、垃圾收集器日志、线程快照、堆转储快照等。当我们遇到一些问题时，通过这些工具定位问题，解决问题。下面介绍几个常用的工具。 2、基础工具2.1、jpsjps（JVM Process Status Tool）列出正在运行的虚拟机进程，并显示虚拟机执行主类（Main Class，main() 函数所在的类）名称以及这些进程的本地虚拟机唯一ID(LVMID，Local Virtual Machine Identifier)。 命令格式： 1jps [options] [hostid] 参数解释： options：可以使用如下参数。 -q：显示进程ID。 -m：显示进程ID，主类名称，以及传入main方法的参数。 -l：显示进程ID，主类全名。 -v：显示进程ID，主类名称，以及传入JVM的参数。 -V：显示进程ID，主类名称。 注意：其中 -mlv 可以连用。 hostid：主机或者服务器的ip，如果不指定，默认为当前的主机或者是服务器。 示例：列出所有的虚拟机进程。 1jps -l 2.2、jstatjstat（JVM Statistics Monitoring Tool）是用于监视虚拟机各种运行状态信息的命令行工具。可以显示本地或者远程虚拟机进程中的类加载、内存、垃圾收集、即时编译等运行时数据。 命令格式： 1jstat [option vmid [interval[s|ms] [count]]] &lt;pid&gt; 参数解释： option：指定要查询的虚拟机信息，主要分为3类：类加载、内存、垃圾收集和即时编译状况，具体选项及作用如下： -class：监视类加载、卸载数量、总空间以及类装载所耗费的时间。 -compiler：输出即时编译器编译过的方法、耗时等信息。 -gc：监视Java 堆状况，包括 Eden 区、2个 Survivor区、老年代、永久代等的容量，已用空间，垃圾收集时间合计等信息。 -gccapacity：监视内容与 gc 基本相同，但输出主要关注 Java 堆各个区域使用到的最大、最小空间。 -gccause：显示有关垃圾收集统计信息（同-gcutil），以及上一次和当前（如果适用）垃圾收集事件的原因。 -gcnew：显示新生代行为的统计信息。 -gcnewcapacity：显示有关新生代大小及其相应空间的统计信息。 -gcold：显示有关老年代行为的统计信息。 -gcoldcapacity：显示有关老年代大小及其相应空间的统计信息。 -gcmetacapacity：显示有关元空间大小的统计信息。 -gcutil：显示有关垃圾收集统计信息。 -printcompilation：显示Java HotSpot VM编译方法统计信息。 vmid：如果是本地虚拟机进程，vmid和本地虚拟机唯一ID是一致的；如果是远程虚拟机进程，那么vmid的格式应当是：protocol:lvmid[@hostname[:port]/servername] interval：采样间隔，单位为秒(s)或毫秒(ms)，默认单位是毫秒。必须为正整数。指定后，该jstat命令将在每个间隔产生其输出。 count：要显示的样本数。 示例： 展示类加载器统计信息。 1jstat -class 6240 结果： Loaded Bytes Unloaded Bytes Time 610 1232.9 0 0.0 0.08 Loaded：已加载的类总数。 Bytes：加载的KB数。 Unloaded：卸载的类总数。 Bytes：卸载的KB数。 Time：执行类加载和卸载操作所花费的时间。 展示Java HotSpot VM 即时编译器统计信息。 1jstat -compiler 6240 结果： Compiled Failed Invalid Time FailedType FailedMethod 74 0 0 0.02 0 Compiled：执行的编译任务数。 Failed：失败的编译任务数。 Invalid：无效的编译任务数。 Time：执行编译任务所花费的时间。 FailedType：上次失败的编译的编译类型。 FailedMethod：上次失败的编译的类名和方法。 展示垃圾收集的堆统计信息。 1jstat -gc 6240 结果： S0C S1C S0U S1U EC EU OC OU MC MU CCSC CCSU YGC YGCT FGC FGCT GCT1024.0 1024.0 0.0 0.0 8192.0 5049.1 10240.0 0.0 4480.0 776.8 384.0 76.6 0 0.000 0 0.000 0.000 S0C：当前幸存者空间0容量（KB）。 S1C：当前幸存者空间1容量（KB）。 S0U：幸存者空间0使用大小（KB）。 S1U：幸存者空间1使用大小（KB）。 EC：当前伊甸园空间容量（KB）。 EU：伊甸园空间使用大小（KB）。 OC：当前老年代容量（KB）。 OU：老年代使用大小（KB）。 MC：元空间容量（KB）。 MU：元空间使用大小（KB）。 CCSC：压缩的类空间容量（KB）。 CCSU：使用的压缩类空间（KB）。 YGC：新生代垃圾收集事件的数量。 YGCT：新生代垃圾收集时间。 FGC：完整GC垃圾收集事件的数量。 FGCT：完整GC垃圾收集时间。 GCT：总垃圾收集时间。 2.3、jinfojinfo（Configuration Info for Java）的作用是实时查看和调整虚拟机各项参数。 命令格式： 1jinfo [option] &lt;pid&gt; 参数解释： option no option：输出全部的参数和系统属性。 -flag name：输出对应名称的参数。 -flag[+|-]name：开启或者关闭对应名称的参数。 -flag name=value：设定对应名称的参数。 -flags：输出全部的参数。 -sysprops：输出系统属性。 示例：输出当前进程的jvm全部参数。 1jinfo -flags 6240 2.4、jmapjmap（Memory Map for Java）可以生成 java 程序的 dump 文件，也可以查看堆内对象信息、查看ClassLoader 的信息以及 finalizer 队列。 命令格式： 1jmap [option] &lt;pid&gt; 参数解释： option no option：查看进程的内存映像信息，类似 Solaris pmap命令。 -heap：显示Java堆详细信息。 -histo[:live]：显示堆中对象的统计信息。 -clstats：打印类加载器信息。 -finalizerinfo：显示在F-Queue队列等待Finalize线程执行finalizer方法的对象。 -dump:：生成堆转储快照。 示例：生成堆转储快照。 1jmap -dump:live,format=b,file=E:\\jmap.bin 34152 2.5、jstackjstack（Stack Trace for Java）命令用于查看或导出虚拟机当前时刻的线程快照。线程快照是当前java虚拟机内每一条线程正在执行的方法堆栈的集合，生成线程快照的主要目的是定位线程出现长时间停顿的原因，如线程间死锁、死循环、长时间等待外部资源等。线程出现停顿的时候通过jstack来查看各个线程的调用堆栈，就可以知道没有响应的线程到底在后台做什么 事情，或者等待什么资源。如果java程序崩溃生成core文件，jstack工具可以用来获得core文件的java stack和native stack的信息，从而可以轻松地知道java程序是如何崩溃和在程序何处发生问题。另外，jstack工具还可以附属到正在运行的java程序中，看到当时运行的java程序的java stack和native stack的信息。 命令格式： 1jstack [option] &lt;pid&gt; 参数解释： option -F：当线程挂起时，使用jstack -l pid 请求不被响应时，强制输出线程堆栈。 -l：除堆栈外，显示关于锁的附加信息，例如ownable synchronizers -m：可以同时输出java以及C/C++的堆栈信息。 示例： 输出堆栈信息，并显示关于锁的附加信息。 1jstack -l 34692 3、可视化工具3.1、JConsoleJConsole（Java Monitoring and Management Console）是一款基于JMX的可视化监视、管理工具。它的主要功能是通过JMX的MBean 对系统进行信息收集和参数动态调整。 连接： 可以连接本地进程，也支持远程进程。 主界面： 概览中展示了堆内存、线程、类、CPU的使用信息。上面还可以查看每个模块详细的信息。这里没什么难度，就不详细介绍了。 3.2、JVisualVMVisualVM（All-in-One Java Troubleshooting Tool）是功能最强大的运行监视和故障处理程序之一，曾经在很长一段时间内是Oracle官方主力发展的虚拟机故障处理工具。Oracle曾在VisualVM的软件说明中写上了“All-in-One”的字样，预示着它除了常规的运行监视、故障处理外，还将提供其他方面的能力，譬如性能分析（Profiling）。VisualVM的性能分析功能比起JProfiler、YourKit等专业且收费的Profiling工具都不遑多让。而且相比这些第三方工具，VisualVM还有一个很大的优点：不需要被监视的程序基于特殊Agent去运行，因此它的通用性很强，对应用程序实际性能的影响也较小，使得它可以直接应用在生产环境中。这个优点是JProfiler、YourKit等工具无法与之媲美的。","categories":[{"name":"JVM","slug":"JVM","permalink":"https://blog.lee81.cn/categories/JVM/"}],"tags":[{"name":"JVM","slug":"JVM","permalink":"https://blog.lee81.cn/tags/JVM/"},{"name":"工具","slug":"工具","permalink":"https://blog.lee81.cn/tags/%E5%B7%A5%E5%85%B7/"}]},{"title":"Spring事务","slug":"Spring事务","date":"2020-01-07T07:09:27.000Z","updated":"2022-08-13T12:29:03.586Z","comments":true,"path":"2020/01/07/Spring事务/","link":"","permalink":"https://blog.lee81.cn/2020/01/07/Spring%E4%BA%8B%E5%8A%A1/","excerpt":"","text":"1、简介事务就是一组由于逻辑上紧密关联而合并成一个整体（工作单元）的多个数据库操作，这些操作要么都执行，要么都不执行。 2、事务的特性（ACID） 原子性(atomicity)：“原子”的本意是“不可再分”，事务的原子性表现为一个事务中涉及到的多个操作在逻辑上缺一不可。事务的原子性要求事务中的所有操作要么都执行，要么都不执行。 一致性(consistency)：“一致”指的是数据的一致，具体是指：所有数据都处于满足业务规则的一致性状态。一致性原则要求：一个事务中不管涉及到多少个操作，都必须保证事务执行之前数据是正确的，事务执行之后数据仍然是正确的。如果一个事务在执行的过程中，其中某一个或某几个操作失败了，则必须将其他所有操作撤销，将数据恢复到事务执行之前的状态，这就是回滚。 隔离性(isolation)： 在应用程序实际运行过程中，事务往往是并发执行的，所以很有可能有许多事务同时处理相同的数据，因此每个事务都应该与其他事务隔离开来，防止数据损坏。隔离性原则要求多个事务在并发执行过程中不会互相干扰。 持久性(durability)： 持久性原则要求事务执行完成后，对数据的修改永久的保存下来，不会因各种系统错误或其他意外情况而受到影响。通常情况下，事务对数据的修改应该被写入到持久化存储器中。 3、Spring 事务管理器Spring 从不同的事务管理API中抽象出了一整套事务管理机制，使开发人员可以通过配置的方式进行事务管理，而不必了解其底层是如何实现的。Spring的核心事务管理抽象是 PlatformTransactionManager 接口： 12345678910package org.springframework.transaction;public interface PlatformTransactionManager &#123; TransactionStatus getTransaction(TransactionDefinition definition) throws TransactionException; void commit(TransactionStatus status) throws TransactionException; void rollback(TransactionStatus status) throws TransactionException; &#125; PlatformTransactionManager 接口常用的实现类： DataSourceTransactionManager：应用于普通的JDBC。 JtaTransactionManager：应用于JPA。 HibernateTransactionManager：应用于Hibernate框架。 TransactionTemplate：应用于编程式事务管理。 4、Spring 事务管理Spring提供了两种事务管理的方式，分别是： 编程式事务管理 编程式事务管理类似于使用原生的JDBC API实现事务管理，将事务管理的代码嵌入到业务代码中来控制事务的提交和回滚。但是事务管理的代码相同，会产生大量的代码冗余。 声明式事务管理（推荐使用） 因编程式事务管理在代码中会产生大量的代码冗余，所以Spring基于Spring AOP框架实现了一种通过配置即可实现事务管理的方式，即声明式事务。只要方法中抛出RuntimeException或Error就会触发事务回滚。Spring提供了两种配置方式： 注解@Transaction（推荐使用）@Transaction 可以放在方法上使用，也可以放在类上使用，如果放在类上使用就是为类中的所有方法以及子类中的所有方法都加上了事务。 123456789101112131415&lt;!-- 配置数据源--&gt;&lt;bean id=&quot;dataSource&quot; class=&quot;org.apache.commons.dbcp.BasicDataSource&quot; destroy-method=&quot;close&quot;&gt; &lt;property name=&quot;driverClassName&quot; value=&quot;oracle.jdbc.driver.OracleDriver&quot;/&gt; &lt;property name=&quot;url&quot; value=&quot;jdbc:oracle:thin:@rj-t42:1521:elvis&quot;/&gt; &lt;property name=&quot;username&quot; value=&quot;scott&quot;/&gt; &lt;property name=&quot;password&quot; value=&quot;tiger&quot;/&gt; &lt;/bean&gt; &lt;!-- 配置事务管理器--&gt;&lt;bean id=&quot;txManager&quot; class=&quot;org.springframework.jdbc.datasource.DataSourceTransactionManager&quot;&gt; &lt;property name=&quot;dataSource&quot; ref=&quot;dataSource&quot;/&gt; &lt;/bean&gt;&lt;!-- 开启事务注解，当配置的事务管理器的id为transactionManager时，transaction-manager属性可以省略，如果不是，则必须显示赋值--&gt;&lt;tx:annotation-driven transaction-manager=&quot;txManager&quot;/&gt; xml配置 1234567891011121314151617181920212223242526272829&lt;!-- 配置数据源--&gt;&lt;bean id=&quot;dataSource&quot; class=&quot;org.apache.commons.dbcp.BasicDataSource&quot; destroy-method=&quot;close&quot;&gt; &lt;property name=&quot;driverClassName&quot; value=&quot;oracle.jdbc.driver.OracleDriver&quot;/&gt; &lt;property name=&quot;url&quot; value=&quot;jdbc:oracle:thin:@rj-t42:1521:elvis&quot;/&gt; &lt;property name=&quot;username&quot; value=&quot;scott&quot;/&gt; &lt;property name=&quot;password&quot; value=&quot;tiger&quot;/&gt; &lt;/bean&gt; &lt;!-- 配置事务管理器--&gt;&lt;bean id=&quot;txManager&quot; class=&quot;org.springframework.jdbc.datasource.DataSourceTransactionManager&quot;&gt; &lt;property name=&quot;dataSource&quot; ref=&quot;dataSource&quot;/&gt; &lt;/bean&gt;&lt;!-- 配置普通的bean--&gt;&lt;bean id=&quot;fooService&quot; class=&quot;x.y.service.DefaultFooService&quot;/&gt; &lt;!-- 配置事务管理与AOP关联--&gt;&lt;tx:advice id=&quot;txAdvice&quot; transaction-manager=&quot;txManager&quot;&gt; &lt;tx:attributes&gt; &lt;tx:method name=&quot;get*&quot; read-only=&quot;true&quot;/&gt; &lt;tx:method name=&quot;*&quot;/&gt; &lt;/tx:attributes&gt; &lt;/tx:advice&gt; &lt;!-- 配置AOP--&gt;&lt;aop:config&gt; &lt;aop:pointcut id=&quot;fooServiceOperation&quot; expression=&quot;execution(* x.y.service.FooService.*(..))&quot;/&gt; &lt;aop:advisor advice-ref=&quot;txAdvice&quot; pointcut-ref=&quot;fooServiceOperation&quot;/&gt;&lt;/aop:config&gt; 例子源码地址：https://github.com/LDknife/spring-example/tree/master/spring-transaction 5、Spring 事务管理的属性配置 值(value) 标识属于哪个事务管理器。如果只有一个事务管理器，默认可以不用设置。 传播行为(propagation) 当事务方法被另一个事务方法调用时，必须指定事务是如何传播的。例如：方法可能继续使用现有的事务，也可能开启一个新的事务。 Spring定义了7种传播行为： 属性值 描述 REQUIRED （默认值）如果有事务在运行，当前的方法就在这个事务内运行，否则，就启动一个新的事务，并在自己的事务内运行 REQUIRED_NEW 当前的方法必须启动新事务，并在它自己的事务内运行。如果有事务正在运行，应该将它挂起。 SUPPORTS 如果有事务在运行，当前的方法就在这个事务内运行。否则它可以不运行在事务中。 NOT_SUPPORTED 当前的方法不应该运行在事务中，如果有运行的事务，将他挂起。 MANDATORY 当前的方法必须运行在事务内部，如果没有正在运行的事务，就抛出异常。 NEVER 当前的方法不应该运行在事务中，如果有运行的事务，就抛出异常。 NESTED 如果有事务在运行，当前的方法就应该在这个事务的嵌套事务内运行。否则，就启动一个新的事务，并在它自己的事务内运行。 隔离级别(isolation) 当多个事务并发执行时，会引发一些问题： 脏读：当一个事务正在访问数据并且对数据进行了修改，而这种修改还没有提交到数据库中，这时另外一个事务也访问了这个数据，然后使用了这个数据。因为这个数据是还没有提交的数据，那么另外一个事务读到的这个数据是“脏数据”，依据“脏数据”所做的操作可能是不正确的。 不可重复读：指在一个事务内多次读同一数据。在这个事务还没有结束时，另一个事务也访问该数据。那么，在第一个事务中的两次读数据之间，由于第二个事务的修改导致第一个事务两次读取的数据可能不太一样。这就发生了在一个事务内两次读到的数据是不一样的情况，因此称为不可重复读。 幻读：幻读与不可重复读类似。它发生在一个事务读取了几行数据，接着另一个并发事务插入了一些数据时。在随后的查询中，第一个事务就会发现多了一些原本不存在的记录，就好像发生了幻觉一样，所以称为幻读。 事务的隔离级别：为解决上述问题，引入了事务隔离的概念。隔离级别越高，数据一致性就越好，但并发性越弱。SQL标准定义了四种隔离级别： READ_UNCOMMITTED（读未提交）：值为1，最低的隔离级别，允许读取尚未提交的数据变更，可能会导致脏读、不可重复读或者幻读。 READ_COMMITTED（读已提交）：值为2，允许读取并发事务已经提交的数据，可以阻止脏读，但是不可重复读或者幻读仍有可能发生。 REPEATABLE_READ（可重复读）：值为4，对同一字段的多次读取结果都是一致的，除非数据是被本身事务自己所修改，可以阻止脏读和不可重复读，但是幻读仍有可能发生。 mysql默认的隔离级别。 SERIALIZABLE（串行化）：值为8，最高的隔离级别，完全服从ACID的隔离级别。所有的事务依次逐个执行，这样事务之间就完全不可能产生干扰，该级别可以防止脏读、不可重复读和幻读。 触发事务回滚的异常 默认情况下捕获到RuntimeException或Error时回滚。也可以设置属性： rollbackFor：指定必须进行回滚的异常类型，可以为多个。 rollbackForClassName：指定必须进行回滚的异常类全类名，可以为多个。 noRollbackFor：指定不进行回滚的异常类型，可以为多个。 noRollbackForClassName：指定不进行回滚的异常类全类名，可以为多个。 超时(timeout) 事务在强制回滚之前可以保持多久。这样可以防止长期运行的事务占用资源。默认为 -1。 只读(readOnly) 标识这个事务只是读取数据，不更新数据。默认为false。","categories":[{"name":"Spring","slug":"Spring","permalink":"https://blog.lee81.cn/categories/Spring/"}],"tags":[{"name":"Spring","slug":"Spring","permalink":"https://blog.lee81.cn/tags/Spring/"}]},{"title":"SpringAOP","slug":"SpringAOP","date":"2020-01-06T07:09:27.000Z","updated":"2022-08-13T12:29:03.585Z","comments":true,"path":"2020/01/06/SpringAOP/","link":"","permalink":"https://blog.lee81.cn/2020/01/06/SpringAOP/","excerpt":"","text":"1、简介面向切面编程(AOP) 提供另外一种思考程序结构的方式来补充面向对象编程（OOP）。可以将一些方法公共的功能提取出来，单独处理。提高了代码的整洁度和健壮性。 2、AspectJAspectJ是一个面向切面的框架，它扩展了Java语言。AspectJ定义了AOP语法，它有一个专门的编译器用来生成遵守Java字节编码规范的Class文件。（来自百度百科）Spring 整合了AspectJ切面框架，我们大多数情况下是使用的AspectJ框架。 3、术语 横切关注点： 从每个方法中抽取出来的同一类非核心业务。 切面(Aspect)： 封装从每个方法中抽取出来的同一类非核心业务的类。 通知(Advice)： 切面必须要完成的各个具体的工作。 连接点(Join point)： 横切关注点在程序代码中的具体体现，对应程序执行的某个特定位置。 切入点(Pointcut)： 定位连接点的方式。 目标(Target object)： 被通知的对象。 代理(AOP proxy)： 向目标对象应用通知之后创建的代理对象。 图解： 4、切入点表达式和JoinPoint4.1、切入点表达式通过表达式的方式定位一个或多个具体的连接点。语法格式： 1execution([权限修饰符][返回值类型][简单类名/全类名][方法名]([参数列表])) 例子： 1execution(* com.ld.spring.TestService.*(..)) 解释： 第一个“ * ”代表任意修饰符和任意返回值。 第二个“ * ”代表任意方法。 “..”匹配任意数量、任意类型的参数。 若目标类或接口与该切面类在同一包中可以省略包名。 其他使用方法：可以通过“&amp;&amp;”、“||”、“!”等操作符结合使用。 1execution(* *.add*(int,..)) || execution(* *.sub*(int,..)) 解释：任意类中第一个参数为int类型的以add或sub开头的方法名的方法。 4.2、JoinPoint切入点表达式通常都会是从宏观上定位一组方法，跟具体某个通知的注解结合起来就能够确定对应的连接点。那么就一个具体的连接点而言，我们可能会关心这个连接点的一些具体信息，例如：当前连接点所在方法的方法名、当前传入的参数值等等。这些信息都封装在JoinPoint接口的实例对象中。 5、通知：通知就是在具体的连接点上要执行的操作。一个切面可以有一个或多个通知。 前置通知(Before advice)： 在连接点执行之前执行。 使用@Before注解。 返回通知(After returning advice)： 在连接点返回结果的时候指定。 使用@AfterReturning注解。在注解中添加returning属性，就可以访问连接点的返回值。该属性的值即为用来传入返回值的参数名称。必须在通知方法的签名中添加一个同名参数。在运行SpringAOP时会通过这个参数传递返回值。 异常通知(After throwing advice)： 在连接点抛出异常时执行。 使用@AfterThrowing注解。在注解中添加throwing属性，就可以访问连接点抛出的异常。Throwable是所有错误和异常类的顶级父类，所以在异常通知方法可以捕获到任何错误和异常。 如果只对某种特殊的异常类型感兴趣，可以将参数声明为其他异常的参数类型。然后通知就只在抛出这个类型及其子类的异常时才被执行。 后置通知(After (finally) advice)： 也叫最终通知，是在连接点完成之后执行的，即连接点返回结果或者抛出异常的时候。 使用@After注解。 环绕通知(Around advice)： 环绕通知是所有通知类型中功能最强大的，能够全面的控制连接点，甚至可以控制是否执行连接点。 对于环绕通知来说，连接点的参数类型必须是ProceedingJoinPoint。它是JoinPoint的子接口，允许控制何时执行，是否执行连接点。 在环绕通知中需要明确调用ProceedingJoinPoint的proceed()方法来执行被代理的方法。如果忘记这样做就会导致通知被执行了，但目标方法没有被执行。 注意：环绕通知的方法需要返回目标方法执行之后的结果，即调用joinPoint.proceed()的返回值，否则会出现空指针异常。 6、配置方式Spring提供了两种AOP配置方式： xml模板配置 注解配置 例子源码地址：https://github.com/LDknife/spring-example/tree/master/spring-aop 7、重用切入点定义 在编写AspectJ切面时，可以直接在通知注解中书写切入点表达式。但同一个切点表达式可能会在多个通知中重复出现。 在AspectJ切面中，可以通过 @Pointcut 注解将一个切入点声明称简单的方法。切入点的方法体通常是空的，因为将切入点定义与应用程序逻辑混在一起是不合理的。 切入点方法的访问控制符同时也控制着这个切入点的可见性。如果切入点要在多个切面中共用，最好将它们集中在一个公共的类中。在这种情况下，它们必须被声明为public。在引入这个切入点时，必须将类名也包括在内。如果类没有与这个切面放在同一个包中，还必须包含包名。 其他通知可以通过方法名称引入该切入点。 8、指定切面的优先级 在同一个连接点上应用不止一个切面时，除非明确指定，否则它们的优先级是不确定的。 切面的优先级可以通过 实现Ordered接口或使用@Order注解指定。 实现Ordered接口，getOrder()方法返回序号。 使用@Order注解，在注解中设置序号。 序号值越小，优先级越高。","categories":[{"name":"Spring","slug":"Spring","permalink":"https://blog.lee81.cn/categories/Spring/"}],"tags":[{"name":"Spring","slug":"Spring","permalink":"https://blog.lee81.cn/tags/Spring/"}]},{"title":"Spring配置Bean","slug":"Spring配置Bean","date":"2020-01-05T07:09:27.000Z","updated":"2022-08-13T12:29:03.586Z","comments":true,"path":"2020/01/05/Spring配置Bean/","link":"","permalink":"https://blog.lee81.cn/2020/01/05/Spring%E9%85%8D%E7%BD%AEBean/","excerpt":"","text":"1、Spring IoC 容器简介控制反转（IoC） 也称为依赖注入（DI）。其思想是反转资源的获取方向，spring容器在创建bean时通过构造方法，工厂方法定义其属性和其依赖项。 2、ApplicationContextorg.springframework.context.ApplicationContext接口代表Spring IoC容器，并负责实例化，配置和组装Bean。BeanFactory为容器的基本实现，而ApplicationContext是BeanFactory的子接口，增加了更多针对企业的高级功能。 主要实现类和接口： ClassPathXmlApplicationContext：从类路径下加载配置文件。 FileSystemXmlApplicationContext：从文件系统中加载配置文件。 ConfigurableApplicationContext：扩展ApplicationContext，新增 refresh() 和 close() 两个主要方法，让ApplicationContext具有启动，刷新和关闭上下文的能力。 WebApplicationContext：用于web项目。 3、配置BeanSpring 配置Bean的三种方式： 基于xml文件配置 基于注解配置 基于java+注解配置 4、依赖注入方式（基于xml文件配置）Spring 支持三种依赖注入方式： 属性注入（常用） 构造器注入（常用） 工厂方法注入 实现FactoryBean接口 4.1 属性注入通过setter方法注入Bean的属性值或依赖对象。例子： 12345678&lt;bean id=&quot;helloWorld&quot; class=&quot;com.ld.spring.HelloWorld&quot;&gt; &lt;property name=&quot;name&quot; value=&quot;ld&quot;/&gt; &lt;property name=&quot;age&quot; value=&quot;18&quot;/&gt; &lt;property name=&quot;sex&quot; value=&quot;0&quot;/&gt; &lt;property name=&quot;address&quot;&gt; &lt;value&gt;中国&lt;/value&gt; &lt;/property&gt;&lt;/bean&gt; 在xml配置文件中： 标签表示一个Bean id：在IoC容器中必须唯一，若id没有指定，Spring自动将类名作为Bean的id。 class：全类名，通过映射的方式在IoC容器中创建Bean,所以要求Bean中必须有无参的构造器。 标签表示一个Bean的属性 name：表示属性名称 value或子节点：表示属性值 4.2 构造器注入通过构造器注入Bean的属性值或依赖对象。例子： 12345678&lt;bean id=&quot;helloWorld&quot; class=&quot;com.ld.spring.HelloWorld&quot;&gt; &lt;constructor-arg value=&quot;ld&quot; index=&quot;0&quot;/&gt; &lt;constructor-arg value=&quot;18&quot; name=&quot;age&quot;/&gt; &lt;constructor-arg value=&quot;0&quot; type=&quot;int&quot;/&gt; &lt;constructor-arg index=&quot;3&quot;&gt; &lt;value&gt;中国&lt;/value&gt; &lt;/constructor-arg&gt;&lt;/bean&gt; 在xml配置文件中： 标签表示构造器中的一个参数。在构造器的参数中不存在歧义时，通过解析参数的类型进行匹配注入。在构造器的参数中存在歧义时，通过解析显示指定的参数类型，参数索引，参数名称进行匹配注入。（注意：参数索引从0开始） 4.3 工厂方法注入 静态工厂方法 使用静态方法的方式创建对象。例子： 1234567891011121314public class StaticFactory &#123; private static StaticFactory staticFactory = new StaticFactory(); private StaticFactory()&#123;&#125; public static StaticFactory createInstance()&#123; return staticFactory; &#125; public void test()&#123; System.out.println(&quot;我获取到实例对象了&quot;); &#125;&#125; 1&lt;bean id=&quot;staticFactory&quot; class=&quot;com.ld.spring.bean.StaticFactory&quot; factory-method=&quot;createInstance&quot;/&gt; 在xml配置文件中： factory-method：指向静态工厂的静态方法。 实例工厂方法 使用实例工厂的实例对象，调用对象中的非静态方法来获取或创建其他类的实例对象。例子： 123public class ClientService&#123; public ClientService()&#123;&#125;&#125; 12345678public class DefaultServiceLocator &#123; private static ClientService clientService = new ClientServiceImpl(); public ClientService createClientServiceInstance() &#123; return clientService; &#125; &#125; 1234&lt;!-- 实例工厂bean--&gt; &lt;bean id=&quot;serviceLocator&quot; class=&quot;examples.DefaultServiceLocator&quot;/&gt; &lt;!-- 调用工厂方法获取其他bean--&gt; &lt;bean id=&quot;clientService&quot; factory-bean=&quot;serviceLocator&quot; factory-method=&quot;createClientServiceInstance&quot;/&gt; 在xml配置文件中： factory-bean：引入实例工厂的bean。 factory-method：指向实例工厂的非静态方法。 注意：一个实例工厂里可以有一个或多个工厂方法。 4.4 实现FactoryBean 接口Spring中有两种类型的bean，一种是普通bean，另一种是工厂bean，即FactoryBean。工厂bean跟普通的bean不同，其返回的对象不是指定类的一个实例，其返回的是该工厂bean的getObject方法所返回的对象。 实现FactoryBean接口，配置xml，注入bean到IoC容器。 Spring提供的FactoryBean接口：123456789101112131415package org.springframework.beans.factory;import org.springframework.lang.Nullable;public interface FactoryBean&lt;T&gt; &#123; @Nullable T getObject() throws Exception; @Nullable Class&lt;?&gt; getObjectType(); default boolean isSingleton() &#123; return true; &#125;&#125; 实现FactoryBean接口： 自定义Car类 123456789public class Car&#123; private String name; private double price; public Car(String name,double price)&#123; this.name = name; this.price = price; &#125;&#125; 自定义CarFactoryBean类，实现FactoryBean接口 123456789101112131415161718192021public class CarFactoryBean implements FactoryBean&lt;Car&gt;&#123; private String name; private double price; public CarFactoryBean(String name,double price)&#123; this.name = name; this.price = price; &#125; public CarFactoryBean() &#123;&#125; @Override public Car getObject() throws Exception &#123; return new Car(name,price); &#125; @Override public Class&lt;?&gt; getObjectType() &#123; return Car.class; &#125;&#125; 配置xml：1234&lt;bean id=&quot;car&quot; class=&quot;com.ld.spring.bean.CarFactoryBean&quot;&gt; &lt;constructor-arg value=&quot;audi&quot;/&gt; &lt;constructor-arg value=&quot;300000&quot;/&gt;&lt;/bean&gt; 5、依赖注入细节 字面量 支持字面量值的注入方式，若字面量值中包含特殊字符，可以使用 把字面量值包裹起来。 123&lt;bean id=&quot;person&quot; class=&quot;com.ld.spring.bean.Person&quot;&gt; &lt;property name=&quot;name&quot; value=&quot;&lt;![CDATA[&lt;ld&gt;]]&gt;&quot;/&gt;&lt;/bean&gt; null 可以使用专用的 标签为Bean的字符串或其他对象类型的属性注入null值。 1234&lt;bean id=&quot;person&quot; class=&quot;com.ld.spring.bean.Person&quot;&gt; &lt;property name=&quot;name&quot; value=&quot;ld&quot;/&gt; &lt;property name=&quot;car&quot;&gt;&lt;null/&gt;&lt;/property&gt; &lt;/bean&gt; 给bean的级联属性赋值。 使用ref属性注入外部已声明的bean。 123456789&lt;bean id=&quot;car&quot; class=&quot;com.ld.spring.bean.Car&quot;&gt; &lt;property name=&quot;name&quot; value=&quot;audi&quot;/&gt; &lt;property name=&quot;price&quot; value=&quot;300000&quot;/&gt;&lt;/bean&gt;&lt;bean id=&quot;person&quot; class=&quot;com.ld.spring.bean.Person&quot;&gt; &lt;property name=&quot;name&quot; value=&quot;ld&quot;/&gt; &lt;property name=&quot;car&quot; ref=&quot;car&quot;/&gt;&lt;/bean&gt; 内部bean。 123456789&lt;bean id=&quot;person&quot; class=&quot;com.ld.spring.bean.Person&quot;&gt; &lt;property name=&quot;name&quot; value=&quot;ld&quot;/&gt; &lt;property name=&quot;car&quot;&gt; &lt;bean class=&quot;com.ld.spring.bean.Car&quot;&gt; &lt;property name=&quot;name&quot; value=&quot;bwm&quot;/&gt; &lt;property name=&quot;price&quot; value=&quot;400000&quot;/&gt; &lt;/bean&gt; &lt;/property&gt;&lt;/bean&gt; 集合属性 123456789101112131415161718192021222324252627282930313233343536373839404142434445&lt;!-- &lt;list&gt; 标签--&gt;&lt;bean id=&quot;person&quot; class=&quot;com.ld.spring.bean.Person&quot;&gt; &lt;property name=&quot;name&quot; value=&quot;ld&quot;&gt; &lt;property name=&quot;addressList&quot;&gt; &lt;list&gt; &lt;value&gt;北京&lt;/value&gt; &lt;value&gt;上海&lt;/value&gt; &lt;value&gt;广州&lt;/value&gt; &lt;/list&gt; &lt;/property&gt;&lt;/bean&gt;&lt;!-- &lt;set&gt;标签--&gt;&lt;bean id=&quot;person&quot; class=&quot;com.ld.spring.bean.Person&quot;&gt; &lt;property name=&quot;name&quot; value=&quot;ld&quot;&gt; &lt;property name=&quot;cars&quot;&gt; &lt;set&gt; &lt;ref bean=&quot;car1&quot;/&gt; &lt;ref bean=&quot;car2&quot;/&gt; &lt;/set&gt; &lt;/property&gt;&lt;/bean&gt;&lt;!-- &lt;map&gt;标签--&gt;&lt;bean id=&quot;person&quot; class=&quot;com.ld.spring.bean.Person&quot;&gt; &lt;property name=&quot;name&quot; value=&quot;ld&quot;&gt; &lt;property name=&quot;carMaps&quot;&gt; &lt;map&gt; &lt;entry key=&quot;AA&quot; vlaue-ref=&quot;car1&quot;/&gt; &lt;entry key=&quot;BB&quot; vlaue-ref=&quot;car2&quot;/&gt; &lt;/map&gt; &lt;/property&gt;&lt;/bean&gt;&lt;!-- &lt;props&gt;标签--&gt;&lt;bean id=&quot;dataSourc&quot; class=&quot;com.ld.spring.bean.DataSource&quot;&gt; &lt;property name=&quot;properties&quot;&gt; &lt;props&gt; &lt;prop key=&quot;user&quot;&gt;root&lt;/prop&gt; &lt;prop key=&quot;password&quot;&gt;123456&lt;/prop&gt; &lt;prop key=&quot;url&quot;&gt;jdbc:mysql://127.0.0.1:3306/test&lt;/prop&gt; &lt;prop key=&quot;driver&quot;&gt;com.mysql.jdbc.Driver&lt;/prop&gt; &lt;/props&gt; &lt;/property&gt;&lt;/bean&gt; 使用 utility scheme 定义集合 123456789&lt;util:list id=&quot;cars&quot;&gt; &lt;ref bean=&quot;car&quot;/&gt; &lt;ref bean=&quot;car1&quot;/&gt;&lt;/util:list&gt;&lt;bean id=&quot;person&quot; class=&quot;com.ld.spring.bean.Person&quot;&gt; &lt;property name=&quot;name&quot; value=&quot;ld&quot;/&gt; &lt;property name=&quot;cars&quot; ref=&quot;cars&quot;/&gt;&lt;/bean&gt; 使用p命名空间 Spring从2.5版本引入新的p命名空间，用于简化xml配置。 1&lt;bean id=&quot;car&quot; class=&quot;com.ld.spring.bean.Car&quot; p:name=&quot;audi&quot; p:price=&quot;300000&quot;/&gt; 6、Bean的高级配置 Bean的继承 Spring允许继承bean的配置，被继承的bean称为父bean，继承父bean的bean为子bean。 子bean可以继承父bean的配置，包括属性配置。 子bean也可以覆盖从父bean继承过来的配置。 可以设置父bean为模板，即设置的abstract属性为true。Spring不会实例化这个bean。 可以不为父bean设置class属性，则这个bean必定为抽象bean,即abstract属性为true。 并不是所有的属性都可以被继承，比如：autowire,abstract 等。 123456789101112131415&lt;bean id=&quot;dept&quot; class=&quot;com.ld.spring.bean.Dept&quot;&gt; &lt;property name=&quot;deptId&quot; value=&quot;1001&quot;/&gt; &lt;property name=&quot;deptName&quot; value=&quot;PM&quot;/&gt;&lt;/bean&gt;&lt;bean id=&quot;emp01&quot; class=&quot;com.ld.spring.bean.Emp&quot;&gt; &lt;property name=&quot;id&quot; value=&quot;01&quot;/&gt; &lt;property name=&quot;name&quot; value=&quot;ld&quot;/&gt; &lt;property name=&quot;dept&quot; ref=&quot;dept&quot;&gt;&lt;/bean&gt;&lt;bean id=&quot;emp02&quot; parent=&quot;emp01&quot;&gt; &lt;property name=&quot;id&quot; value=&quot;02&quot;/&gt; &lt;property name=&quot;name&quot; value=&quot;monkey&quot;/&gt;&lt;/bean&gt; Bean之间的依赖 有时创建一个bean需要保证另一个bean也被创建，这时我们称前面的bean对后面的bean有依赖。依赖也可以不引用。 123456789&lt;bean id=&quot;dept&quot; class=&quot;com.ld.spring.bean.Dept&quot;&gt; &lt;property name=&quot;deptId&quot; value=&quot;1001&quot;/&gt; &lt;property name=&quot;deptName&quot; value=&quot;PM&quot;/&gt;&lt;/bean&gt;&lt;!-- emp 依赖 dept--&gt;&lt;bean id=&quot;emp&quot; class=&quot;com.ld.spring.bean.Emp&quot; depends-on=&quot;dept&quot;&gt; &lt;property name=&quot;id&quot; value=&quot;01&quot;/&gt; &lt;property name=&quot;name&quot; value=&quot;ld&quot;/&gt;&lt;/bean&gt; Bean的懒加载 SpringIoC容器中默认都为单例Bean,即在创建IoC容器时，创建所有的Bean。有时我们为了性能不需要预先实例化bean，所以Spring提供延迟初始化Bean的方式，即首次请求时创建。设置lazy-init为true即可。 1&lt;bean id=&quot;person&quot; class=&quot;com.ld.spring.bean.Person&quot; lazy-init=&quot;true&quot;/&gt; 我们也可以在容器级别控制延迟初始化。 123&lt;beans default-lazy-init=&quot;true&quot;&gt; ...&lt;/beans&gt; 7、Bean的作用域在Spring中，可以在 标签的scope属性里设置bean的作用域。Spring支持的作用域： singleton：(默认值) 在Spring IoC容器中所有bean仅存在单个对象实例。在创建IoC容器时，创建定义的bean对象。 prototype：可以将bean创建任意数量的对象实例。在调用bean时，才创建bean对象。 request：在WEB容器中使用，将bean对象的作用域限定在单个HTTP请求的生命周期中。 session：在WEB容器中使用，将bean对象的作用域限定在单个Session的生命周期中。 application：在WEB容器中使用，将bean对象的作用域限定在ServletContext的生命周期中。 websocket：在WEB容器中使用，将bean对象的作用域限定在websocket的生命周期中。 8、Bean的生命周期Bean的生命周期流程： 通过构造器或工厂方法创建bean实例。 为bean的属性赋值和对其他bean的引用。 调用bean的初始化方法。 使用bean对象。 当容器关闭时，调用bean的销毁方法。 注意：在配置bean时，可以通过init-method和destory-method属性指定初始化和销毁方法。例子源码地址：https://github.com/LDknife/spring-example/tree/master/spring-bean 9、Bean的后置处理器bean的后置处理器允许在调用bean的初始化方法的前后对bean进行额外处理。bean的后置处理器是对IoC容器中所有的bean实例逐一处理，而非单一实例。其典型应用是：检查bean属性的正确性或根据特定的标准更改bean的属性。 Spring提供的BeanPostProcessor接口： 123456789101112131415package org.springframework.beans.factory.config;import org.springframework.beans.BeansException;import org.springframework.lang.Nullable;public interface BeanPostProcessor &#123; @Nullable default Object postProcessBeforeInitialization(Object bean, String beanName) throws BeansException &#123; return bean; &#125; @Nullable default Object postProcessAfterInitialization(Object bean, String beanName) throws BeansException &#123; return bean; &#125;&#125; 10、引入外部配置文件当xml配置文件中配置的bean比较多时，查找或者修改一些bean的配置会变得比较困难。因此Spring提供将bean的配置信息以properties文件存储，然后以引入外部配置文件的方式，使其关联起来。从而实现修改properties文件即可修改bean的配置信息。 前提：xml配置文件中需要引入context命名空间。 创建并配置properties文件。 1234jdbc.username=rootjdbc.password=123456jdbc.url=jdbc:mysql://127.0.0.1:3306/testjdbc.driver=com.mysql.jdbc.Driver 在xml配置文件中引入properties属性文件。 方式一（常用）：123&lt;!-- classpath:xxx 表示属性文件位于类路径下--&gt;&lt;!-- 如果有多个properties配置文件需要引入，那么一定要加上 ignore-unresolvable=&quot;true&quot;,多个配置文件以”,“分割--&gt;&lt;context:property-placeholder location=&quot;classpath:jdbc.properties&quot;/&gt; 方式二：123&lt;bean class=&quot;org.springframework.beans.factory.config.PropertyPlaceholderConfigurer&quot;&gt; &lt;property name=&quot;location&quot; value=&quot;classpath:jdbc.properties&quot; /&gt;&lt;/bean&gt; 在xml配置文件中关联properties属性1234567&lt;!-- $&#123;&#125; 用于关联properties属性--&gt;&lt;bean id=&quot;dataSource&quot; class=&quot;com.mchange.v2.c3p0.ComboPooledDataSource&quot;&gt; &lt;property name=&quot;user&quot; value=&quot;$&#123;jdbc.username&#125;&quot;/&gt; &lt;property name=&quot;password&quot; value=&quot;$&#123;jdbc.password&#125;&quot;/&gt; &lt;property name=&quot;jdbcUrl&quot; value=&quot;$&#123;jdbc.url&#125;&quot;/&gt; &lt;property name=&quot;driverClass&quot; value=&quot;$&#123;jdbc.driver&#125;&quot;/&gt;&lt;/bean&gt; 11、自动装配根据指定的装配规则，不需要明确指定，Spring自动将匹配的属性值注入bean中。Spring提供的装配模式： byName：将目标bean的名称和属性名完全相同才可装配成功。 byType：将类型匹配的目标bean,作为属性注入到另一个bean中。如果目标bean存在多个，将无法判定使用哪一个bean。无法装配成功。 constructor：当bean中存在多个构造器时，此种自动装配方式将会很复杂。不推荐使用。 注意：在xml中自动装配比较笨拙，开发时多用于注解的方式。 12、基于注解配置Bean相对于xml方式而言，通过注解的方式配置bean更加简洁和优雅，是开发中常用的使用方式。 12.1、常用组件注解 @Component：标识一个受SpringIoC容器管理的组件。 @Controller：标识一个受SpringIoC容器管理的表述层控制器组件。 @Service：标识一个受SpringIoC容器管理的业务逻辑层组件。 @Repository：标识一个受SpringIoC容器管理的持久化层组件。 12.2、组件命名规则 默认情况：使用组件的简单类名首字母小写后得到的字符串作为bean的id。 自定义：可以自定义bean的id。注意：使用组件注解的value属性指定bean的id。 12.3、扫描组件组件被注解标识后，需要通过Spring进行扫描才能够检测到。指定被扫描的package（xml文件需要引入context命名空间）： base-package 属性可以指定一个需要扫描的基类包，Spring容器将会扫描这个基类包及其子包中的所有类。 当需要扫描多个包时可以使用逗号分隔。 如果仅希望扫描特定的类，而非基包下的所有类，可以使用 resource-pattern 属性过滤特定的类。 &lt;context:include-filter /&gt;子节点表示要包含的目标类。注意：通常需要与 use-default-filters 属性配合使用才能达到效果。即：通过将 use-default-filters 属性设置为false，禁用默认过滤器，然后扫描的就只是include-filter中的规则指定的组件了。 &lt;context:exclude-filter /&gt;子节点表示要排除的目标类。 component-scan 下可以拥有若干个 include-filter 和 exclude-filter 子节点。 过滤表达式： annotation：过滤所有标注此类注解的类。 assignable：过滤所有同父类的子类。 1&lt;context:component-scan base-package=&quot;com.ld.spring&quot;/&gt; 12.4、组件装配在指定要扫描的包时，&lt;context:component-scan &gt;标签会自动注册一个bean的后置处理器：AutowiredAnnotationBeanPostProcessor 的实例。该后置处理器可以自动装配标记了@Autowired、@Resource 或 @Inject 注解的属性。 @Autowired： 根据类型实现自动装配。 构造器、普通字段（即使是非public）、一切具有参数的方法都可以应用@Autowired注解。 默认情况下，所有使用@Autowired 注解的属性都需要被设置。当Spring找不到匹配的bean装配属性时，会抛出异常。 若某一属性允许不被设置，可以设置@Autowired注解的 required 属性为false。 默认情况下，当IoC容器里存在多个类型兼容的bean时，Spring会尝试匹配bean的id值是否与变量名相同，如果相同则进行装配。如果bean的id值不相同，通过类型的自动装配将无法工作。此时可以在 @Qualifier 注解里提供bean的名称。Spring 甚至允许在方法的形参上标注@Qualifier注解以指定注入bean的名称。 @Autowired 注解可以应用在数组类型的属性上，此时Spring 将会把所有的匹配的bean进行自动装配。 @Autowired 注解可以应用在集合属性上，此时Spring 读取该集合的类型信息，然后自动装配所有与之兼容的bean。 @Autowired 注解可以应用在java.util.Map上，若该map的键值为String，那么Spring 将自动装配与值类型兼容的bean作为值，并以bean的id值作为键。 @Resource @Resource 注解要求提供一个bean名称的属性，若该属性为空，则自动采用标注处的变量或方法名作为bean的名称。 @Inject @Inject 和 @Autowired 注解一样也是按类型装配的，但没有required 属性。","categories":[{"name":"Spring","slug":"Spring","permalink":"https://blog.lee81.cn/categories/Spring/"}],"tags":[{"name":"Spring","slug":"Spring","permalink":"https://blog.lee81.cn/tags/Spring/"}]},{"title":"SpringBoot引入本地jar包","slug":"SpringBoot引入本地jar包","date":"2020-01-03T07:09:27.000Z","updated":"2022-08-13T12:29:03.585Z","comments":true,"path":"2020/01/03/SpringBoot引入本地jar包/","link":"","permalink":"https://blog.lee81.cn/2020/01/03/SpringBoot%E5%BC%95%E5%85%A5%E6%9C%AC%E5%9C%B0jar%E5%8C%85/","excerpt":"","text":"1、添加本地依赖jar包在 dependencies 中添加如下配置： 123456&lt;dependency&gt; &lt;groupId&gt;weather-log&lt;/groupId&gt; &lt;artifactId&gt;weather-log&lt;/artifactId&gt; &lt;version&gt;0.1&lt;/version&gt; &lt;scope&gt;system&lt;/scope&gt; &lt;systemPath&gt;$&#123;project.basedir&#125;/src/main/resources/lib/weather-log.jar&lt;/systemPath&gt;&lt;/dependency&gt; 注意：${project.basedir}/src/main/resources/lib/weather-log.jar 一定要和你的jar包路径一样，我的是放在resources/lib文件夹下 2、配置plugin在 plugins 中添加如下配置： 12345678&lt;plugin&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-maven-plugin&lt;/artifactId&gt; &lt;configuration&gt; &lt;includeSystemScope&gt;true&lt;/includeSystemScope&gt; &lt;fork&gt;true&lt;/fork&gt; &lt;/configuration&gt;&lt;/plugin&gt; 就是这么简单，完成了，真的没了。。。","categories":[{"name":"SpringBoot","slug":"SpringBoot","permalink":"https://blog.lee81.cn/categories/SpringBoot/"}],"tags":[{"name":"SpringBoot","slug":"SpringBoot","permalink":"https://blog.lee81.cn/tags/SpringBoot/"}]},{"title":"SpringBoot整合WebSocket","slug":"SpringBoot整合WebSocket","date":"2020-01-02T06:25:14.000Z","updated":"2022-08-13T12:29:03.586Z","comments":true,"path":"2020/01/02/SpringBoot整合WebSocket/","link":"","permalink":"https://blog.lee81.cn/2020/01/02/SpringBoot%E6%95%B4%E5%90%88WebSocket/","excerpt":"","text":"1、引入jar包1234&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-websocket&lt;/artifactId&gt;&lt;/dependency&gt; 2、自定义HandshakeInterceptor1234567891011121314151617181920212223242526@Componentpublic class WebSocketHandshakeInterceptor implements HandshakeInterceptor &#123; @Override public boolean beforeHandshake(ServerHttpRequest serverHttpRequest, ServerHttpResponse serverHttpResponse, WebSocketHandler webSocketHandler, Map&lt;String, Object&gt; attributes) throws Exception &#123; if (serverHttpRequest instanceof ServletServerHttpRequest) &#123; //强转请求类型 HttpServletRequest servletRequest = ((ServletServerHttpRequest) serverHttpRequest).getServletRequest(); //通过请求参数获取socketId,用于作为socket账号信息 String socketId = servletRequest.getParameter(&quot;socket_id&quot;); if(StringUtils.isEmpty(socketId))&#123; return false; &#125; attributes.put(&quot;socket_id&quot;, socketId); &#125; return true; &#125; @Override public void afterHandshake(ServerHttpRequest serverHttpRequest, ServerHttpResponse serverHttpResponse,WebSocketHandler webSocketHandler, Exception e) &#123; &#125; &#125; 3、自定义WebSocketHandler123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114@Componentpublic class WebSocketHandler implements WebSocketHandler &#123; //存储websocket session 集合 public static ConcurrentHashMap&lt;String, WebSocketSession&gt; webSocketSessionMap = new ConcurrentHashMap&lt;&gt;(); /** * 建立连接之后 * @param webSocketSession * @throws Exception */ @Override public void afterConnectionEstablished(WebSocketSession webSocketSession) throws Exception &#123; //获取socketId String websocket_id = (String) webSocketSession.getAttributes().get(&quot;socket_id&quot;); //存储socketId和session对象 webSocketSessionMap.put(websocket_id,webSocketSession); LogUtil.debug(websocket_id + &quot;,建立连接成功...&quot;); &#125; /** * 获取到消息 * @param webSocketSession * @param webSocketMessage * @throws Exception */ @Override public void handleMessage(WebSocketSession webSocketSession, WebSocketMessage&lt;?&gt; webSocketMessage) throws Exception &#123; LogUtil.debug(&quot;获取发来的消息,&quot; + webSocketMessage.getPayload().toString()); &#125; /** * 连接错误 * @param webSocketSession * @param throwable * @throws Exception */ @Override public void handleTransportError(WebSocketSession webSocketSession, Throwable throwable) throws Exception &#123; //获取socketId String websocket_id = (String) webSocketSession.getAttributes().get(&quot;socket_id&quot;); //根据socketId删除session对象 webSocketSessionMap.remove(websocket_id); LogUtil.debug(websocket_id + &quot;,连接出现错误...&quot;); &#125; /** * 关闭连接 * @param webSocketSession * @param closeStatus * @throws Exception */ @Override public void afterConnectionClosed(WebSocketSession webSocketSession, CloseStatus closeStatus) throws Exception &#123; //获取socketId String websocket_id = (String) webSocketSession.getAttributes().get(&quot;socket_id&quot;); //根据socketId删除session对象 webSocketSessionMap.remove(websocket_id); LogUtil.debug(websocket_id + &quot;,关闭连接...&quot;); &#125; @Override public boolean supportsPartialMessages() &#123; return false; &#125; /** * 给所有的用户发送信息 * @param message 信息 */ public void sendMessageToAllUser(String message)&#123; //遍历session集合 ConcurrentHashMap.KeySetView&lt;String, WebSocketSession&gt; keySet = webSocketSessionMap.keySet(); Iterator&lt;String&gt; iterator = keySet.iterator(); while (iterator.hasNext())&#123; //获取socketId String websocket_id = iterator.next(); //获取session对象 WebSocketSession webSocketSession = webSocketSessionMap.get(websocket_id); if(webSocketSession != null &amp;&amp; webSocketSession.isOpen())&#123; try &#123; //发送消息 webSocketSession.sendMessage(new TextMessage(message)); &#125; catch (IOException e) &#123; LogUtil.error(&quot;websocket 发送数据失败，失败原因：&quot; + e); &#125; &#125; &#125; &#125; /** * 给单个用户发送信息 * @param socketId socket账户 * @param message 消息 */ public void sendMessageToOneUser(String socketId,String message)&#123; if(!StringUtils.isEmpty(socketId))&#123; //判断session集合中存在socketId if(webSocketSessionMap.containsKey(socketId))&#123; //获取session对象 WebSocketSession webSocketSession = webSocketSessionMap.get(socketId); if(webSocketSession != null &amp;&amp; webSocketSession.isOpen())&#123; try &#123; //发送消息 webSocketSession.sendMessage(new TextMessage(message)); &#125; catch (IOException e) &#123; LogUtil.error(&quot;websocket 发送数据失败，失败原因：&quot; + e); &#125; &#125; &#125; &#125; &#125;&#125; 4、注册webSocket组件 实现 WebSocketConfigurer 接口，重写 registerWebSocketHandlers 方法，这是一个核心实现方法，配置 websocket 入口，允许访问的域、注册 Handler、SockJs 支持和拦截器。 registry.addHandler()注册和路由的功能，当客户端发起 websocket 连接，把 /path 交给对应的 handler 处理，而不实现具体的业务逻辑，可以理解为收集和任务分发中心。 addInterceptors，顾名思义就是为 handler 添加拦截器，可以在调用 handler 前后加入我们自己的逻辑代码。 setAllowedOrigins(String[] domains),允许指定的域名或 IP (含端口号)建立长连接，如果只允许自家域名访问，这里轻松设置。如果不限时使用”* ”号，如果指定了域名，则必须要以 http 或 https 开头。 1234567891011121314151617181920@Configurationpublic class WebSocketConfig implements WebSocketConfigurer &#123; //拦截器 @Autowired private webSocketHandshakeInterceptor handshakeInterceptor; //websocket控件 @Autowired private sebSocketHandler webSocketHandler; @Override public void registerWebSocketHandlers(WebSocketHandlerRegistry registry) &#123; //部分 支持websocket 的访问链接,允许跨域 registry.addHandler(webSocketHandler,&quot;/websocket&quot;) .addInterceptors(handshakeInterceptor).setAllowedOrigins(&quot;*&quot;); //部分 不支持websocket的访问链接,允许跨域 registry.addHandler(webSocketHandler,&quot;/sockjs/websocket&quot;) .addInterceptors(handshakeInterceptor).setAllowedOrigins(&quot;*&quot;).withSockJS(); &#125;&#125; 5、开启WebSocket一定不要忘添加@EnableWebSocket 1234567@EnableWebSocket@SpringBootApplicationpublic class WebSocketApplication &#123; public static void main(String[] args) &#123; SpringApplication.run(WebSocketApplication.class, args); &#125;&#125;","categories":[{"name":"SpringBoot","slug":"SpringBoot","permalink":"https://blog.lee81.cn/categories/SpringBoot/"}],"tags":[{"name":"SpringBoot","slug":"SpringBoot","permalink":"https://blog.lee81.cn/tags/SpringBoot/"},{"name":"WebSocket","slug":"WebSocket","permalink":"https://blog.lee81.cn/tags/WebSocket/"}]},{"title":"Hexo博客搭建","slug":"Hexo博客搭建","date":"2020-01-01T16:02:15.000Z","updated":"2022-08-13T12:29:03.572Z","comments":true,"path":"2020/01/02/Hexo博客搭建/","link":"","permalink":"https://blog.lee81.cn/2020/01/02/Hexo%E5%8D%9A%E5%AE%A2%E6%90%AD%E5%BB%BA/","excerpt":"","text":"1、准备环境1.1、安装Git下载地址：https://git-scm.com/download/win 安装好后，查看版本，验证是否安装成功。 1git --version 1.2、安装nodejs、npm下载地址：https://nodejs.org/en/download/ 因为nodejs包含npm,所以不需要单独安装，安装好后用以下命令来查看版本，验证是否安装成功。 12node -vnpm -v 1.3、安装cnpm因为npm服务器不在国内，访问速度有些慢，但是淘宝团队提供了国内镜像，所以需要安装cnpm。 1npm install -g cnpm --registry=https://registry.npm.taobao.org 查看版本，验证是否安装成功。 1cnpm -v 2、安装Hexo2.1、安装1cnpm install -g hexo-cli 查看版本，验证是否安装成功。 1hexo -v 2.2、初始化先创建一个文件夹，用于存放hexo初始化的文件，我创建的文件夹的位置为E:\\blog。然后在此文件夹下执行如下命令： 1hexo init blog 其中hexo-blog为自定义的文件夹名。如果缺少module，就进入到hexo-blog文件夹，执行如下命令： 1cnpm install 文件夹目录如下： 1234567node_modules：npm依赖scaffolds：生成文章的一些模板source：存放文章themes：主题_config.yml：主要配置文件package.jsonpackage-lock.json 2.3、运行生成服务： 1hexo g 运行服务： 1hexo server 使用浏览器访问 http://localhost:4000 就可以看到生成的博客。 3、将Hexo部署到Gitee3.1、在gitee上创建一个仓库3.2、启动Gitee Pages服务点击仓库服务中的Gitee Pages，然后点击开启即可。 3.3、修改本地_config.yml配置文件修改如下配置： 1234567url: 开启的Gitee Pages服务的urlroot: 仓库名称deploy: type: git repo: 你自己的仓库地址 branch: master 3.4、安装deploy-git安装deploy-git，用于部署服务。执行如下命令： 1cnpm install hexo-deployer-git --save 3.5、清空、生成和部署123hexo cleanhexo generatehexo deploy 3.6、刷新服务因为gitee不会自动部署刷新，所以需要每次部署完进行手动刷新。然后就可以在浏览器访问Gitee Pages服务生成的网站地址了，此地址就是你对外的博客地址。 4、配置个人域名在Gitee 上是花钱的，这个就看自己选择吧。 5、多终端工作为了支持多个终端进行编写部署，使用git分支特性来实现。 5.1、创建分支5.2、克隆分支到本地1git clone -b 分支名 仓库地址 5.3、复制hexo资源首先删除除.git文件的其他文件，然后将原先的除.deploy_git文件的其他资源文件拷贝到这里。 5.4、提交123git add .git commit -m &quot;add source&quot;git push 注意：一般只提交以下文件 1234567scaffolds：生成文章的一些模板source：存放文章themes：主题.gitignore：过滤配置_config.yml：主要配置文件package-lock.jsonpackage.json 5.5、切换到其他电脑 首先配置好环境，按照上面的步骤配置 克隆分支仓库到本地 执行 cnpm install 命令进行初始化 编写自己的新内容 然后生成、部署 最后别忘了提交自己的新内容 注意：如果当前电脑已经有了上述环境，直接执行如下命令同步一下仓库就可以了。 1git pull 6、修改主题如果不喜欢hexo默认提供的主题，可以自己寻找自己喜欢的主题进行切换。 6.1、下载主题1git clone 主题仓库地址 themes/主题名称 其中 themes/主题名称 是指将主题下载到指定位置。 这里有两个我比较喜欢的主题，我使用的是pure： https://github.com/cofess/hexo-theme-pure https://github.com/lxqxsyu/hexo-theme-icarus 6.2、修改配置这里需要说明一下，在根目录下有一个配置文件_config.yml，这个是用于配置hexo的，进入到 themes/pure目录中，同样有一个配置文件 _config.yml ,这个是用于配置主题的。 这里我们需要修改的是hexo配置文件，修改如下： 1theme: 主题名称 然后重新清空、生成和部署即可。 6.3、配置主题按照自己选定的主题，进行自主配置。因为每个主题配置都不尽相同，所以这里就不做描述，可以根据主题相关文档进行配置。 7、配置Hexo请参考官方文档进行配置。 8、添加插件","categories":[{"name":"Hexo","slug":"Hexo","permalink":"https://blog.lee81.cn/categories/Hexo/"}],"tags":[{"name":"Hexo","slug":"Hexo","permalink":"https://blog.lee81.cn/tags/Hexo/"}]}],"categories":[{"name":"笔试题","slug":"笔试题","permalink":"https://blog.lee81.cn/categories/%E7%AC%94%E8%AF%95%E9%A2%98/"},{"name":"算法","slug":"算法","permalink":"https://blog.lee81.cn/categories/%E7%AE%97%E6%B3%95/"},{"name":"Kafka","slug":"Kafka","permalink":"https://blog.lee81.cn/categories/Kafka/"},{"name":"Zookeeper","slug":"Zookeeper","permalink":"https://blog.lee81.cn/categories/Zookeeper/"},{"name":"Nginx","slug":"Nginx","permalink":"https://blog.lee81.cn/categories/Nginx/"},{"name":"Maven","slug":"Maven","permalink":"https://blog.lee81.cn/categories/Maven/"},{"name":"Linux","slug":"Linux","permalink":"https://blog.lee81.cn/categories/Linux/"},{"name":"Cassandra","slug":"Cassandra","permalink":"https://blog.lee81.cn/categories/Cassandra/"},{"name":"动态代理","slug":"动态代理","permalink":"https://blog.lee81.cn/categories/%E5%8A%A8%E6%80%81%E4%BB%A3%E7%90%86/"},{"name":"Elasticsearch","slug":"Elasticsearch","permalink":"https://blog.lee81.cn/categories/Elasticsearch/"},{"name":"Docker","slug":"Docker","permalink":"https://blog.lee81.cn/categories/Docker/"},{"name":"JVM","slug":"JVM","permalink":"https://blog.lee81.cn/categories/JVM/"},{"name":"Spring","slug":"Spring","permalink":"https://blog.lee81.cn/categories/Spring/"},{"name":"SpringBoot","slug":"SpringBoot","permalink":"https://blog.lee81.cn/categories/SpringBoot/"},{"name":"Hexo","slug":"Hexo","permalink":"https://blog.lee81.cn/categories/Hexo/"}],"tags":[{"name":"笔试题","slug":"笔试题","permalink":"https://blog.lee81.cn/tags/%E7%AC%94%E8%AF%95%E9%A2%98/"},{"name":"算法","slug":"算法","permalink":"https://blog.lee81.cn/tags/%E7%AE%97%E6%B3%95/"},{"name":"排序","slug":"排序","permalink":"https://blog.lee81.cn/tags/%E6%8E%92%E5%BA%8F/"},{"name":"集群搭建","slug":"集群搭建","permalink":"https://blog.lee81.cn/tags/%E9%9B%86%E7%BE%A4%E6%90%AD%E5%BB%BA/"},{"name":"Kafka","slug":"Kafka","permalink":"https://blog.lee81.cn/tags/Kafka/"},{"name":"Zookeeper","slug":"Zookeeper","permalink":"https://blog.lee81.cn/tags/Zookeeper/"},{"name":"运维","slug":"运维","permalink":"https://blog.lee81.cn/tags/%E8%BF%90%E7%BB%B4/"},{"name":"一致性协议","slug":"一致性协议","permalink":"https://blog.lee81.cn/tags/%E4%B8%80%E8%87%B4%E6%80%A7%E5%8D%8F%E8%AE%AE/"},{"name":"使用场景","slug":"使用场景","permalink":"https://blog.lee81.cn/tags/%E4%BD%BF%E7%94%A8%E5%9C%BA%E6%99%AF/"},{"name":"深入原理","slug":"深入原理","permalink":"https://blog.lee81.cn/tags/%E6%B7%B1%E5%85%A5%E5%8E%9F%E7%90%86/"},{"name":"客户端","slug":"客户端","permalink":"https://blog.lee81.cn/tags/%E5%AE%A2%E6%88%B7%E7%AB%AF/"},{"name":"Nginx","slug":"Nginx","permalink":"https://blog.lee81.cn/tags/Nginx/"},{"name":"安装","slug":"安装","permalink":"https://blog.lee81.cn/tags/%E5%AE%89%E8%A3%85/"},{"name":"Maven","slug":"Maven","permalink":"https://blog.lee81.cn/tags/Maven/"},{"name":"Linux","slug":"Linux","permalink":"https://blog.lee81.cn/tags/Linux/"},{"name":"Ubuntu","slug":"Ubuntu","permalink":"https://blog.lee81.cn/tags/Ubuntu/"},{"name":"Cassandra","slug":"Cassandra","permalink":"https://blog.lee81.cn/tags/Cassandra/"},{"name":"动态代理","slug":"动态代理","permalink":"https://blog.lee81.cn/tags/%E5%8A%A8%E6%80%81%E4%BB%A3%E7%90%86/"},{"name":"Elasticsearch","slug":"Elasticsearch","permalink":"https://blog.lee81.cn/tags/Elasticsearch/"},{"name":"Docker","slug":"Docker","permalink":"https://blog.lee81.cn/tags/Docker/"},{"name":"JVM","slug":"JVM","permalink":"https://blog.lee81.cn/tags/JVM/"},{"name":"工具","slug":"工具","permalink":"https://blog.lee81.cn/tags/%E5%B7%A5%E5%85%B7/"},{"name":"Spring","slug":"Spring","permalink":"https://blog.lee81.cn/tags/Spring/"},{"name":"SpringBoot","slug":"SpringBoot","permalink":"https://blog.lee81.cn/tags/SpringBoot/"},{"name":"WebSocket","slug":"WebSocket","permalink":"https://blog.lee81.cn/tags/WebSocket/"},{"name":"Hexo","slug":"Hexo","permalink":"https://blog.lee81.cn/tags/Hexo/"}]}